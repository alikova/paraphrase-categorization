{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["8rUN7eCZBkXU","-BPcvwxZBkXY","sX-obQ9KBkXZ","4FhHiV9ewezJ","jCSpfR0I_0zc","BCcetVRwBkXc","X7Li0568BkXc","GOjH7N941z9z","tnJIJ9oNBkXf","7teb07y3BkXj","iZetRXUWBkXq","faVNT2NCBkXu","4_qBaj9Tq3wH"],"machine_shape":"hm","authorship_tag":"ABX9TyOml+/toMJd7+qtM16sOjV4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#### Optimized code for translation (*test_code_Paraphrase Datasets Translations - GaMS.ipynb*) with OpenAI model. This script uses cache patterns and batch processing inside of pipeline programming, enabling parallel processing of translation batches. As a result, the API calls are optimized, and if an error occurs during the translation of a single sentence, the entire batch is not lost. We are using ChatGPT-3.5 via the OpenAI API key."],"metadata":{"id":"B7cJnBTxBa3h"}},{"cell_type":"markdown","source":["## Mount Google Drive"],"metadata":{"id":"j9NLS82cGq5F"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"id":"msAJWILyGttj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739721381537,"user_tz":-60,"elapsed":29388,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"98bbc00e-9eae-4c57-eddc-bc76f2196b24"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## Git add and commit"],"metadata":{"id":"8rUN7eCZBkXU"}},{"cell_type":"code","source":["!git clone https://alikova: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@github.com/alikova/paraphrase-categorization.git\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739721381622,"user_tz":-60,"elapsed":58,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"24d1472c-a4de-4be8-e9dd-e61e2523c9cb","id":"9s71E83_BkXU"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'paraphrase-categorization' already exists and is not an empty directory.\n"]}]},{"cell_type":"code","source":["!ls /content\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739543149333,"user_tz":-60,"elapsed":301,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"adfe9931-f382-4b7c-a96a-4cc678957b2a","id":"tAfkbrc3BkXV"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["drive  paraphrase-categorization  sample_data\n"]}]},{"cell_type":"code","source":["%cd /content/paraphrase-categorization\n","!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739721384839,"user_tz":-60,"elapsed":129,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"f9be46b5-83df-424a-86ad-f675824a0a4a","id":"-tcdAMSyBkXV"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/paraphrase-categorization\n","/content/paraphrase-categorization\n"]}]},{"cell_type":"code","source":["!find /content -name \"Paraphrase_Datasets_Translations_GPT3.5.ipynb\"\n","\n","!ls /content/paraphrase-categorization/\n","\n","!ls /content/drive/MyDrive/\n"],"metadata":{"executionInfo":{"status":"ok","timestamp":1739721387381,"user_tz":-60,"elapsed":699,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"id":"uVLQ8AlpBkXW","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b618a3f6-81ca-479c-b7c0-f2c4f4e7961a"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/paraphrase-categorization/Paraphrase_Datasets_Translations_GPT3.5.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Paraphrase_Datasets_Translations_GPT3.5.ipynb\n"," kaggle_prevajajanje_zbirk.html\n","'Load and translate Paraphrases with GaMS _ Kaggle.html'\n"," paraphrase_datasets_translation_GaMS_gpu\n"," Paraphrase_Datasets_Translations_GaMS.ipynb\n"," Paraphrase_Datasets_Translations_GPT3.5_GPU.ipynb\n"," Paraphrase_Datasets_Translations_GPT3.5.ipynb\n"," paraphrase_read-and-translate.py\n"," README.md\n","'Colab Notebooks'   Translated_Datasets\n"]}]},{"cell_type":"code","source":["!find /content/drive/ -name \"Paraphrase_Datasets_Translations_GPT3.5.ipynb\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bLpfCqYYHay-","executionInfo":{"status":"ok","timestamp":1739721390157,"user_tz":-60,"elapsed":173,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"16f9e0cd-f0e8-47b3-893e-409e49f51a22"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/Paraphrase_Datasets_Translations_GPT3.5.ipynb\n"]}]},{"cell_type":"code","source":["!cp \"/content/drive/MyDrive/Colab Notebooks/Paraphrase_Datasets_Translations_GPT3.5.ipynb\" /content/paraphrase-categorization/\n","\n","!ls /content/paraphrase-categorization/\n","%cd /content/paraphrase-categorization\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739721392691,"user_tz":-60,"elapsed":1151,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"91afa176-d4b7-4ce7-ebcd-51f493bc7206","id":"HlEcO_pxBkXW"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":[" kaggle_prevajajanje_zbirk.html\n","'Load and translate Paraphrases with GaMS _ Kaggle.html'\n"," paraphrase_datasets_translation_GaMS_gpu\n"," Paraphrase_Datasets_Translations_GaMS.ipynb\n"," Paraphrase_Datasets_Translations_GPT3.5_GPU.ipynb\n"," Paraphrase_Datasets_Translations_GPT3.5.ipynb\n"," paraphrase_read-and-translate.py\n"," README.md\n","/content/paraphrase-categorization\n"]}]},{"cell_type":"code","source":["!ls -a\n","\n","!git add Paraphrase_Datasets_Translations_GPT3.5.ipynb\n","!git status\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739721395946,"user_tz":-60,"elapsed":381,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"e8863e22-f06c-4b66-ba4a-e3661a0e9ef0","id":"sZYez0CLBkXX"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":[" .\n"," ..\n"," .git\n"," kaggle_prevajajanje_zbirk.html\n","'Load and translate Paraphrases with GaMS _ Kaggle.html'\n"," paraphrase_datasets_translation_GaMS_gpu\n"," Paraphrase_Datasets_Translations_GaMS.ipynb\n"," Paraphrase_Datasets_Translations_GPT3.5_GPU.ipynb\n"," Paraphrase_Datasets_Translations_GPT3.5.ipynb\n"," paraphrase_read-and-translate.py\n"," README.md\n","On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes to be committed:\n","  (use \"git restore --staged <file>...\" to unstage)\n","\t\u001b[32mmodified:   Paraphrase_Datasets_Translations_GPT3.5.ipynb\u001b[m\n","\n"]}]},{"cell_type":"code","source":["!git config --global user.email \"z.alenka7@gmail.com\"\n","!git config --global user.name \"alikova\"\n"],"metadata":{"id":"95QXRLcUBkXX","executionInfo":{"status":"ok","timestamp":1739721399368,"user_tz":-60,"elapsed":249,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["!git commit -m \"Update Paraphrase_Datasets_Translations_GPT3.5.ipynb\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739721401951,"user_tz":-60,"elapsed":206,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"85925b28-7b05-451a-fd62-21b2749f6075","id":"GcR-ZHLjBkXX"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["[main a0cb81a] Update Paraphrase_Datasets_Translations_GPT3.5.ipynb\n"," 1 file changed, 1 insertion(+), 1 deletion(-)\n"," rewrite Paraphrase_Datasets_Translations_GPT3.5.ipynb (93%)\n"]}]},{"cell_type":"code","source":["!git push origin main  # or the appropriate branch name if it's not 'main'\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739721422389,"user_tz":-60,"elapsed":1332,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"44ebfad3-5a98-4df8-f113-7190604c8c5a","id":"sj0U_6hoBkXY"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Enumerating objects: 5, done.\n","Counting objects:  20% (1/5)\rCounting objects:  40% (2/5)\rCounting objects:  60% (3/5)\rCounting objects:  80% (4/5)\rCounting objects: 100% (5/5)\rCounting objects: 100% (5/5), done.\n","Delta compression using up to 8 threads\n","Compressing objects:  33% (1/3)\rCompressing objects:  66% (2/3)\rCompressing objects: 100% (3/3)\rCompressing objects: 100% (3/3), done.\n","Writing objects:  33% (1/3)\rWriting objects:  66% (2/3)\rWriting objects: 100% (3/3)\rWriting objects: 100% (3/3), 1.13 KiB | 289.00 KiB/s, done.\n","Total 3 (delta 2), reused 0 (delta 0), pack-reused 0\n","remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n","To https://github.com/alikova/paraphrase-categorization.git\n","   bde0964..a0cb81a  main -> main\n"]}]},{"cell_type":"markdown","source":["## Installations"],"metadata":{"id":"-BPcvwxZBkXY"}},{"cell_type":"code","source":["pip uninstall openai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cftOsVoceHhc","executionInfo":{"status":"ok","timestamp":1739278323309,"user_tz":-60,"elapsed":6983,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"3d166a23-57c1-4b2b-9b30-15fed7ed3e54"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: openai 1.61.1\n","Uninstalling openai-1.61.1:\n","  Would remove:\n","    /usr/local/bin/openai\n","    /usr/local/lib/python3.11/dist-packages/openai-1.61.1.dist-info/*\n","    /usr/local/lib/python3.11/dist-packages/openai/*\n","Proceed (Y/n)? Y\n","  Successfully uninstalled openai-1.61.1\n"]}]},{"cell_type":"code","source":["!pip uninstall -y openai\n","!pip install openai>=1.0.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"umygU4wve8r0","executionInfo":{"status":"ok","timestamp":1739351731412,"user_tz":-60,"elapsed":3720,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"202d4756-e6c7-45cb-c832-525e4fb6c194"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: openai 1.61.1\n","Uninstalling openai-1.61.1:\n","  Successfully uninstalled openai-1.61.1\n"]}]},{"cell_type":"code","source":["#!pip uninstall -y openai\n","!pip install openai>=1.0.0\n","!python -c \"import openai; print(openai.__version__)\"  # Should print 1.x.x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lqjl4jP7_R7t","executionInfo":{"status":"ok","timestamp":1739278345567,"user_tz":-60,"elapsed":3643,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"426e3c3b-dd3e-4520-a067-60e9af424082"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["1.61.1\n"]}]},{"cell_type":"markdown","metadata":{"id":"sX-obQ9KBkXZ"},"source":["## Connect to OpenAI with an API key"]},{"cell_type":"code","source":["import os\n","import openai"],"metadata":{"id":"rZdz89fScAR7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import userdata\n","#userdata.get('OPENAI_API_KEY')\n"],"metadata":{"id":"gaQuw2A9BSvb","executionInfo":{"status":"ok","timestamp":1739278355382,"user_tz":-60,"elapsed":7,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Retrieve the API key\n","api_key = userdata.get(\"OPENAI_API_KEY\")\n","\n","# Verify if the key exists (good practice)\n","if api_key is None:\n","    raise ValueError(\"API key not found in environment variables\")\n","\n","print(\"API key successfully loaded\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9wGD1XIodUgT","executionInfo":{"status":"ok","timestamp":1738916298717,"user_tz":-60,"elapsed":698,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"ddcedc92-07b3-4c44-8f4c-6e4e5cc59af9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["API key successfully loaded\n"]}]},{"cell_type":"code","source":["# This will retrieve the key you configured in Colab's secrets\n","api_key = userdata.get('OPENAI_API_KEY')"],"metadata":{"id":"evqZmL5YhEIk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create an OpenAI client (New API format)\n","from openai import OpenAI  # We'll use synchronous version instead\n","\n","# Instead of AsyncOpenAI, we'll modify our code to use the synchronous version:\n","client = OpenAI(api_key=api_key)"],"metadata":{"id":"o3fsR0bCmXa5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Example OpenAI API request\n","response = client.chat.completions.create(\n","    model=\"gpt-3.5-turbo\",\n","    messages=[{\"role\": \"user\", \"content\": \"Tell me a joke!\"}]\n",")\n","\n","print(response.choices[0].message.content)\n","print(response.usage.total_tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yBzGPkvFgr2w","executionInfo":{"status":"ok","timestamp":1738919275914,"user_tz":-60,"elapsed":738,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"fe35311e-4649-4b4f-9b4d-36d39bad57db"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Why was the math book sad?\n","\n","Because it had too many problems.\n","27\n"]}]},{"cell_type":"markdown","metadata":{"id":"9_PrDfecBkXb"},"source":["# Translate with Pipeline Programming"]},{"cell_type":"markdown","source":["#####           Lower Temperature (closer to 0): The model will be more deterministic and predictable, choosing the words with the highest probability. It will tend to produce more repetitive and safe outputs. This is often preferred for tasks where accuracy and consistency are paramount, such as translation or factual question answering. Higher Temperature (closer to 1 or above): The model becomes more creative and unpredictable. It's more likely to sample from less probable words, leading to more diverse and unexpected outputs. This is suitable for tasks where creativity and novelty are desired, such as creative writing or brainstorming.\n"],"metadata":{"id":"lq-c_WA97e72"}},{"cell_type":"markdown","source":["#### Code without asynchronous function - testing the translation on the first n sentences"],"metadata":{"id":"4FhHiV9ewezJ"}},{"cell_type":"code","source":["# Code is working, it fecthes first n sentences\n","\n","from typing import Iterator, List, Dict, Any, Tuple, Optional\n","import numpy as np\n","import json\n","import os\n","from pathlib import Path\n","from datetime import datetime\n","from openai import OpenAI\n","from openai.types.chat import ChatCompletion\n","import time\n","\n","class TranslationManager:\n","    def __init__(self, api_key: str, cache_dir: str = \"translation_cache\", checkpoint_dir: str = \"checkpoints\"):\n","        self.client = OpenAI(api_key=api_key)\n","        self.cache_dir = Path(cache_dir)\n","        self.checkpoint_dir = Path(checkpoint_dir)\n","        self.cache_dir.mkdir(exist_ok=True)\n","        self.checkpoint_dir.mkdir(exist_ok=True)\n","        self.batch_cache = {}\n","        self.current_cache_size = 0\n","        self.max_cache_size = 1000\n","\n","    def _get_cache_file(self, batch_id: str) -> Path:\n","        return self.cache_dir / f\"cache_{batch_id}.json\"\n","\n","    def get_checkpoint_file(self, dataset_name: str) -> Path:\n","        return self.checkpoint_dir / f\"{dataset_name}_checkpoint.json\"\n","\n","    def _save_batch_cache(self, batch_id: str):\n","        cache_file = self._get_cache_file(batch_id)\n","        with open(cache_file, 'w', encoding='utf-8') as f:\n","            json.dump(self.batch_cache, f, ensure_ascii=False, indent=2)\n","        self.batch_cache = {}\n","        self.current_cache_size = 0\n","\n","    def _load_cache(self, batch_id: str) -> Dict:\n","        cache_file = self._get_cache_file(batch_id)\n","        if cache_file.exists():\n","            with open(cache_file, 'r', encoding='utf-8') as f:\n","                return json.load(f)\n","        return {}\n","\n","    def save_checkpoint(self, dataset_name: str, batch_num: int, translations_count: int):\n","        checkpoint_data = {\n","            \"last_batch\": batch_num,\n","            \"translations_count\": translations_count,\n","            \"timestamp\": datetime.now().isoformat()\n","        }\n","        checkpoint_file = self.get_checkpoint_file(dataset_name)\n","        with open(checkpoint_file, 'w', encoding='utf-8') as f:\n","            json.dump(checkpoint_data, f, indent=2)\n","\n","    def load_checkpoint(self, dataset_name: str) -> Dict:\n","        checkpoint_file = self.get_checkpoint_file(dataset_name)\n","        if checkpoint_file.exists():\n","            with open(checkpoint_file, 'r', encoding='utf-8') as f:\n","                return json.load(f)\n","        return {\"last_batch\": -1, \"translations_count\": 0}\n","\n","    def translate_batch(self, texts: List[str], batch_id: str) -> Tuple[List[str], Optional[ChatCompletion]]:\n","        if not texts:\n","            return [], None\n","\n","        try:\n","            cache = self._load_cache(batch_id)\n","            translations = []\n","            uncached_texts = []\n","            uncached_indices = []\n","\n","            for i, text in enumerate(texts):\n","                text = text.strip()\n","                if not text:  # Skip empty strings\n","                    translations.append(\"\")\n","                    continue\n","                if text in cache:\n","                    translations.append(cache[text])\n","                else:\n","                    uncached_texts.append(text)\n","                    uncached_indices.append(i)\n","\n","            if uncached_texts:\n","                try:\n","                    response = self.client.chat.completions.create(\n","                        model=\"gpt-3.5-turbo\",\n","                        messages=[\n","                            {\"role\": \"system\", \"content\": \"Translate the following English texts to Slovenian:\"},\n","                            {\"role\": \"user\", \"content\": \"\\n-\\n\".join(uncached_texts)}\n","                        ],\n","                        temperature=0.3\n","                    )\n","\n","                    new_translations = [choice.message.content for choice in response.choices]\n","\n","                    # Ensure we have the same number of translations as input texts\n","                    if len(new_translations) != len(uncached_texts):\n","                        new_translations = new_translations[:len(uncached_texts)]\n","                        if len(new_translations) < len(uncached_texts):\n","                            new_translations.extend([\"\"] * (len(uncached_texts) - len(new_translations)))\n","\n","                    for text, trans in zip(uncached_texts, new_translations):\n","                        self.batch_cache[text] = trans\n","                        self.current_cache_size += 1\n","\n","                    for idx, trans in zip(uncached_indices, new_translations):\n","                        translations.insert(idx, trans)\n","\n","                    if self.current_cache_size >= self.max_cache_size:\n","                        self._save_batch_cache(batch_id)\n","\n","                    return translations, response\n","\n","                except Exception as e:\n","                    print(f\"Error in API call: {str(e)}\")\n","                    return [f\"ERROR: {str(e)}\"] * len(texts), None\n","\n","            return translations, None\n","\n","        except Exception as e:\n","            print(f\"Error in batch processing: {str(e)}\")\n","            return [f\"ERROR: {str(e)}\"] * len(texts), None\n","\n","class DatasetIterator:\n","    def __init__(self, file_path: str, batch_size: int, start_line: int = 0, max_sentences: int = 100):\n","        self.file_path = file_path\n","        self.batch_size = batch_size\n","        self.max_sentences = max_sentences\n","        self.total_lines = min(self._count_lines(), max_sentences)  # Limit total lines\n","        self.start_line = min(start_line, max(0, self.total_lines - 1))\n","\n","    def _count_lines(self) -> int:\n","        try:\n","            with open(self.file_path, \"r\", encoding=\"utf-8\") as f:\n","                return sum(1 for _ in f)\n","        except Exception as e:\n","            print(f\"Error counting lines: {str(e)}\")\n","            return 0\n","\n","    def __iter__(self) -> Iterator[List[str]]:\n","        current_batch = []\n","        processed_lines = 0\n","\n","        try:\n","            with open(self.file_path, \"r\", encoding=\"utf-8\") as f:\n","                # Skip to start line\n","                for _ in range(self.start_line):\n","                    next(f, None)\n","\n","                for line in f:\n","                    if processed_lines >= self.max_sentences:\n","                        break\n","\n","                    line = line.strip()\n","                    if line:  # Only add non-empty lines\n","                        current_batch.append(line)\n","                        processed_lines += 1\n","\n","                        if len(current_batch) == self.batch_size:\n","                            yield current_batch\n","                            current_batch = []\n","\n","                    if processed_lines >= self.max_sentences:\n","                        break\n","\n","                if current_batch:  # Don't forget last partial batch\n","                    yield current_batch\n","\n","        except Exception as e:\n","            print(f\"Error reading file: {str(e)}\")\n","            if current_batch:  # Yield any remaining batch on error\n","                yield current_batch\n","\n","class CostTracker:\n","    def __init__(self):\n","        self.requests = 0\n","        self.total_tokens = 0\n","        self.price_per_1k_tokens = 0.002\n","\n","    def update(self, response: ChatCompletion):\n","        self.requests += 1\n","        self.total_tokens += response.usage.completion_tokens + response.usage.prompt_tokens\n","\n","    def get_cost(self) -> float:\n","        return (self.total_tokens / 1000) * self.price_per_1k_tokens\n","\n","    def report(self) -> str:\n","        return f\"\"\"\n","        API Calls: {self.requests}\n","        Total Tokens: {self.total_tokens}\n","        Estimated Cost: ${self.get_cost():.2f}\n","        \"\"\"\n","\n","def save_pairs(originals: List[str], translations: List[str], dataset_name: str, mode: str = \"a\"):\n","    base_path = Path(\"/content/drive/My Drive/Colab Notebooks\")\n","\n","    for filename, data in [\n","        (f\"{dataset_name}_originals_GPT3.5.txt\", originals),\n","        (f\"{dataset_name}_translations_GPT3.5.txt\", translations),\n","    ]:\n","        try:\n","            with open(base_path / filename, mode, encoding=\"utf-8\") as f:\n","                for item in data:\n","                    f.write(f\"{item}\\n\")\n","        except Exception as e:\n","            print(f\"Error saving to {filename}: {str(e)}\")\n","\n","    try:\n","        with open(base_path / f\"{dataset_name}_aligned_pairs_GPT3.5.txt\", mode, encoding=\"utf-8\") as f:\n","            for orig, trans in zip(originals, translations):\n","                f.write(f\"Original: {orig}\\nTranslation: {trans}\\n---\\n\")\n","    except Exception as e:\n","        print(f\"Error saving aligned pairs: {str(e)}\")\n","\n","def process_dataset(\n","    input_file: str,\n","    dataset_name: str,\n","    api_key: str,\n","    batch_size: int = 32,\n","    checkpoint_interval: int = 5,\n","    max_sentences: int = 10949 # Parameter to limit number of sentences in the dataset - write manually since this code is working okay\n","):\n","    translator = TranslationManager(api_key=api_key)\n","\n","    # Load checkpoint if exists\n","    checkpoint = translator.load_checkpoint(dataset_name)\n","    start_batch = checkpoint[\"last_batch\"] + 1\n","    translations_count = checkpoint[\"translations_count\"]\n","\n","    # Calculate starting line\n","    start_line = start_batch * batch_size\n","\n","    # Create iterator with sentence limit\n","    dataset_iterator = DatasetIterator(\n","        file_path=input_file,\n","        batch_size=batch_size,\n","        start_line=start_line,\n","        max_sentences=max_sentences\n","    )\n","\n","    cost_tracker = CostTracker()\n","    total_batches = max(1, min(dataset_iterator.total_lines, max_sentences) // batch_size)\n","\n","    print(f\"Starting from batch {start_batch}, line {start_line}\")\n","    print(f\"Will process up to {max_sentences} sentences\")\n","    print(f\"Total lines to process: {min(dataset_iterator.total_lines, max_sentences)}\")\n","\n","    for batch_num, batch in enumerate(dataset_iterator, start=start_batch):\n","        try:\n","            batch_id = f\"{dataset_name}_{batch_num}\"\n","            translations, response = translator.translate_batch(batch, batch_id)\n","\n","            if response is not None:\n","                cost_tracker.update(response)\n","\n","            save_pairs(batch, translations, dataset_name, mode=\"a\")\n","            translations_count += len(translations)\n","\n","            if batch_num % checkpoint_interval == 0:\n","                translator.save_checkpoint(dataset_name, batch_num, translations_count)\n","                print(f\"Checkpoint saved at batch {batch_num}\")\n","\n","            print(f\"Processed batch {batch_num}/{total_batches} ({len(batch)} items)\")\n","            if batch_num % 10 == 0:\n","                print(cost_tracker.report())\n","\n","            # Add a small delay to avoid rate limiting\n","            time.sleep(0.5)\n","\n","        except Exception as e:\n","            print(f\"Error processing batch {batch_num}: {str(e)}\")\n","            translator.save_checkpoint(dataset_name, batch_num-1, translations_count)\n","            time.sleep(1)  # Longer delay on error\n","            continue\n","\n","    # Final checkpoint and report\n","    translator.save_checkpoint(dataset_name, total_batches-1, translations_count)\n","    print(\"\\nFinal Statistics:\")\n","    print(cost_tracker.report())\n","    print(f\"Total translations: {translations_count}\")"],"metadata":{"id":"Pj2w8X4eDJnm","executionInfo":{"status":"ok","timestamp":1739284526888,"user_tz":-60,"elapsed":102,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["# try\n","\n","if __name__ == \"__main__\":\n","    input_file = \"/content/drive/My Drive/Colab Notebooks/msr_paraphrase_data.txt\"\n","    dataset_name = \"msr_paraphrase_test\"  # Using test suffix to distinguish from full runs\n","    max_sentences = 10949  # Parameter to limit number of sentences in the dataset - write manually since this code is working okay\n","\n","    try:\n","        from google.colab import userdata\n","        api_key = userdata.get('OPENAI_API_KEY')\n","    except ImportError:\n","        api_key = os.getenv('OPENAI_API_KEY')\n","\n","    if not api_key:\n","        raise ValueError(\"API key not found. Please set the OPENAI_API_KEY in Colab secrets or environment variables.\")\n","\n","    process_dataset(\n","        input_file=input_file,\n","        dataset_name=dataset_name,\n","        api_key=api_key,\n","        batch_size=32,  # Keeping original batch size\n","        checkpoint_interval=10,  # Frequent checkpoints for testing\n","        max_sentences=10949  # Parameter to limit number of sentences in the dataset - write manually since this code is working okay\n","    )"],"metadata":{"id":"gLFdSOLe2D1F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Code with asynchronous function - not working"],"metadata":{"id":"jCSpfR0I_0zc"}},{"cell_type":"code","source":["# Throving an error\n","\n","from typing import Iterator, List, Dict, Any, Tuple, Optional\n","from openai import OpenAI\n","import json\n","from pathlib import Path\n","from datetime import datetime\n","import time\n","import os\n","\n","class TranslationManager:\n","    def __init__(self, api_key: str, cache_dir: str = \"translation_cache\", checkpoint_dir: str = \"checkpoints\"):\n","        #self.api_key = api_key  # Store the API key\n","        self.client = OpenAI(api_key=api_key)  # Initialize client properly\n","        self.cache_dir = Path(cache_dir)\n","        self.checkpoint_dir = Path(checkpoint_dir)\n","        self.cache_dir.mkdir(exist_ok=True)\n","        self.checkpoint_dir.mkdir(exist_ok=True)\n","        self.batch_cache = {}\n","        self.current_cache_size = 0\n","        self.max_cache_size = 1000\n","\n","    def translate_batch(self, texts: List[str], batch_id: str) -> Tuple[List[str], Optional[ChatCompletion]]:\n","        if not texts:\n","            return [], None\n","\n","        try:\n","            cache = self._load_cache(batch_id)\n","            translations = []\n","            uncached_texts = []\n","            uncached_indices = []\n","\n","            for i, text in enumerate(texts):\n","                text = text.strip()\n","                if not text:  # Skip empty strings\n","                    translations.append(\"\")\n","                    continue\n","                if text in cache:\n","                    translations.append(cache[text])\n","                else:\n","                    uncached_texts.append(text)\n","                    uncached_indices.append(i)\n","\n","            if uncached_texts:\n","                try:\n","                    response = self.client.chat.completions.create(\n","                        model=\"gpt-3.5-turbo\",\n","                        messages=[\n","                            {\"role\": \"system\", \"content\": \"Translate the following English texts to Slovenian:\"},\n","                            {\"role\": \"user\", \"content\": \"\\n---\\n\".join(uncached_texts)}\n","                        ],\n","                        temperature=0.3\n","                    )\n","\n","                    # Get translations from response\n","                    new_translations = [choice.message.content for choice in response.choices]\n","\n","                    # Ensure we have the same number of translations as input texts\n","                    if len(new_translations) != len(uncached_texts):\n","                        new_translations = new_translations[:len(uncached_texts)]\n","                        if len(new_translations) < len(uncached_texts):\n","                            new_translations.extend([\"\"] * (len(uncached_texts) - len(new_translations)))\n","\n","                    # Update cache\n","                    for text, trans in zip(uncached_texts, new_translations):\n","                        self.batch_cache[text] = trans\n","                        self.current_cache_size += 1\n","\n","                    # Insert translations at correct positions\n","                    for idx, trans in zip(uncached_indices, new_translations):\n","                        translations.insert(idx, trans)\n","\n","                    if self.current_cache_size >= self.max_cache_size:\n","                        self._save_batch_cache(batch_id)\n","\n","                    return translations, response\n","\n","                except Exception as e:\n","                    print(f\"Error in API call: {str(e)}\")\n","                    return [f\"ERROR: {str(e)}\"] * len(texts), None\n","\n","            return translations, None\n","\n","        except Exception as e:\n","            print(f\"Error in batch processing: {str(e)}\")\n","            return [f\"ERROR: {str(e)}\"] * len(texts), None\n","\n","    def _get_cache_file(self, batch_id: str) -> Path:\n","        return self.cache_dir / f\"cache_{batch_id}.json\"\n","\n","    def get_checkpoint_file(self, dataset_name: str) -> Path:\n","        return self.checkpoint_dir / f\"{dataset_name}_checkpoint.json\"\n","\n","    def _save_batch_cache(self, batch_id: str):\n","        cache_file = self._get_cache_file(batch_id)\n","        with open(cache_file, 'w', encoding='utf-8') as f:\n","            json.dump(self.batch_cache, f, ensure_ascii=False, indent=2)\n","        self.batch_cache = {}\n","        self.current_cache_size = 0\n","\n","    def _load_cache(self, batch_id: str) -> Dict:\n","        cache_file = self._get_cache_file(batch_id)\n","        if cache_file.exists():\n","            with open(cache_file, 'r', encoding='utf-8') as f:\n","                return json.load(f)\n","        return {}\n","\n","    def save_checkpoint(self, dataset_name: str, batch_num: int, translations_count: int):\n","        checkpoint_data = {\n","            \"last_batch\": batch_num,\n","            \"translations_count\": translations_count,\n","            \"timestamp\": datetime.now().isoformat()\n","        }\n","        checkpoint_file = self.get_checkpoint_file(dataset_name)\n","        with open(checkpoint_file, 'w', encoding='utf-8') as f:\n","            json.dump(checkpoint_data, f, indent=2)\n","\n","    def load_checkpoint(self, dataset_name: str) -> Dict:\n","        checkpoint_file = self.get_checkpoint_file(dataset_name)\n","        if checkpoint_file.exists():\n","            with open(checkpoint_file, 'r', encoding='utf-8') as f:\n","                return json.load(f)\n","        return {\"last_batch\": -1, \"translations_count\": 0}\n","\n","    def translate_batch(self, texts: List[str], batch_id: str) -> Tuple[List[str], Optional[ChatCompletion]]:\n","        if not texts:\n","            return [], None\n","\n","        try:\n","            cache = self._load_cache(batch_id)\n","            translations = []\n","            uncached_texts = []\n","            uncached_indices = []\n","\n","            for i, text in enumerate(texts):\n","                text = text.strip()\n","                if not text:  # Skip empty strings\n","                    translations.append(\"\")\n","                    continue\n","                if text in cache:\n","                    translations.append(cache[text])\n","                else:\n","                    uncached_texts.append(text)\n","                    uncached_indices.append(i)\n","\n","            if uncached_texts:\n","                try:\n","                    response = self.client.chat.completions.create(\n","                        model=\"gpt-3.5-turbo\",\n","                        messages=[\n","                            {\"role\": \"system\", \"content\": \"Translate the following English texts to Slovenian:\"},\n","                            {\"role\": \"user\", \"content\": \"\\n---\\n\".join(uncached_texts)}\n","                        ],\n","                        temperature=0.3\n","                    )\n","\n","                    # new_translations = response.choices[0].message.content.split(\"\\n---\\n\") # for version 0.28\n","                    new_translations = [choice.message.content for choice in response.choices]\n","\n","                    # Ensure we have the same number of translations as input texts\n","                    if len(new_translations) != len(uncached_texts):\n","                        new_translations = new_translations[:len(uncached_texts)]\n","                        if len(new_translations) < len(uncached_texts):\n","                            new_translations.extend([\"\"] * (len(uncached_texts) - len(new_translations)))\n","\n","                    for text, trans in zip(uncached_texts, new_translations):\n","                        self.batch_cache[text] = trans\n","                        self.current_cache_size += 1\n","\n","                    for idx, trans in zip(uncached_indices, new_translations):\n","                        translations.insert(idx, trans)\n","\n","                    if self.current_cache_size >= self.max_cache_size:\n","                        self._save_batch_cache(batch_id)\n","\n","                    return translations, response\n","\n","                except Exception as e:\n","                    print(f\"Error in API call: {str(e)}\")\n","                    return [f\"ERROR: {str(e)}\"] * len(texts), None\n","\n","            return translations, None\n","\n","        except Exception as e:\n","            print(f\"Error in batch processing: {str(e)}\")\n","            return [f\"ERROR: {str(e)}\"] * len(texts), None\n","\n","class DatasetIterator:\n","    def __init__(self, file_path: str, batch_size: int, start_line: int = 0, text_column_index: int = 1):\n","        self.file_path = file_path\n","        self.batch_size = batch_size\n","        self.text_column_index = text_column_index  # Default to second column (index 1)\n","        self.total_lines = self._count_lines()\n","        # Add 1 to account for header\n","        self.start_line = min(start_line + 1, max(0, self.total_lines - 1))\n","\n","    def _count_lines(self) -> int:\n","        try:\n","            with open(self.file_path, \"r\", encoding=\"utf-8\") as f:\n","                return sum(1 for _ in f)\n","        except Exception as e:\n","            print(f\"Error counting lines: {str(e)}\")\n","            return 0\n","\n","    def __iter__(self) -> Iterator[List[str]]:\n","        current_batch = []\n","        current_line = 0\n","\n","        try:\n","            with open(self.file_path, \"r\", encoding=\"utf-8\") as f:\n","                # Skip header\n","                header = next(f, None)\n","                if not header:\n","                    raise ValueError(\"Empty file or no header found\")\n","\n","                # Skip to start line (accounting for already skipped header)\n","                for _ in range(self.start_line - 1):\n","                    next(f, None)\n","                    current_line += 1\n","\n","                for line in f:\n","                    try:\n","                        columns = line.strip().split('\\t')\n","                        if len(columns) > self.text_column_index:\n","                            text = columns[self.text_column_index].strip()\n","                            if text:  # Only add non-empty texts\n","                                current_batch.append(text)\n","                                if len(current_batch) == self.batch_size:\n","                                    yield current_batch\n","                                    current_batch = []\n","                    except Exception as e:\n","                        print(f\"Error processing line: {line.strip()}\")\n","                        print(f\"Error details: {str(e)}\")\n","                        continue\n","\n","                if current_batch:  # Don't forget last partial batch\n","                    yield current_batch\n","\n","        except Exception as e:\n","            print(f\"Error reading file: {str(e)}\")\n","            if current_batch:  # Yield any remaining batch on error\n","                yield current_batch\n","\n","class CostTracker:\n","    def __init__(self):\n","        self.requests = 0\n","        self.total_tokens = 0\n","        self.price_per_1k_tokens = 0.002\n","\n","    def update(self, response: ChatCompletion):\n","        self.requests += 1\n","        self.total_tokens += response.usage.completion_tokens + response.usage.prompt_tokens\n","\n","    def get_cost(self) -> float:\n","        return (self.total_tokens / 1000) * self.price_per_1k_tokens\n","\n","    def report(self) -> str:\n","        return f\"\"\"\n","        API Calls: {self.requests}\n","        Total Tokens: {self.total_tokens}\n","        Estimated Cost: ${self.get_cost():.2f}\n","        \"\"\"\n","\n","def save_pairs(originals: List[str], translations: List[str], dataset_name: str, mode: str = \"a\"):\n","    base_path = Path(\"/content/drive/My Drive/Colab Notebooks\")\n","\n","    for filename, data in [\n","        (f\"{dataset_name}_originals_GPT3.5.txt\", originals),\n","        (f\"{dataset_name}_translations_GPT3.5.txt\", translations),\n","    ]:\n","        try:\n","            with open(base_path / filename, mode, encoding=\"utf-8\") as f:\n","                for item in data:\n","                    f.write(f\"{item}\\n\")\n","        except Exception as e:\n","            print(f\"Error saving to {filename}: {str(e)}\")\n","\n","    try:\n","        with open(base_path / f\"{dataset_name}_aligned_pairs_GPT3.5.txt\", mode, encoding=\"utf-8\") as f:\n","            for orig, trans in zip(originals, translations):\n","                f.write(f\"Original: {orig}\\nTranslation: {trans}\\n---\\n\")\n","    except Exception as e:\n","        print(f\"Error saving aligned pairs: {str(e)}\")\n","\n","def process_dataset(\n","    input_file: str,\n","    dataset_name: str,\n","    api_key: str,\n","    batch_size: int = 32,\n","    checkpoint_interval: int = 5\n","):\n","    translator = TranslationManager(api_key=api_key)\n","\n","    # Load checkpoint if exists\n","    checkpoint = translator.load_checkpoint(dataset_name)\n","    start_batch = checkpoint[\"last_batch\"] + 1\n","    translations_count = checkpoint[\"translations_count\"]\n","\n","    # Calculate starting line\n","    start_line = start_batch * batch_size\n","\n","    dataset_iterator = DatasetIterator(input_file, batch_size, start_line)\n","    cost_tracker = CostTracker()\n","\n","    total_batches = max(1, dataset_iterator.total_lines // batch_size)\n","\n","    print(f\"Starting from batch {start_batch}, line {start_line}\")\n","    print(f\"Total lines in file: {dataset_iterator.total_lines}\")\n","\n","    for batch_num, batch in enumerate(dataset_iterator, start=start_batch):\n","        try:\n","            batch_id = f\"{dataset_name}_{batch_num}\"\n","            translations, response = translator.translate_batch(batch, batch_id)\n","\n","            if response is not None:\n","                cost_tracker.update(response)\n","\n","            # Only save if we got valid translations\n","            if translations:\n","                save_pairs(batch, translations, dataset_name, mode=\"a\")\n","                translations_count += len(translations)\n","\n","            if batch_num % checkpoint_interval == 0:\n","                translator.save_checkpoint(dataset_name, batch_num, translations_count)\n","                print(f\"Checkpoint saved at batch {batch_num}\")\n","\n","            print(f\"Processed batch {batch_num}/{total_batches} ({len(batch)} items)\")\n","            if batch_num % 10 == 0:\n","                print(cost_tracker.report())\n","\n","            # Add a small delay to avoid rate limiting\n","            time.sleep(0.5)\n","\n","        except Exception as e:\n","            print(f\"Error processing batch {batch_num}: {str(e)}\")\n","            translator.save_checkpoint(dataset_name, batch_num-1, translations_count)\n","            time.sleep(5)  # Longer delay on error\n","            continue\n","\n","    # Final checkpoint and report\n","    translator.save_checkpoint(dataset_name, total_batches-1, translations_count)\n","    print(\"\\nFinal Statistics:\")\n","    print(cost_tracker.report())\n","    print(f\"Total translations: {translations_count}\")"],"metadata":{"id":"k5De-X5UnN-8","executionInfo":{"status":"ok","timestamp":1739284139123,"user_tz":-60,"elapsed":36,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BCcetVRwBkXc"},"source":["## **msr_paraphrase_data.txt**"]},{"cell_type":"markdown","metadata":{"id":"X7Li0568BkXc"},"source":["#### Checking the size of the file"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1737978986468,"user_tz":-60,"elapsed":4870,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"0e863ca1-6db2-418a-a059-f16b50fe1efc","id":"HVE4UDXYBkXc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","File found!\n","The file has 10949 rows.\n"]}],"source":["# Check the size of the file\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","file_path = \"/content/drive/My Drive/Colab Notebooks/msr_paraphrase_data.txt\"\n","\n","# Check if file exists\n","import os\n","if os.path.exists(file_path):\n","    print(\"File found!\")\n","else:\n","    print(\"File not found. Check the path!\")\n","\n","file_path = \"/content/drive/My Drive/Colab Notebooks/msr_paraphrase_data.txt\"\n","\n","# Count lines in the file\n","with open(file_path, \"r\", encoding=\"utf-8\") as file:\n","    line_count = sum(1 for line in file if line.strip())  # Excludes empty lines\n","\n","print(f\"The file has {line_count} rows.\")\n"]},{"cell_type":"markdown","source":["### MSR translation\n","\n","Final Statistics:\n","\n","        API Calls: 342\n","        Total Tokens: 1248224\n","        Estimated Cost: $2.50\n","        Time: 52min\n","        \n","Total translations: 10927"],"metadata":{"id":"GOjH7N941z9z"}},{"cell_type":"code","source":["# Successful\n","\n","if __name__ == \"__main__\":\n","    input_file = \"/content/drive/My Drive/Colab Notebooks/msr_paraphrase_data.txt\"\n","    dataset_name = \"msr_paraphrase_test\"  # Using test suffix to distinguish from full runs\n","    max_sentences = 10949  # Limit to first 100 sentences\n","\n","    try:\n","        from google.colab import userdata\n","        api_key = userdata.get('OPENAI_API_KEY')\n","    except ImportError:\n","        api_key = os.getenv('OPENAI_API_KEY')\n","\n","    if not api_key:\n","        raise ValueError(\"API key not found. Please set the OPENAI_API_KEY in Colab secrets or environment variables.\")\n","\n","    process_dataset(\n","        input_file=input_file,\n","        dataset_name=dataset_name,\n","        api_key=api_key,\n","        batch_size=32,  # Keeping original batch size\n","        checkpoint_interval=10,  # Frequent checkpoints for testing\n","        max_sentences=10949  # Parameter to limit number of sentences\n","    )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_5tHrPhDDvMM","executionInfo":{"status":"ok","timestamp":1739291199654,"user_tz":-60,"elapsed":3176968,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"e8e7c91a-552e-45f7-fa54-792b510426ae"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting from batch 1, line 32\n","Will process up to 10949 sentences\n","Total lines to process: 10949\n","Processed batch 1/342 (32 items)\n","Processed batch 2/342 (32 items)\n","Processed batch 3/342 (32 items)\n","Processed batch 4/342 (32 items)\n","Processed batch 5/342 (32 items)\n","Processed batch 6/342 (32 items)\n","Processed batch 7/342 (32 items)\n","Processed batch 8/342 (32 items)\n","Processed batch 9/342 (32 items)\n","Checkpoint saved at batch 10\n","Processed batch 10/342 (32 items)\n","\n","        API Calls: 10\n","        Total Tokens: 37928\n","        Estimated Cost: $0.08\n","        \n","Processed batch 11/342 (32 items)\n","Processed batch 12/342 (32 items)\n","Processed batch 13/342 (32 items)\n","Processed batch 14/342 (32 items)\n","Processed batch 15/342 (32 items)\n","Processed batch 16/342 (32 items)\n","Processed batch 17/342 (32 items)\n","Processed batch 18/342 (32 items)\n","Processed batch 19/342 (32 items)\n","Checkpoint saved at batch 20\n","Processed batch 20/342 (32 items)\n","\n","        API Calls: 20\n","        Total Tokens: 73322\n","        Estimated Cost: $0.15\n","        \n","Processed batch 21/342 (32 items)\n","Processed batch 22/342 (32 items)\n","Processed batch 23/342 (32 items)\n","Processed batch 24/342 (32 items)\n","Processed batch 25/342 (32 items)\n","Processed batch 26/342 (32 items)\n","Processed batch 27/342 (32 items)\n","Processed batch 28/342 (32 items)\n","Processed batch 29/342 (32 items)\n","Checkpoint saved at batch 30\n","Processed batch 30/342 (32 items)\n","\n","        API Calls: 30\n","        Total Tokens: 109329\n","        Estimated Cost: $0.22\n","        \n","Processed batch 31/342 (32 items)\n","Processed batch 32/342 (32 items)\n","Processed batch 33/342 (32 items)\n","Processed batch 34/342 (32 items)\n","Processed batch 35/342 (32 items)\n","Processed batch 36/342 (32 items)\n","Processed batch 37/342 (32 items)\n","Processed batch 38/342 (32 items)\n","Processed batch 39/342 (32 items)\n","Checkpoint saved at batch 40\n","Processed batch 40/342 (32 items)\n","\n","        API Calls: 40\n","        Total Tokens: 146025\n","        Estimated Cost: $0.29\n","        \n","Processed batch 41/342 (32 items)\n","Processed batch 42/342 (32 items)\n","Processed batch 43/342 (32 items)\n","Processed batch 44/342 (32 items)\n","Processed batch 45/342 (32 items)\n","Processed batch 46/342 (32 items)\n","Processed batch 47/342 (32 items)\n","Processed batch 48/342 (32 items)\n","Processed batch 49/342 (32 items)\n","Checkpoint saved at batch 50\n","Processed batch 50/342 (32 items)\n","\n","        API Calls: 50\n","        Total Tokens: 182819\n","        Estimated Cost: $0.37\n","        \n","Processed batch 51/342 (32 items)\n","Processed batch 52/342 (32 items)\n","Processed batch 53/342 (32 items)\n","Processed batch 54/342 (32 items)\n","Processed batch 55/342 (32 items)\n","Processed batch 56/342 (32 items)\n","Processed batch 57/342 (32 items)\n","Processed batch 58/342 (32 items)\n","Processed batch 59/342 (32 items)\n","Checkpoint saved at batch 60\n","Processed batch 60/342 (32 items)\n","\n","        API Calls: 60\n","        Total Tokens: 217586\n","        Estimated Cost: $0.44\n","        \n","Processed batch 61/342 (32 items)\n","Processed batch 62/342 (32 items)\n","Processed batch 63/342 (32 items)\n","Processed batch 64/342 (32 items)\n","Processed batch 65/342 (32 items)\n","Processed batch 66/342 (32 items)\n","Processed batch 67/342 (32 items)\n","Processed batch 68/342 (32 items)\n","Processed batch 69/342 (32 items)\n","Checkpoint saved at batch 70\n","Processed batch 70/342 (32 items)\n","\n","        API Calls: 70\n","        Total Tokens: 248324\n","        Estimated Cost: $0.50\n","        \n","Processed batch 71/342 (32 items)\n","Processed batch 72/342 (32 items)\n","Processed batch 73/342 (32 items)\n","Processed batch 74/342 (32 items)\n","Processed batch 75/342 (32 items)\n","Processed batch 76/342 (32 items)\n","Processed batch 77/342 (32 items)\n","Processed batch 78/342 (32 items)\n","Processed batch 79/342 (32 items)\n","Checkpoint saved at batch 80\n","Processed batch 80/342 (32 items)\n","\n","        API Calls: 80\n","        Total Tokens: 284445\n","        Estimated Cost: $0.57\n","        \n","Processed batch 81/342 (32 items)\n","Processed batch 82/342 (32 items)\n","Processed batch 83/342 (32 items)\n","Processed batch 84/342 (32 items)\n","Processed batch 85/342 (32 items)\n","Processed batch 86/342 (32 items)\n","Processed batch 87/342 (32 items)\n","Processed batch 88/342 (32 items)\n","Processed batch 89/342 (32 items)\n","Checkpoint saved at batch 90\n","Processed batch 90/342 (32 items)\n","\n","        API Calls: 90\n","        Total Tokens: 320208\n","        Estimated Cost: $0.64\n","        \n","Processed batch 91/342 (32 items)\n","Processed batch 92/342 (32 items)\n","Processed batch 93/342 (32 items)\n","Processed batch 94/342 (32 items)\n","Processed batch 95/342 (32 items)\n","Processed batch 96/342 (32 items)\n","Processed batch 97/342 (32 items)\n","Processed batch 98/342 (32 items)\n","Processed batch 99/342 (32 items)\n","Checkpoint saved at batch 100\n","Processed batch 100/342 (32 items)\n","\n","        API Calls: 100\n","        Total Tokens: 357002\n","        Estimated Cost: $0.71\n","        \n","Processed batch 101/342 (32 items)\n","Processed batch 102/342 (32 items)\n","Processed batch 103/342 (32 items)\n","Processed batch 104/342 (32 items)\n","Processed batch 105/342 (32 items)\n","Processed batch 106/342 (32 items)\n","Processed batch 107/342 (32 items)\n","Processed batch 108/342 (32 items)\n","Processed batch 109/342 (32 items)\n","Checkpoint saved at batch 110\n","Processed batch 110/342 (32 items)\n","\n","        API Calls: 110\n","        Total Tokens: 393340\n","        Estimated Cost: $0.79\n","        \n","Processed batch 111/342 (32 items)\n","Processed batch 112/342 (32 items)\n","Processed batch 113/342 (32 items)\n","Processed batch 114/342 (32 items)\n","Processed batch 115/342 (32 items)\n","Processed batch 116/342 (32 items)\n","Processed batch 117/342 (32 items)\n","Processed batch 118/342 (32 items)\n","Processed batch 119/342 (32 items)\n","Checkpoint saved at batch 120\n","Processed batch 120/342 (32 items)\n","\n","        API Calls: 120\n","        Total Tokens: 430714\n","        Estimated Cost: $0.86\n","        \n","Processed batch 121/342 (32 items)\n","Processed batch 122/342 (32 items)\n","Processed batch 123/342 (32 items)\n","Processed batch 124/342 (32 items)\n","Processed batch 125/342 (32 items)\n","Processed batch 126/342 (32 items)\n","Processed batch 127/342 (32 items)\n","Processed batch 128/342 (32 items)\n","Processed batch 129/342 (32 items)\n","Checkpoint saved at batch 130\n","Processed batch 130/342 (32 items)\n","\n","        API Calls: 130\n","        Total Tokens: 465011\n","        Estimated Cost: $0.93\n","        \n","Processed batch 131/342 (32 items)\n","Processed batch 132/342 (32 items)\n","Processed batch 133/342 (32 items)\n","Processed batch 134/342 (32 items)\n","Processed batch 135/342 (32 items)\n","Processed batch 136/342 (32 items)\n","Processed batch 137/342 (32 items)\n","Processed batch 138/342 (32 items)\n","Processed batch 139/342 (32 items)\n","Checkpoint saved at batch 140\n","Processed batch 140/342 (32 items)\n","\n","        API Calls: 140\n","        Total Tokens: 505688\n","        Estimated Cost: $1.01\n","        \n","Processed batch 141/342 (32 items)\n","Processed batch 142/342 (32 items)\n","Processed batch 143/342 (32 items)\n","Processed batch 144/342 (32 items)\n","Processed batch 145/342 (32 items)\n","Processed batch 146/342 (32 items)\n","Processed batch 147/342 (32 items)\n","Processed batch 148/342 (32 items)\n","Processed batch 149/342 (32 items)\n","Checkpoint saved at batch 150\n","Processed batch 150/342 (32 items)\n","\n","        API Calls: 150\n","        Total Tokens: 544197\n","        Estimated Cost: $1.09\n","        \n","Processed batch 151/342 (32 items)\n","Processed batch 152/342 (32 items)\n","Processed batch 153/342 (32 items)\n","Processed batch 154/342 (32 items)\n","Processed batch 155/342 (32 items)\n","Processed batch 156/342 (32 items)\n","Processed batch 157/342 (32 items)\n","Processed batch 158/342 (32 items)\n","Processed batch 159/342 (32 items)\n","Checkpoint saved at batch 160\n","Processed batch 160/342 (32 items)\n","\n","        API Calls: 160\n","        Total Tokens: 579162\n","        Estimated Cost: $1.16\n","        \n","Processed batch 161/342 (32 items)\n","Processed batch 162/342 (32 items)\n","Processed batch 163/342 (32 items)\n","Processed batch 164/342 (32 items)\n","Processed batch 165/342 (32 items)\n","Processed batch 166/342 (32 items)\n","Processed batch 167/342 (32 items)\n","Processed batch 168/342 (32 items)\n","Processed batch 169/342 (32 items)\n","Checkpoint saved at batch 170\n","Processed batch 170/342 (32 items)\n","\n","        API Calls: 170\n","        Total Tokens: 616551\n","        Estimated Cost: $1.23\n","        \n","Processed batch 171/342 (32 items)\n","Processed batch 172/342 (32 items)\n","Processed batch 173/342 (32 items)\n","Processed batch 174/342 (32 items)\n","Processed batch 175/342 (32 items)\n","Processed batch 176/342 (32 items)\n","Processed batch 177/342 (32 items)\n","Processed batch 178/342 (32 items)\n","Processed batch 179/342 (32 items)\n","Checkpoint saved at batch 180\n","Processed batch 180/342 (32 items)\n","\n","        API Calls: 180\n","        Total Tokens: 649967\n","        Estimated Cost: $1.30\n","        \n","Processed batch 181/342 (32 items)\n","Processed batch 182/342 (32 items)\n","Processed batch 183/342 (32 items)\n","Processed batch 184/342 (32 items)\n","Processed batch 185/342 (32 items)\n","Processed batch 186/342 (32 items)\n","Processed batch 187/342 (32 items)\n","Processed batch 188/342 (32 items)\n","Processed batch 189/342 (32 items)\n","Checkpoint saved at batch 190\n","Processed batch 190/342 (32 items)\n","\n","        API Calls: 190\n","        Total Tokens: 687474\n","        Estimated Cost: $1.37\n","        \n","Processed batch 191/342 (32 items)\n","Processed batch 192/342 (32 items)\n","Processed batch 193/342 (32 items)\n","Processed batch 194/342 (32 items)\n","Processed batch 195/342 (32 items)\n","Processed batch 196/342 (32 items)\n","Processed batch 197/342 (32 items)\n","Processed batch 198/342 (32 items)\n","Processed batch 199/342 (32 items)\n","Checkpoint saved at batch 200\n","Processed batch 200/342 (32 items)\n","\n","        API Calls: 200\n","        Total Tokens: 726060\n","        Estimated Cost: $1.45\n","        \n","Processed batch 201/342 (32 items)\n","Processed batch 202/342 (32 items)\n","Processed batch 203/342 (32 items)\n","Processed batch 204/342 (32 items)\n","Processed batch 205/342 (32 items)\n","Processed batch 206/342 (32 items)\n","Processed batch 207/342 (32 items)\n","Processed batch 208/342 (32 items)\n","Processed batch 209/342 (32 items)\n","Checkpoint saved at batch 210\n","Processed batch 210/342 (32 items)\n","\n","        API Calls: 210\n","        Total Tokens: 760956\n","        Estimated Cost: $1.52\n","        \n","Processed batch 211/342 (32 items)\n","Processed batch 212/342 (32 items)\n","Processed batch 213/342 (32 items)\n","Processed batch 214/342 (32 items)\n","Processed batch 215/342 (32 items)\n","Processed batch 216/342 (32 items)\n","Processed batch 217/342 (32 items)\n","Processed batch 218/342 (32 items)\n","Processed batch 219/342 (32 items)\n","Checkpoint saved at batch 220\n","Processed batch 220/342 (32 items)\n","\n","        API Calls: 220\n","        Total Tokens: 800130\n","        Estimated Cost: $1.60\n","        \n","Processed batch 221/342 (32 items)\n","Processed batch 222/342 (32 items)\n","Processed batch 223/342 (32 items)\n","Processed batch 224/342 (32 items)\n","Processed batch 225/342 (32 items)\n","Processed batch 226/342 (32 items)\n","Processed batch 227/342 (32 items)\n","Processed batch 228/342 (32 items)\n","Processed batch 229/342 (32 items)\n","Checkpoint saved at batch 230\n","Processed batch 230/342 (32 items)\n","\n","        API Calls: 230\n","        Total Tokens: 836066\n","        Estimated Cost: $1.67\n","        \n","Processed batch 231/342 (32 items)\n","Processed batch 232/342 (32 items)\n","Processed batch 233/342 (32 items)\n","Processed batch 234/342 (32 items)\n","Processed batch 235/342 (32 items)\n","Processed batch 236/342 (32 items)\n","Processed batch 237/342 (32 items)\n","Processed batch 238/342 (32 items)\n","Processed batch 239/342 (32 items)\n","Checkpoint saved at batch 240\n","Processed batch 240/342 (32 items)\n","\n","        API Calls: 240\n","        Total Tokens: 874207\n","        Estimated Cost: $1.75\n","        \n","Processed batch 241/342 (32 items)\n","Processed batch 242/342 (32 items)\n","Processed batch 243/342 (32 items)\n","Processed batch 244/342 (32 items)\n","Processed batch 245/342 (32 items)\n","Processed batch 246/342 (32 items)\n","Processed batch 247/342 (32 items)\n","Processed batch 248/342 (32 items)\n","Processed batch 249/342 (32 items)\n","Checkpoint saved at batch 250\n","Processed batch 250/342 (32 items)\n","\n","        API Calls: 250\n","        Total Tokens: 911818\n","        Estimated Cost: $1.82\n","        \n","Processed batch 251/342 (32 items)\n","Processed batch 252/342 (32 items)\n","Processed batch 253/342 (32 items)\n","Processed batch 254/342 (32 items)\n","Processed batch 255/342 (32 items)\n","Processed batch 256/342 (32 items)\n","Processed batch 257/342 (32 items)\n","Processed batch 258/342 (32 items)\n","Processed batch 259/342 (32 items)\n","Checkpoint saved at batch 260\n","Processed batch 260/342 (32 items)\n","\n","        API Calls: 260\n","        Total Tokens: 949344\n","        Estimated Cost: $1.90\n","        \n","Processed batch 261/342 (32 items)\n","Processed batch 262/342 (32 items)\n","Processed batch 263/342 (32 items)\n","Processed batch 264/342 (32 items)\n","Processed batch 265/342 (32 items)\n","Processed batch 266/342 (32 items)\n","Processed batch 267/342 (32 items)\n","Processed batch 268/342 (32 items)\n","Processed batch 269/342 (32 items)\n","Checkpoint saved at batch 270\n","Processed batch 270/342 (32 items)\n","\n","        API Calls: 270\n","        Total Tokens: 987972\n","        Estimated Cost: $1.98\n","        \n","Processed batch 271/342 (32 items)\n","Processed batch 272/342 (32 items)\n","Processed batch 273/342 (32 items)\n","Processed batch 274/342 (32 items)\n","Processed batch 275/342 (32 items)\n","Processed batch 276/342 (32 items)\n","Processed batch 277/342 (32 items)\n","Processed batch 278/342 (32 items)\n","Processed batch 279/342 (32 items)\n","Checkpoint saved at batch 280\n","Processed batch 280/342 (32 items)\n","\n","        API Calls: 280\n","        Total Tokens: 1024726\n","        Estimated Cost: $2.05\n","        \n","Processed batch 281/342 (32 items)\n","Processed batch 282/342 (32 items)\n","Processed batch 283/342 (32 items)\n","Processed batch 284/342 (32 items)\n","Processed batch 285/342 (32 items)\n","Processed batch 286/342 (32 items)\n","Processed batch 287/342 (32 items)\n","Processed batch 288/342 (32 items)\n","Processed batch 289/342 (32 items)\n","Checkpoint saved at batch 290\n","Processed batch 290/342 (32 items)\n","\n","        API Calls: 290\n","        Total Tokens: 1061975\n","        Estimated Cost: $2.12\n","        \n","Processed batch 291/342 (32 items)\n","Processed batch 292/342 (32 items)\n","Processed batch 293/342 (32 items)\n","Processed batch 294/342 (32 items)\n","Processed batch 295/342 (32 items)\n","Processed batch 296/342 (32 items)\n","Processed batch 297/342 (32 items)\n","Processed batch 298/342 (32 items)\n","Processed batch 299/342 (32 items)\n","Checkpoint saved at batch 300\n","Processed batch 300/342 (32 items)\n","\n","        API Calls: 300\n","        Total Tokens: 1097615\n","        Estimated Cost: $2.20\n","        \n","Processed batch 301/342 (32 items)\n","Processed batch 302/342 (32 items)\n","Processed batch 303/342 (32 items)\n","Processed batch 304/342 (32 items)\n","Processed batch 305/342 (32 items)\n","Processed batch 306/342 (32 items)\n","Processed batch 307/342 (32 items)\n","Processed batch 308/342 (32 items)\n","Processed batch 309/342 (32 items)\n","Checkpoint saved at batch 310\n","Processed batch 310/342 (32 items)\n","\n","        API Calls: 310\n","        Total Tokens: 1133789\n","        Estimated Cost: $2.27\n","        \n","Processed batch 311/342 (32 items)\n","Processed batch 312/342 (32 items)\n","Processed batch 313/342 (32 items)\n","Processed batch 314/342 (32 items)\n","Processed batch 315/342 (32 items)\n","Processed batch 316/342 (32 items)\n","Processed batch 317/342 (32 items)\n","Processed batch 318/342 (32 items)\n","Processed batch 319/342 (32 items)\n","Checkpoint saved at batch 320\n","Processed batch 320/342 (32 items)\n","\n","        API Calls: 320\n","        Total Tokens: 1170206\n","        Estimated Cost: $2.34\n","        \n","Processed batch 321/342 (32 items)\n","Processed batch 322/342 (32 items)\n","Processed batch 323/342 (32 items)\n","Processed batch 324/342 (32 items)\n","Processed batch 325/342 (32 items)\n","Processed batch 326/342 (32 items)\n","Processed batch 327/342 (32 items)\n","Processed batch 328/342 (32 items)\n","Processed batch 329/342 (32 items)\n","Checkpoint saved at batch 330\n","Processed batch 330/342 (32 items)\n","\n","        API Calls: 330\n","        Total Tokens: 1210258\n","        Estimated Cost: $2.42\n","        \n","Processed batch 331/342 (32 items)\n","Processed batch 332/342 (32 items)\n","Processed batch 333/342 (32 items)\n","Processed batch 334/342 (32 items)\n","Processed batch 335/342 (32 items)\n","Processed batch 336/342 (32 items)\n","Processed batch 337/342 (32 items)\n","Processed batch 338/342 (32 items)\n","Processed batch 339/342 (32 items)\n","Checkpoint saved at batch 340\n","Processed batch 340/342 (32 items)\n","\n","        API Calls: 340\n","        Total Tokens: 1243900\n","        Estimated Cost: $2.49\n","        \n","Processed batch 341/342 (32 items)\n","Processed batch 342/342 (5 items)\n","\n","Final Statistics:\n","\n","        API Calls: 342\n","        Total Tokens: 1248224\n","        Estimated Cost: $2.50\n","        \n","Total translations: 10927\n"]}]},{"cell_type":"markdown","metadata":{"id":"tnJIJ9oNBkXf"},"source":["### Few tries of translation of msr paraphrase dataset - Executing the code for 1h\n","\n","Final Statistics:\n","\n","        API Calls: 172\n","        Total Tokens: 1094704\n","        Estimated Cost: $2.19\n"]},{"cell_type":"code","source":["# new, more robust and for non-asynchronous function\n","\n","if __name__ == \"__main__\":\n","    input_file = \"/content/drive/My Drive/Colab Notebooks/msr_paraphrase_data.txt\"\n","    dataset_name = \"msr_paraphrase\"\n","\n","    try:\n","        from google.colab import userdata\n","        api_key = userdata.get('OPENAI_API_KEY')\n","    except ImportError:\n","        api_key = os.getenv('OPENAI_API_KEY')\n","\n","    if not api_key:\n","        raise ValueError(\"API key not found. Please set the OPENAI_API_KEY in Colab secrets or environment variables.\")\n","\n","    process_dataset(\n","        input_file=input_file,\n","        dataset_name=dataset_name,\n","        api_key=api_key,\n","        batch_size=64,\n","        checkpoint_interval=5\n","    )\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GNao8vk4CdtN","outputId":"e25df440-3d7f-476a-ee54-07a3eedf366c","executionInfo":{"status":"ok","timestamp":1739284153125,"user_tz":-60,"elapsed":5353,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}}},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting from batch 171, line 10944\n","Total lines in file: 10949\n","Processed batch 171/171 (4 items)\n","\n","Final Statistics:\n","\n","        API Calls: 1\n","        Total Tokens: 308\n","        Estimated Cost: $0.00\n","        \n","Total translations: 11016\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wwQOdDo6BkXf","executionInfo":{"status":"ok","timestamp":1738865559047,"user_tz":-60,"elapsed":5157663,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"cfbf12d0-a925-456c-d94f-f62cdeddad9c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Processed batch 5/343\n","Processed batch 6/343\n","Processed batch 0/172\n","\n","        API Calls: 1\n","        Total Tokens: 7487\n","        Estimated Cost: $0.01\n","        \n","Processed batch 7/343\n","Processed batch 1/172\n","Processed batch 2/172\n","Processed batch 8/343\n","Processed batch 9/343\n","Processed batch 3/172\n","Processed batch 10/343\n","\n","        API Calls: 11\n","        Total Tokens: 39969\n","        Estimated Cost: $0.08\n","        \n","Processed batch 11/343\n","Processed batch 4/172\n","Processed batch 12/343\n","Processed batch 5/172\n","Processed batch 6/172\n","Processed batch 13/343\n","Processed batch 14/343\n","Processed batch 7/172\n","Processed batch 15/343\n","Processed batch 16/343\n","Processed batch 8/172\n","Processed batch 9/172\n","Processed batch 10/172\n","\n","        API Calls: 11\n","        Total Tokens: 70814\n","        Estimated Cost: $0.14\n","        \n","Processed batch 11/172\n","Processed batch 17/343\n","Processed batch 18/343\n","Processed batch 19/343\n","Processed batch 12/172\n","Processed batch 20/343\n","\n","        API Calls: 21\n","        Total Tokens: 78213\n","        Estimated Cost: $0.16\n","        \n","Processed batch 21/343\n","Processed batch 13/172\n","Processed batch 22/343\n","Processed batch 14/172\n","Processed batch 23/343\n","Processed batch 24/343\n","Processed batch 25/343\n","Processed batch 15/172\n","Processed batch 16/172\n","Processed batch 26/343\n","Processed batch 27/343\n","Processed batch 17/172\n","Processed batch 28/343\n","Processed batch 18/172\n","Processed batch 19/172\n","Processed batch 20/172\n","\n","        API Calls: 21\n","        Total Tokens: 130578\n","        Estimated Cost: $0.26\n","        \n","Processed batch 29/343\n","Processed batch 30/343\n","\n","        API Calls: 31\n","        Total Tokens: 115868\n","        Estimated Cost: $0.23\n","        \n","Processed batch 31/343\n","Processed batch 21/172\n","Processed batch 32/343\n","Processed batch 33/343\n","Processed batch 22/172\n","Processed batch 34/343\n","Processed batch 35/343\n","Processed batch 36/343\n","Processed batch 23/172\n","Processed batch 37/343\n","Processed batch 38/343\n","Processed batch 24/172\n","Processed batch 39/343\n","Processed batch 25/172\n","Processed batch 40/343\n","\n","        API Calls: 41\n","        Total Tokens: 150629\n","        Estimated Cost: $0.30\n","        \n","Processed batch 41/343\n","Processed batch 26/172\n","Processed batch 42/343\n","Processed batch 43/343\n","Processed batch 44/343\n","Processed batch 27/172\n","Processed batch 45/343\n","Processed batch 28/172\n","Processed batch 46/343\n","Processed batch 29/172\n","Processed batch 47/343\n","Processed batch 30/172\n","\n","        API Calls: 31\n","        Total Tokens: 199562\n","        Estimated Cost: $0.40\n","        \n","Processed batch 31/172\n","Processed batch 48/343\n","Processed batch 49/343\n","Processed batch 50/343\n","\n","        API Calls: 51\n","        Total Tokens: 185868\n","        Estimated Cost: $0.37\n","        \n","Processed batch 32/172\n","Processed batch 33/172\n","Processed batch 51/343\n","Processed batch 34/172\n","Processed batch 52/343\n","Processed batch 53/343\n","Processed batch 35/172\n","Processed batch 54/343\n","Processed batch 36/172\n","Processed batch 55/343\n","Processed batch 56/343\n","Processed batch 57/343\n","Processed batch 58/343\n","Processed batch 37/172\n","Processed batch 59/343\n","Processed batch 60/343\n","\n","        API Calls: 61\n","        Total Tokens: 219779\n","        Estimated Cost: $0.44\n","        \n","Processed batch 38/172\n","Processed batch 61/343\n","Processed batch 62/343\n","Processed batch 63/343\n","Processed batch 64/343\n","Processed batch 39/172\n","Processed batch 65/343\n","Processed batch 66/343\n","Processed batch 40/172\n","\n","        API Calls: 41\n","        Total Tokens: 265480\n","        Estimated Cost: $0.53\n","        \n","Processed batch 67/343\n","Processed batch 41/172\n","Processed batch 68/343\n","Processed batch 69/343\n","Processed batch 70/343\n","\n","        API Calls: 71\n","        Total Tokens: 253708\n","        Estimated Cost: $0.51\n","        \n","Processed batch 42/172\n","Processed batch 71/343\n","Processed batch 72/343\n","Processed batch 43/172\n","Processed batch 73/343\n","Processed batch 74/343\n","Processed batch 44/172\n","Processed batch 75/343\n","Processed batch 45/172\n","Processed batch 76/343\n","Processed batch 77/343\n","Processed batch 78/343\n","Processed batch 46/172\n","Processed batch 79/343\n","Processed batch 47/172\n","Processed batch 80/343\n","\n","        API Calls: 81\n","        Total Tokens: 292033\n","        Estimated Cost: $0.58\n","        \n","Processed batch 81/343\n","Processed batch 48/172\n","Processed batch 82/343\n","Processed batch 83/343\n","Processed batch 84/343\n","Processed batch 49/172\n","Processed batch 50/172\n","\n","        API Calls: 51\n","        Total Tokens: 337627\n","        Estimated Cost: $0.68\n","        \n","Processed batch 85/343\n","Processed batch 86/343\n","Processed batch 51/172\n","Processed batch 87/343\n","Processed batch 52/172\n","Processed batch 88/343\n","Processed batch 89/343\n","Processed batch 90/343\n","\n","        API Calls: 90\n","        Total Tokens: 324480\n","        Estimated Cost: $0.65\n","        \n","Processed batch 53/172\n","Processed batch 91/343\n","Processed batch 92/343\n","Processed batch 54/172\n","Processed batch 55/172\n","Processed batch 93/343\n","Processed batch 94/343\n","Processed batch 56/172\n","Processed batch 95/343\n","Processed batch 96/343\n","Processed batch 97/343\n","Processed batch 98/343\n","Processed batch 57/172\n","Processed batch 99/343\n","Processed batch 100/343\n","\n","        API Calls: 100\n","        Total Tokens: 361588\n","        Estimated Cost: $0.72\n","        \n","Processed batch 58/172\n","Processed batch 101/343\n","Processed batch 102/343\n","Processed batch 59/172\n","Processed batch 103/343\n","Processed batch 104/343\n","Processed batch 60/172\n","\n","        API Calls: 61\n","        Total Tokens: 405808\n","        Estimated Cost: $0.81\n","        \n","Processed batch 61/172\n","Processed batch 62/172\n","Processed batch 105/343\n","Processed batch 106/343\n","Processed batch 107/343\n","Processed batch 108/343\n","Processed batch 63/172\n","Processed batch 109/343\n","Processed batch 110/343\n","\n","        API Calls: 110\n","        Total Tokens: 399138\n","        Estimated Cost: $0.80\n","        \n","Processed batch 64/172\n","Processed batch 111/343\n","Processed batch 112/343\n","Processed batch 65/172\n","Processed batch 66/172\n","Processed batch 113/343\n","Processed batch 114/343\n","Processed batch 67/172\n","Processed batch 115/343\n","Processed batch 116/343\n","Processed batch 68/172\n","Processed batch 117/343\n","Processed batch 118/343\n","Processed batch 119/343\n","Processed batch 69/172\n","Processed batch 70/172\n","\n","        API Calls: 71\n","        Total Tokens: 468025\n","        Estimated Cost: $0.94\n","        \n","Processed batch 120/343\n","\n","        API Calls: 120\n","        Total Tokens: 435532\n","        Estimated Cost: $0.87\n","        \n","Processed batch 71/172\n","Processed batch 121/343\n","Processed batch 122/343\n","Processed batch 72/172\n","Processed batch 123/343\n","Processed batch 124/343\n","Processed batch 125/343\n","Processed batch 73/172\n","Processed batch 126/343\n","Processed batch 127/343\n","Processed batch 128/343\n","Processed batch 74/172\n","Processed batch 129/343\n","Processed batch 130/343\n","\n","        API Calls: 130\n","        Total Tokens: 471201\n","        Estimated Cost: $0.94\n","        \n","Processed batch 75/172\n","Processed batch 131/343\n","Processed batch 76/172\n","Processed batch 132/343\n","Processed batch 77/172\n","Processed batch 133/343\n","Processed batch 134/343\n","Processed batch 78/172\n","Processed batch 79/172\n","Processed batch 80/172\n","\n","        API Calls: 81\n","        Total Tokens: 532175\n","        Estimated Cost: $1.06\n","        \n","Processed batch 135/343\n","Processed batch 136/343\n","Processed batch 137/343\n","Processed batch 81/172\n","Processed batch 138/343\n","Processed batch 139/343\n","Processed batch 140/343\n","\n","        API Calls: 140\n","        Total Tokens: 507152\n","        Estimated Cost: $1.01\n","        \n","Processed batch 82/172\n","Processed batch 141/343\n","Processed batch 142/343\n","Processed batch 143/343\n","Processed batch 144/343\n","Processed batch 145/343\n","Processed batch 83/172\n","Processed batch 84/172\n","Processed batch 85/172\n","Processed batch 146/343\n","Processed batch 86/172\n","Processed batch 147/343\n","Processed batch 148/343\n","Processed batch 87/172\n","Processed batch 149/343\n","Processed batch 150/343\n","\n","        API Calls: 150\n","        Total Tokens: 539586\n","        Estimated Cost: $1.08\n","        \n","Processed batch 151/343\n","Processed batch 88/172\n","Processed batch 152/343\n","Processed batch 89/172\n","Processed batch 153/343\n","Processed batch 154/343\n","Processed batch 155/343\n","Processed batch 156/343\n","Processed batch 90/172\n","\n","        API Calls: 91\n","        Total Tokens: 596889\n","        Estimated Cost: $1.19\n","        \n","Processed batch 91/172\n","Processed batch 157/343\n","Processed batch 92/172\n","Processed batch 158/343\n","Processed batch 93/172\n","Processed batch 159/343\n","Processed batch 160/343\n","\n","        API Calls: 159\n","        Total Tokens: 571100\n","        Estimated Cost: $1.14\n","        \n","Processed batch 94/172\n","Processed batch 161/343\n","Processed batch 162/343\n","Processed batch 95/172\n","Processed batch 163/343\n","Processed batch 96/172\n","Processed batch 164/343\n","Processed batch 165/343\n","Processed batch 97/172\n","Processed batch 166/343\n","Processed batch 98/172\n","Processed batch 167/343\n","Processed batch 168/343\n","Processed batch 99/172\n","Processed batch 169/343\n","Processed batch 170/343\n","\n","        API Calls: 169\n","        Total Tokens: 608469\n","        Estimated Cost: $1.22\n","        \n","Processed batch 100/172\n","\n","        API Calls: 101\n","        Total Tokens: 657743\n","        Estimated Cost: $1.32\n","        \n","Processed batch 171/343\n","Processed batch 172/343\n","Processed batch 173/343\n","Processed batch 101/172\n","Processed batch 174/343\n","Processed batch 175/343\n","Processed batch 102/172\n","Processed batch 176/343\n","Processed batch 177/343\n","Processed batch 103/172\n","Processed batch 178/343\n","Processed batch 179/343\n","Processed batch 180/343\n","\n","        API Calls: 179\n","        Total Tokens: 640217\n","        Estimated Cost: $1.28\n","        \n","Processed batch 104/172\n","Processed batch 181/343\n","Processed batch 182/343\n","Processed batch 183/343\n","Processed batch 105/172\n","Processed batch 106/172\n","Processed batch 184/343\n","Processed batch 185/343\n","Processed batch 107/172\n","Processed batch 108/172\n","Processed batch 109/172\n","Processed batch 186/343\n","Processed batch 187/343\n","Processed batch 110/172\n","\n","        API Calls: 111\n","        Total Tokens: 722939\n","        Estimated Cost: $1.45\n","        \n","Processed batch 188/343\n","Processed batch 111/172\n","Processed batch 112/172\n","Processed batch 113/172\n","Processed batch 189/343\n","Processed batch 190/343\n","\n","        API Calls: 189\n","        Total Tokens: 677766\n","        Estimated Cost: $1.36\n","        \n","Processed batch 114/172\n","Processed batch 115/172\n","Processed batch 191/343\n","Processed batch 192/343\n","Processed batch 116/172\n","Processed batch 193/343\n","Processed batch 194/343\n","Processed batch 117/172\n","Processed batch 195/343\n","Processed batch 196/343\n","Processed batch 118/172\n","Processed batch 197/343\n","Processed batch 119/172\n","Processed batch 198/343\n","Processed batch 199/343\n","Processed batch 120/172\n","\n","        API Calls: 121\n","        Total Tokens: 781706\n","        Estimated Cost: $1.56\n","        \n","Processed batch 200/343\n","\n","        API Calls: 199\n","        Total Tokens: 712923\n","        Estimated Cost: $1.43\n","        \n","Processed batch 201/343\n","Processed batch 202/343\n","Processed batch 121/172\n","Processed batch 122/172\n","Processed batch 203/343\n","Processed batch 204/343\n","Processed batch 123/172\n","Processed batch 205/343\n","Processed batch 206/343\n","Processed batch 207/343\n","Processed batch 208/343\n","Processed batch 124/172\n","Processed batch 209/343\n","Processed batch 210/343\n","\n","        API Calls: 209\n","        Total Tokens: 745741\n","        Estimated Cost: $1.49\n","        \n","Processed batch 211/343\n","Processed batch 125/172\n","Processed batch 126/172\n","Processed batch 212/343\n","Processed batch 213/343\n","Processed batch 127/172\n","Processed batch 214/343\n","Processed batch 215/343\n","Processed batch 216/343\n","Processed batch 217/343\n","Processed batch 128/172\n","Processed batch 218/343\n","Processed batch 129/172\n","Processed batch 219/343\n","Processed batch 220/343\n","\n","        API Calls: 219\n","        Total Tokens: 779082\n","        Estimated Cost: $1.56\n","        \n","Processed batch 221/343\n","Processed batch 222/343\n","Processed batch 130/172\n","\n","        API Calls: 131\n","        Total Tokens: 848475\n","        Estimated Cost: $1.70\n","        \n","Processed batch 223/343\n","Processed batch 224/343\n","Processed batch 131/172\n","Processed batch 225/343\n","Processed batch 226/343\n","Processed batch 227/343\n","Processed batch 132/172\n","Processed batch 228/343\n","Processed batch 133/172\n","Processed batch 229/343\n","Processed batch 230/343\n","\n","        API Calls: 229\n","        Total Tokens: 812829\n","        Estimated Cost: $1.63\n","        \n","Processed batch 231/343\n","Processed batch 134/172\n","Processed batch 232/343\n","Processed batch 135/172\n","Processed batch 233/343\n","Processed batch 136/172\n","Processed batch 234/343\n","Processed batch 235/343\n","Processed batch 137/172\n","Processed batch 138/172\n","Processed batch 236/343\n","Processed batch 237/343\n","Processed batch 139/172\n","Processed batch 238/343\n","Processed batch 239/343\n","Processed batch 140/172\n","\n","        API Calls: 141\n","        Total Tokens: 912265\n","        Estimated Cost: $1.82\n","        \n","Processed batch 240/343\n","\n","        API Calls: 238\n","        Total Tokens: 848298\n","        Estimated Cost: $1.70\n","        \n","Processed batch 241/343\n","Processed batch 141/172\n","Processed batch 142/172\n","Processed batch 242/343\n","Processed batch 143/172\n","Processed batch 243/343\n","Processed batch 144/172\n","Processed batch 244/343\n","Processed batch 145/172\n","Processed batch 245/343\n","Processed batch 246/343\n","Processed batch 146/172\n","Processed batch 247/343\n","Processed batch 248/343\n","Processed batch 249/343\n","Processed batch 147/172\n","Processed batch 250/343\n","\n","        API Calls: 248\n","        Total Tokens: 885864\n","        Estimated Cost: $1.77\n","        \n","Processed batch 148/172\n","Processed batch 251/343\n","Processed batch 252/343\n","Processed batch 149/172\n","Processed batch 253/343\n","Processed batch 150/172\n","\n","        API Calls: 151\n","        Total Tokens: 972907\n","        Estimated Cost: $1.95\n","        \n","Processed batch 254/343\n","Processed batch 255/343\n","Processed batch 256/343\n","Processed batch 151/172\n","Processed batch 257/343\n","Processed batch 152/172\n","Processed batch 258/343\n","Processed batch 153/172\n","Processed batch 259/343\n","Processed batch 260/343\n","\n","        API Calls: 258\n","        Total Tokens: 921875\n","        Estimated Cost: $1.84\n","        \n","Processed batch 154/172\n","Processed batch 261/343\n","Processed batch 155/172\n","Processed batch 262/343\n","Processed batch 263/343\n","Processed batch 156/172\n","Processed batch 157/172\n","Processed batch 264/343\n","Processed batch 158/172\n","Processed batch 265/343\n","Processed batch 266/343\n","Processed batch 267/343\n","Processed batch 159/172\n","Processed batch 268/343\n","Processed batch 160/172\n","\n","        API Calls: 161\n","        Total Tokens: 1034691\n","        Estimated Cost: $2.07\n","        \n","Processed batch 269/343\n","Processed batch 270/343\n","\n","        API Calls: 268\n","        Total Tokens: 956962\n","        Estimated Cost: $1.91\n","        \n","Processed batch 271/343\n","Processed batch 161/172\n","Processed batch 272/343\n","Processed batch 273/343\n","Processed batch 162/172\n","Processed batch 274/343\n","Processed batch 275/343\n","Processed batch 163/172\n","Processed batch 276/343\n","Processed batch 164/172\n","Processed batch 165/172\n","Processed batch 277/343\n","Processed batch 278/343\n","Processed batch 279/343\n","Processed batch 166/172\n","Processed batch 167/172\n","Processed batch 280/343\n","\n","        API Calls: 278\n","        Total Tokens: 989053\n","        Estimated Cost: $1.98\n","        \n","Processed batch 281/343\n","Processed batch 168/172\n","Processed batch 169/172\n","Processed batch 282/343\n","Processed batch 283/343\n","Processed batch 170/172\n","\n","        API Calls: 171\n","        Total Tokens: 1094214\n","        Estimated Cost: $2.19\n","        \n","Processed batch 171/172\n","\n","Final Statistics:\n","\n","        API Calls: 172\n","        Total Tokens: 1094704\n","        Estimated Cost: $2.19\n","        \n"]}],"source":["# running for asyncronous function, which is not in use at the moment\n","\n","if __name__ == \"__main__\":\n","    input_file = \"/content/drive/My Drive/Colab Notebooks/msr_paraphrase_data.txt\"\n","    dataset_name = \"msr_paraphrase\"\n","\n","    # Get the OpenAI API key using userdata\n","    from google.colab import userdata\n","    api_key = userdata.get('OPENAI_API_KEY')\n","\n","    if api_key is None:\n","        raise ValueError(\"API key not found. Please set the OPENAI_API_KEY in Colab secrets.\")\n","\n","    # Use nest_asyncio to integrate with the existing loop\n","    import nest_asyncio\n","    nest_asyncio.apply()\n","\n","    # Get the current event loop\n","    loop = asyncio.get_event_loop()\n","\n","    # Run the process_dataset function using the existing loop\n","    loop.run_until_complete(process_dataset(\n","        input_file=input_file,\n","        dataset_name=dataset_name,\n","        api_key=api_key,\n","        batch_size=64  # Adjust batch size as needed\n","    ))"]},{"cell_type":"markdown","metadata":{"id":"7teb07y3BkXj"},"source":["## **para-nmt-50m-small.txt**"]},{"cell_type":"markdown","source":["#### Processed batch 2680/3125 (32 items)\n","\n","        API Calls: 2681\n","        Total Tokens: 4742926\n","        Estimated Cost: $9.49"],"metadata":{"id":"xVkgw0v4d1wc"}},{"cell_type":"code","source":["from typing import Iterator, List, Dict, Any, Tuple, Optional\n","import json\n","import os\n","from pathlib import Path\n","from datetime import datetime\n","from openai import OpenAI\n","from openai.types.chat import ChatCompletion\n","import time\n","\n","class TranslationManager:\n","    def __init__(self, api_key: str, cache_dir: str = \"translation_cache\", checkpoint_dir: str = \"checkpoints\"):\n","        self.client = OpenAI(api_key=api_key)\n","        self.cache_dir = Path(cache_dir)\n","        self.checkpoint_dir = Path(checkpoint_dir)\n","        self.cache_dir.mkdir(exist_ok=True)\n","        self.checkpoint_dir.mkdir(exist_ok=True)\n","        self.batch_cache = {}\n","        self.current_cache_size = 0\n","        self.max_cache_size = 1000\n","\n","    def _get_cache_file(self, batch_id: str) -> Path:\n","        return self.cache_dir / f\"cache_{batch_id}.json\"\n","\n","    def get_checkpoint_file(self, dataset_name: str) -> Path:\n","        return self.checkpoint_dir / f\"{dataset_name}_checkpoint.json\"\n","\n","    def _save_batch_cache(self, batch_id: str):\n","        cache_file = self._get_cache_file(batch_id)\n","        with open(cache_file, 'w', encoding='utf-8') as f:\n","            json.dump(self.batch_cache, f, ensure_ascii=False, indent=2)\n","        self.batch_cache = {}\n","        self.current_cache_size = 0\n","\n","    def _load_cache(self, batch_id: str) -> Dict:\n","        cache_file = self._get_cache_file(batch_id)\n","        if cache_file.exists():\n","            with open(cache_file, 'r', encoding='utf-8') as f:\n","                return json.load(f)\n","        return {}\n","\n","    def save_checkpoint(self, dataset_name: str, batch_num: int, translations_count: int):\n","        checkpoint_data = {\n","            \"last_batch\": batch_num,\n","            \"translations_count\": translations_count,\n","            \"timestamp\": datetime.now().isoformat()\n","        }\n","        checkpoint_file = self.get_checkpoint_file(dataset_name)\n","        with open(checkpoint_file, 'w', encoding='utf-8') as f:\n","            json.dump(checkpoint_data, f, indent=2)\n","\n","    def load_checkpoint(self, dataset_name: str) -> Dict:\n","        checkpoint_file = self.get_checkpoint_file(dataset_name)\n","        if checkpoint_file.exists():\n","            with open(checkpoint_file, 'r', encoding='utf-8') as f:\n","                return json.load(f)\n","        return {\"last_batch\": -1, \"translations_count\": 0}\n","\n","    def translate_batch(self, texts: List[str], batch_id: str) -> Tuple[List[str], Optional[ChatCompletion]]:\n","        if not texts:\n","            return [], None\n","\n","        try:\n","            cache = self._load_cache(batch_id)\n","            translations = [\"\"] * len(texts)  # Initialize with empty strings\n","            uncached_texts = []\n","            uncached_indices = []\n","\n","            for i, text in enumerate(texts):\n","                text = text.strip()\n","                if text in cache:\n","                    translations[i] = cache[text]\n","                else:\n","                    uncached_texts.append(text)\n","                    uncached_indices.append(i)\n","\n","            if uncached_texts:\n","                retry_attempts = 3\n","                for attempt in range(retry_attempts):\n","                    try:\n","                        response = self.client.chat.completions.create(\n","                            model=\"gpt-3.5-turbo\",\n","                            messages=[\n","                                {\"role\": \"system\", \"content\": \"Translate the following English texts to Slovenian:\"},\n","                                {\"role\": \"user\", \"content\": \"\\n-\\n\".join(uncached_texts)}\n","                            ],\n","                            temperature=0.3\n","                        )\n","\n","                        new_translations = [choice.message.content for choice in response.choices]\n","\n","                        # Ensure we have the same number of translations as input texts\n","                        if len(new_translations) != len(uncached_texts):\n","                            new_translations = new_translations[:len(uncached_texts)]\n","                            if len(new_translations) < len(uncached_texts):\n","                                new_translations.extend([\"\"] * (len(uncached_texts) - len(new_translations)))\n","\n","                        for text, trans in zip(uncached_texts, new_translations):\n","                            self.batch_cache[text] = trans\n","                            self.current_cache_size += 1\n","\n","                        for idx, trans in zip(uncached_indices, new_translations):\n","                            translations[idx] = trans\n","\n","                        if self.current_cache_size >= self.max_cache_size:\n","                            self._save_batch_cache(batch_id)\n","\n","                        return translations, response\n","\n","                    except Exception as e:\n","                        print(f\"Error in API call (attempt {attempt + 1}/{retry_attempts}): {str(e)}\")\n","                        if attempt < retry_attempts - 1:\n","                            time.sleep(2)  # Wait before retrying\n","                        else:\n","                            # If all attempts fail, log the error and return partial results\n","                            for idx in uncached_indices:\n","                                translations[idx] = f\"ERROR: {str(e)}\"\n","                            return translations, None\n","\n","            return translations, None\n","\n","        except Exception as e:\n","            print(f\"Error in batch processing: {str(e)}\")\n","            return [f\"ERROR: {str(e)}\"] * len(texts), None\n","\n","class DatasetIterator:\n","    def __init__(self, file_path: str, batch_size: int, start_line: int = 0, max_sentences: int = 10949):\n","        self.file_path = file_path\n","        self.batch_size = batch_size\n","        self.max_sentences = max_sentences\n","        self.total_lines = min(self._count_lines(), max_sentences)  # Limit total lines\n","        self.start_line = min(start_line, max(0, self.total_lines - 1))\n","\n","    def _count_lines(self) -> int:\n","        try:\n","            with open(self.file_path, \"r\", encoding=\"utf-8\") as f:\n","                return sum(1 for _ in f)\n","        except Exception as e:\n","            print(f\"Error counting lines: {str(e)}\")\n","            return 0\n","\n","    def __iter__(self) -> Iterator[List[str]]:\n","        current_batch = []\n","        processed_lines = 0\n","\n","        try:\n","            with open(self.file_path, \"r\", encoding=\"utf-8\") as f:\n","                # Skip to start line\n","                for _ in range(self.start_line):\n","                    next(f, None)\n","\n","                for line in f:\n","                    if processed_lines >= self.max_sentences:\n","                        break\n","\n","                    try:\n","                        text = line.strip()\n","                        if text:  # Only add non-empty texts\n","                            current_batch.append(text)\n","                            processed_lines += 1\n","\n","                            if len(current_batch) == self.batch_size:\n","                                yield current_batch\n","                                current_batch = []\n","                    except Exception as e:\n","                        print(f\"Error processing line: {line.strip()}\")\n","                        print(f\"Error details: {str(e)}\")\n","                        continue\n","\n","                if current_batch:  # Don't forget last partial batch\n","                    yield current_batch\n","\n","        except Exception as e:\n","            print(f\"Error reading file: {str(e)}\")\n","            if current_batch:  # Yield any remaining batch on error\n","                yield current_batch\n","\n","class CostTracker:\n","    def __init__(self):\n","        self.requests = 0\n","        self.total_tokens = 0\n","        self.price_per_1k_tokens = 0.002\n","\n","    def update(self, response: ChatCompletion):\n","        self.requests += 1\n","        self.total_tokens += response.usage.completion_tokens + response.usage.prompt_tokens\n","\n","    def get_cost(self) -> float:\n","        return (self.total_tokens / 1000) * self.price_per_1k_tokens\n","\n","    def report(self) -> str:\n","        return f\"\"\"\n","        API Calls: {self.requests}\n","        Total Tokens: {self.total_tokens}\n","        Estimated Cost: ${self.get_cost():.2f}\n","        \"\"\"\n","\n","def save_pairs(originals: List[str], translations: List[str], dataset_name: str, mode: str = \"a\"):\n","    base_path = Path(\"/content/drive/My Drive/Colab Notebooks\")\n","\n","    for filename, data in [\n","        (f\"{dataset_name}_originals_GPT3.5.txt\", originals),\n","        (f\"{dataset_name}_translations_GPT3.5.txt\", translations),\n","    ]:\n","        try:\n","            with open(base_path / filename, mode, encoding=\"utf-8\") as f:\n","                for item in data:\n","                    f.write(f\"{item}\\n\")\n","        except Exception as e:\n","            print(f\"Error saving to {filename}: {str(e)}\")\n","\n","    try:\n","        with open(base_path / f\"{dataset_name}_aligned_pairs_GPT3.5.txt\", mode, encoding=\"utf-8\") as f:\n","            for orig, trans in zip(originals, translations):\n","                f.write(f\"Original: {orig}\\nTranslation: {trans}\\n---\\n\")\n","    except Exception as e:\n","        print(f\"Error saving aligned pairs: {str(e)}\")\n","\n","def process_dataset(\n","    input_file: str,\n","    dataset_name: str,\n","    api_key: str,\n","    batch_size: int = 32,\n","    checkpoint_interval: int = 5,\n","    max_sentences: int = 100000\n","):\n","    translator = TranslationManager(api_key=api_key)\n","\n","    # Load checkpoint if exists\n","    checkpoint = translator.load_checkpoint(dataset_name)\n","    start_batch = checkpoint[\"last_batch\"] + 1\n","    translations_count = checkpoint[\"translations_count\"]\n","\n","    # Calculate starting line\n","    start_line = start_batch * batch_size\n","\n","    # Create iterator with sentence limit\n","    dataset_iterator = DatasetIterator(\n","        file_path=input_file,\n","        batch_size=batch_size,\n","        start_line=start_line,\n","        max_sentences=max_sentences\n","    )\n","\n","    cost_tracker = CostTracker()\n","    total_batches = max(1, min(dataset_iterator.total_lines, max_sentences) // batch_size)\n","\n","    print(f\"Starting from batch {start_batch}, line {start_line}\")\n","    print(f\"Will process up to {max_sentences} sentences\")\n","    print(f\"Total lines to process: {min(dataset_iterator.total_lines, max_sentences)}\")\n","\n","    for batch_num, batch in enumerate(dataset_iterator, start=start_batch):\n","        try:\n","            batch_id = f\"{dataset_name}_{batch_num}\"\n","            translations, response = translator.translate_batch(batch, batch_id)\n","\n","            if response is not None:\n","                cost_tracker.update(response)\n","\n","            save_pairs(batch, translations, dataset_name, mode=\"a\")\n","            translations_count += len(translations)\n","\n","            if batch_num % checkpoint_interval == 0:\n","                translator.save_checkpoint(dataset_name, batch_num, translations_count)\n","                print(f\"Checkpoint saved at batch {batch_num}\")\n","\n","            print(f\"Processed batch {batch_num}/{total_batches} ({len(batch)} items)\")\n","            if batch_num % 10 == 0:\n","                print(cost_tracker.report())\n","\n","            # Add a small delay to avoid rate limiting\n","            time.sleep(0.5)\n","\n","        except Exception as e:\n","            print(f\"Error processing batch {batch_num}: {str(e)}\")\n","            translator.save_checkpoint(dataset_name, batch_num-1, translations_count)\n","            time.sleep(1)  # Longer delay on error\n","            continue\n","\n","    # Final checkpoint and report\n","    translator.save_checkpoint(dataset_name, total_batches-1, translations_count)\n","    print(\"\\nFinal Statistics:\")\n","    print(cost_tracker.report())\n","    print(f\"Total translations: {translations_count}\")\n"],"metadata":{"id":"Gfg7kpM_w8CV","executionInfo":{"status":"ok","timestamp":1739357280559,"user_tz":-60,"elapsed":75,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    input_file = \"/content/drive/My Drive/Colab Notebooks/para-nmt-50m-small.txt\"\n","    dataset_name = \"para-nmt-50m-small_test\"\n","    max_sentences = 100000  # Total number of sentences to process\n","\n","    try:\n","        from google.colab import userdata\n","        api_key = userdata.get('OPENAI_API_KEY')\n","    except ImportError:\n","        api_key = os.getenv('OPENAI_API_KEY')\n","\n","    if not api_key:\n","        raise ValueError(\"API key not found. Please set the OPENAI_API_KEY in Colab secrets or environment variables.\")\n","\n","    process_dataset(\n","        input_file=input_file,\n","        dataset_name=dataset_name,\n","        api_key=api_key,\n","        batch_size=32,\n","        checkpoint_interval=10,  # Increased for larger dataset\n","        max_sentences=max_sentences,\n","    )\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"m4OcKbcpxFv_","executionInfo":{"status":"error","timestamp":1739437536105,"user_tz":-60,"elapsed":978,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"db7c484b-a4cf-4dde-bbd7-a7d65307bc36"},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'process_dataset' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-56617cb1b9d0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"API key not found. Please set the OPENAI_API_KEY in Colab secrets or environment variables.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     process_dataset(\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0minput_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'process_dataset' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"iZetRXUWBkXq"},"source":["## **ppdb-1.0-s-m2o**"]},{"cell_type":"markdown","source":["#### Processed batch 50/1666 (32 items)\n","\n","        API Calls: 51\n","        Total Tokens: 537225\n","        Estimated Cost: $1.07\n","        \n","Processed batch 51/1666 (32 items)\n","Processed batch 52/1666 (32 items)"],"metadata":{"id":"4M10q7Ite_fu"}},{"cell_type":"code","source":["from typing import Iterator, List, Dict, Any, Tuple, Optional\n","import json\n","import os\n","from pathlib import Path\n","from datetime import datetime\n","from openai import OpenAI\n","from openai.types.chat import ChatCompletion\n","import time\n","\n","class TranslationManager:\n","    def __init__(self, api_key: str, cache_dir: str = \"translation_cache\", checkpoint_dir: str = \"checkpoints\"):\n","        self.client = OpenAI(api_key=api_key)\n","        self.cache_dir = Path(cache_dir)\n","        self.checkpoint_dir = Path(checkpoint_dir)\n","        self.cache_dir.mkdir(exist_ok=True)\n","        self.checkpoint_dir.mkdir(exist_ok=True)\n","        self.batch_cache = {}\n","        self.current_cache_size = 0\n","        self.max_cache_size = 1000\n","\n","    def _get_cache_file(self, batch_id: str) -> Path:\n","        return self.cache_dir / f\"cache_{batch_id}.json\"\n","\n","    def get_checkpoint_file(self, dataset_name: str) -> Path:\n","        return self.checkpoint_dir / f\"{dataset_name}_checkpoint.json\"\n","\n","    def _save_batch_cache(self, batch_id: str):\n","        cache_file = self._get_cache_file(batch_id)\n","        with open(cache_file, 'w', encoding='utf-8') as f:\n","            json.dump(self.batch_cache, f, ensure_ascii=False, indent=2)\n","        self.batch_cache = {}\n","        self.current_cache_size = 0\n","\n","    def _load_cache(self, batch_id: str) -> Dict:\n","        cache_file = self._get_cache_file(batch_id)\n","        if cache_file.exists():\n","            with open(cache_file, 'r', encoding='utf-8') as f:\n","                return json.load(f)\n","        return {}\n","\n","    def save_checkpoint(self, dataset_name: str, batch_num: int, translations_count: int):\n","        checkpoint_data = {\n","            \"last_batch\": batch_num,\n","            \"translations_count\": translations_count,\n","            \"timestamp\": datetime.now().isoformat()\n","        }\n","        checkpoint_file = self.get_checkpoint_file(dataset_name)\n","        with open(checkpoint_file, 'w', encoding='utf-8') as f:\n","            json.dump(checkpoint_data, f, indent=2)\n","\n","    def load_checkpoint(self, dataset_name: str) -> Dict:\n","        checkpoint_file = self.get_checkpoint_file(dataset_name)\n","        if checkpoint_file.exists():\n","            with open(checkpoint_file, 'r', encoding='utf-8') as f:\n","                return json.load(f)\n","        return {\"last_batch\": -1, \"translations_count\": 0}\n","\n","    def translate_batch(self, texts: List[str], batch_id: str) -> Tuple[List[str], Optional[ChatCompletion]]:\n","        if not texts:\n","            return [], None\n","\n","        try:\n","            cache = self._load_cache(batch_id)\n","            translations = [\"\"] * len(texts)  # Initialize with empty strings\n","            uncached_texts = []\n","            uncached_indices = []\n","\n","            for i, text in enumerate(texts):\n","                text = text.strip()\n","                if text in cache:\n","                    translations[i] = cache[text]\n","                else:\n","                    uncached_texts.append(text)\n","                    uncached_indices.append(i)\n","\n","            if uncached_texts:\n","                retry_attempts = 3\n","                for attempt in range(retry_attempts):\n","                    try:\n","                        response = self.client.chat.completions.create(\n","                            model=\"gpt-3.5-turbo\",\n","                            messages=[\n","                                {\"role\": \"system\", \"content\": \"Translate the following English texts to Slovenian:\"},\n","                                {\"role\": \"user\", \"content\": \"\\n-\\n\".join(uncached_texts)}\n","                            ],\n","                            temperature=0.3\n","                        )\n","\n","                        new_translations = [choice.message.content for choice in response.choices]\n","\n","                        # Ensure we have the same number of translations as input texts\n","                        if len(new_translations) != len(uncached_texts):\n","                            new_translations = new_translations[:len(uncached_texts)]\n","                            if len(new_translations) < len(uncached_texts):\n","                                new_translations.extend([\"\"] * (len(uncached_texts) - len(new_translations)))\n","\n","                        for text, trans in zip(uncached_texts, new_translations):\n","                            self.batch_cache[text] = trans\n","                            self.current_cache_size += 1\n","\n","                        for idx, trans in zip(uncached_indices, new_translations):\n","                            translations[idx] = trans\n","\n","                        if self.current_cache_size >= self.max_cache_size:\n","                            self._save_batch_cache(batch_id)\n","\n","                        return translations, response\n","\n","                    except Exception as e:\n","                        print(f\"Error in API call (attempt {attempt + 1}/{retry_attempts}): {str(e)}\")\n","                        if attempt < retry_attempts - 1:\n","                            time.sleep(2)  # Wait before retrying\n","                        else:\n","                            # If all attempts fail, log the error and return partial results\n","                            for idx in uncached_indices:\n","                                translations[idx] = f\"ERROR: {str(e)}\"\n","                            return translations, None\n","\n","            return translations, None\n","\n","        except Exception as e:\n","            print(f\"Error in batch processing: {str(e)}\")\n","            return [f\"ERROR: {str(e)}\"] * len(texts), None\n","\n","class DatasetIterator:\n","    def __init__(self, file_path: str, batch_size: int, start_line: int = 0, max_sentences: int = 10949):\n","        self.file_path = file_path\n","        self.batch_size = batch_size\n","        self.max_sentences = max_sentences\n","        self.total_lines = min(self._count_lines(), max_sentences)  # Limit total lines\n","        self.start_line = min(start_line, max(0, self.total_lines - 1))\n","\n","    def _count_lines(self) -> int:\n","        try:\n","            with open(self.file_path, \"rb\") as f:\n","                return sum(1 for _ in f)\n","        except Exception as e:\n","            print(f\"Error counting lines: {str(e)}\")\n","            return 0\n","\n","    def __iter__(self) -> Iterator[List[str]]:\n","        current_batch = []\n","        processed_lines = 0\n","\n","        try:\n","            with open(self.file_path, \"rb\") as f:\n","                # Skip to start line\n","                for _ in range(self.start_line):\n","                    next(f, None)\n","\n","                for line in f:\n","                    if processed_lines >= self.max_sentences:\n","                        break\n","\n","                    try:\n","                        text = line.strip().decode('utf-8')\n","                        if text:  # Only add non-empty texts\n","                            current_batch.append(text)\n","                            processed_lines += 1\n","\n","                            if len(current_batch) == self.batch_size:\n","                                yield current_batch\n","                                current_batch = []\n","                    except Exception as e:\n","                        print(f\"Error processing line: {line.strip()}\")\n","                        print(f\"Error details: {str(e)}\")\n","                        continue\n","\n","                if current_batch:  # Don't forget last partial batch\n","                    yield current_batch\n","\n","        except Exception as e:\n","            print(f\"Error reading file: {str(e)}\")\n","            if current_batch:  # Yield any remaining batch on error\n","                yield current_batch\n","\n","class CostTracker:\n","    def __init__(self):\n","        self.requests = 0\n","        self.total_tokens = 0\n","        self.price_per_1k_tokens = 0.002\n","\n","    def update(self, response: ChatCompletion):\n","        self.requests += 1\n","        self.total_tokens += response.usage.completion_tokens + response.usage.prompt_tokens\n","\n","    def get_cost(self) -> float:\n","        return (self.total_tokens / 1000) * self.price_per_1k_tokens\n","\n","    def report(self) -> str:\n","        return f\"\"\"\n","        API Calls: {self.requests}\n","        Total Tokens: {self.total_tokens}\n","        Estimated Cost: ${self.get_cost():.2f}\n","        \"\"\"\n","\n","def save_pairs(originals: List[str], translations: List[str], dataset_name: str, mode: str = \"a\"):\n","    base_path = Path(\"/content/drive/My Drive/Colab Notebooks\")\n","\n","    for filename, data in [\n","        (f\"{dataset_name}_originals_GPT3.5.txt\", originals),\n","        (f\"{dataset_name}_translations_GPT3.5.txt\", translations),\n","    ]:\n","        try:\n","            with open(base_path / filename, mode, encoding=\"utf-8\") as f:\n","                for item in data:\n","                    f.write(f\"{item}\\n\")\n","        except Exception as e:\n","            print(f\"Error saving to {filename}: {str(e)}\")\n","\n","    try:\n","        with open(base_path / f\"{dataset_name}_aligned_pairs_GPT3.5.txt\", mode, encoding=\"utf-8\") as f:\n","            for orig, trans in zip(originals, translations):\n","                f.write(f\"Original: {orig}\\nTranslation: {trans}\\n---\\n\")\n","    except Exception as e:\n","        print(f\"Error saving aligned pairs: {str(e)}\")\n","\n","def process_dataset(\n","    input_file: str,\n","    dataset_name: str,\n","    api_key: str,\n","    batch_size: int = 32,\n","    checkpoint_interval: int = 5,\n","    max_sentences: int = 53315\n","):\n","    translator = TranslationManager(api_key=api_key)\n","\n","    # Load checkpoint if exists\n","    checkpoint = translator.load_checkpoint(dataset_name)\n","    start_batch = checkpoint[\"last_batch\"] + 1\n","    translations_count = checkpoint[\"translations_count\"]\n","\n","    # Calculate starting line\n","    start_line = start_batch * batch_size\n","\n","    # Create iterator with sentence limit\n","    dataset_iterator = DatasetIterator(\n","        file_path=input_file,\n","        batch_size=batch_size,\n","        start_line=start_line,\n","        max_sentences=max_sentences\n","    )\n","\n","    cost_tracker = CostTracker()\n","    total_batches = max(1, min(dataset_iterator.total_lines, max_sentences) // batch_size)\n","\n","    print(f\"Starting from batch {start_batch}, line {start_line}\")\n","    print(f\"Will process up to {max_sentences} sentences\")\n","    print(f\"Total lines to process: {min(dataset_iterator.total_lines, max_sentences)}\")\n","\n","    for batch_num, batch in enumerate(dataset_iterator, start=start_batch):\n","        try:\n","            batch_id = f\"{dataset_name}_{batch_num}\"\n","            translations, response = translator.translate_batch(batch, batch_id)\n","\n","            if response is not None:\n","                cost_tracker.update(response)\n","\n","            save_pairs(batch, translations, dataset_name, mode=\"a\")\n","            translations_count += len(translations)\n","\n","            if batch_num % checkpoint_interval == 0:\n","                translator.save_checkpoint(dataset_name, batch_num, translations_count)\n","                print(f\"Checkpoint saved at batch {batch_num}\")\n","\n","            print(f\"Processed batch {batch_num}/{total_batches} ({len(batch)} items)\")\n","            if batch_num % 10 == 0:\n","                print(cost_tracker.report())\n","\n","            # Add a small delay to avoid rate limiting\n","            time.sleep(0.5)\n","\n","        except Exception as e:\n","            print(f\"Error processing batch {batch_num}: {str(e)}\")\n","            translator.save_checkpoint(dataset_name, batch_num-1, translations_count)\n","            time.sleep(1)  # Longer delay on error\n","            continue\n","\n","    # Final checkpoint and report\n","    translator.save_checkpoint(dataset_name, total_batches-1, translations_count)\n","    print(\"\\nFinal Statistics:\")\n","    print(cost_tracker.report())\n","    print(f\"Total translations: {translations_count}\")\n"],"metadata":{"id":"-_NetKpqc929","executionInfo":{"status":"ok","timestamp":1739355041791,"user_tz":-60,"elapsed":413,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    input_file = \"/content/drive/My Drive/Colab Notebooks/ppdb-1.0-s-m2o\"\n","    dataset_name = \"ppdb-1.0-s-m2o_test\"\n","    max_sentences = 53315  # Total number of sentences to process\n","\n","    try:\n","        from google.colab import userdata\n","        api_key = userdata.get('OPENAI_API_KEY')\n","    except ImportError:\n","        api_key = os.getenv('OPENAI_API_KEY')\n","\n","    if not api_key:\n","        raise ValueError(\"API key not found. Please set the OPENAI_API_KEY in Colab secrets or environment variables.\")\n","\n","    process_dataset(\n","        input_file=input_file,\n","        dataset_name=dataset_name,\n","        api_key=api_key,\n","        batch_size=32,\n","        checkpoint_interval=10,  # Increased for larger dataset\n","        max_sentences=max_sentences,\n","    )\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"yeoIw578nCt3","executionInfo":{"status":"error","timestamp":1739356753408,"user_tz":-60,"elapsed":102592,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"8bfcd8e6-d071-46a7-e669-e3e92417696a"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting from batch 0, line 0\n","Will process up to 53315 sentences\n","Total lines to process: 53315\n","Checkpoint saved at batch 0\n","Processed batch 0/1666 (32 items)\n","\n","        API Calls: 1\n","        Total Tokens: 7785\n","        Estimated Cost: $0.02\n","        \n","Processed batch 1/1666 (32 items)\n","Processed batch 2/1666 (32 items)\n","Processed batch 3/1666 (32 items)\n","Processed batch 4/1666 (32 items)\n","Processed batch 5/1666 (32 items)\n","Processed batch 6/1666 (32 items)\n","Processed batch 7/1666 (32 items)\n","Processed batch 8/1666 (32 items)\n","Processed batch 9/1666 (32 items)\n","Checkpoint saved at batch 10\n","Processed batch 10/1666 (32 items)\n","\n","        API Calls: 11\n","        Total Tokens: 113148\n","        Estimated Cost: $0.23\n","        \n","Processed batch 11/1666 (32 items)\n","Processed batch 12/1666 (32 items)\n","Processed batch 13/1666 (32 items)\n","Processed batch 14/1666 (32 items)\n","Processed batch 15/1666 (32 items)\n","Processed batch 16/1666 (32 items)\n","Processed batch 17/1666 (32 items)\n","Processed batch 18/1666 (32 items)\n","Processed batch 19/1666 (32 items)\n","Checkpoint saved at batch 20\n","Processed batch 20/1666 (32 items)\n","\n","        API Calls: 21\n","        Total Tokens: 218383\n","        Estimated Cost: $0.44\n","        \n","Processed batch 21/1666 (32 items)\n","Processed batch 22/1666 (32 items)\n","Processed batch 23/1666 (32 items)\n","Processed batch 24/1666 (32 items)\n","Processed batch 25/1666 (32 items)\n","Processed batch 26/1666 (32 items)\n","Processed batch 27/1666 (32 items)\n","Processed batch 28/1666 (32 items)\n","Processed batch 29/1666 (32 items)\n","Checkpoint saved at batch 30\n","Processed batch 30/1666 (32 items)\n","\n","        API Calls: 31\n","        Total Tokens: 319473\n","        Estimated Cost: $0.64\n","        \n","Processed batch 31/1666 (32 items)\n","Processed batch 32/1666 (32 items)\n","Processed batch 33/1666 (32 items)\n","Processed batch 34/1666 (32 items)\n","Processed batch 35/1666 (32 items)\n","Processed batch 36/1666 (32 items)\n","Processed batch 37/1666 (32 items)\n","Processed batch 38/1666 (32 items)\n","Processed batch 39/1666 (32 items)\n","Checkpoint saved at batch 40\n","Processed batch 40/1666 (32 items)\n","\n","        API Calls: 41\n","        Total Tokens: 424584\n","        Estimated Cost: $0.85\n","        \n","Processed batch 41/1666 (32 items)\n","Processed batch 42/1666 (32 items)\n","Processed batch 43/1666 (32 items)\n","Processed batch 44/1666 (32 items)\n","Processed batch 45/1666 (32 items)\n","Processed batch 46/1666 (32 items)\n","Processed batch 47/1666 (32 items)\n","Processed batch 48/1666 (32 items)\n","Processed batch 49/1666 (32 items)\n","Checkpoint saved at batch 50\n","Processed batch 50/1666 (32 items)\n","\n","        API Calls: 51\n","        Total Tokens: 537225\n","        Estimated Cost: $1.07\n","        \n","Processed batch 51/1666 (32 items)\n","Processed batch 52/1666 (32 items)\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-2735f72bc999>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"API key not found. Please set the OPENAI_API_KEY in Colab secrets or environment variables.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     process_dataset(\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0minput_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-933115c55510>\u001b[0m in \u001b[0;36mprocess_dataset\u001b[0;34m(input_file, dataset_name, api_key, batch_size, checkpoint_interval, max_sentences)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mbatch_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{dataset_name}_{batch_num}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             \u001b[0mtranslations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-933115c55510>\u001b[0m in \u001b[0;36mtranslate_batch\u001b[0;34m(self, texts, batch_id)\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mattempt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_attempts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                         response = self.client.chat.completions.create(\n\u001b[0m\u001b[1;32m     81\u001b[0m                             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                             messages=[\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    861\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m    862\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    864\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             body=maybe_transform(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1281\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m         )\n\u001b[0;32m-> 1283\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m     def patch(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[0mretries_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    961\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m             response = self._client.send(\n\u001b[0m\u001b[1;32m    997\u001b[0m                 \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m                 \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stream_response_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0mauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_request_auth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         response = self._send_handling_auth(\n\u001b[0m\u001b[1;32m    915\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m                 response = self._send_handling_redirects(\n\u001b[0m\u001b[1;32m    943\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m                     \u001b[0mfollow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_redirects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    977\u001b[0m                 \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_single_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSyncByteStream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    248\u001b[0m         )\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_connections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;31m# Return the response. Note that in this case we still have to manage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m                     \u001b[0;31m# Send the request on the assigned connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                     response = connection.handle_request(\n\u001b[0m\u001b[1;32m    237\u001b[0m                         \u001b[0mpool_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                     )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNetworkStream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"response_closed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;31m# Sending the request...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    104\u001b[0m                     \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mtrailing_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 ) = self._receive_response_headers(**kwargs)\n\u001b[0m\u001b[1;32m    107\u001b[0m                 trace.return_value = (\n\u001b[1;32m    108\u001b[0m                     \u001b[0mhttp_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEED_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 data = self._network_stream.read(\n\u001b[0m\u001b[1;32m    218\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_NUM_BYTES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_backends/sync.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1293\u001b[0m                     \u001b[0;34m\"non-zero flags not allowed in calls to recv() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m                     self.__class__)\n\u001b[0;32m-> 1295\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1166\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"2uD21LepBkXu"},"source":["## **paws_train.tsv**"]},{"cell_type":"markdown","source":["#### Final Statistics:\n","\n","        API Calls: 1544\n","        Total Tokens: 3364654\n","        Estimated Cost: $6.73\n","        \n","Total translations: 49401"],"metadata":{"id":"zLqJihJifL3b"}},{"cell_type":"code","source":["# Code for translating TSV dataset with batching and checkpoints\n","\n","from typing import Iterator, List, Dict, Any, Tuple, Optional\n","import numpy as np\n","import json\n","import os\n","from pathlib import Path\n","from datetime import datetime\n","from openai import OpenAI\n","from openai.types.chat import ChatCompletion\n","import time\n","\n","class TranslationManager:\n","    def __init__(self, api_key: str, cache_dir: str = \"translation_cache\", checkpoint_dir: str = \"checkpoints\"):\n","        self.client = OpenAI(api_key=api_key)\n","        self.cache_dir = Path(cache_dir)\n","        self.checkpoint_dir = Path(checkpoint_dir)\n","        self.cache_dir.mkdir(exist_ok=True)\n","        self.checkpoint_dir.mkdir(exist_ok=True)\n","        self.batch_cache = {}\n","        self.current_cache_size = 0\n","        self.max_cache_size = 1000\n","\n","    def _get_cache_file(self, batch_id: str) -> Path:\n","        return self.cache_dir / f\"cache_{batch_id}.json\"\n","\n","    def get_checkpoint_file(self, dataset_name: str) -> Path:\n","        return self.checkpoint_dir / f\"{dataset_name}_checkpoint.json\"\n","\n","    def _save_batch_cache(self, batch_id: str):\n","        cache_file = self._get_cache_file(batch_id)\n","        with open(cache_file, 'w', encoding='utf-8') as f:\n","            json.dump(self.batch_cache, f, ensure_ascii=False, indent=2)\n","        self.batch_cache = {}\n","        self.current_cache_size = 0\n","\n","    def _load_cache(self, batch_id: str) -> Dict:\n","        cache_file = self._get_cache_file(batch_id)\n","        if cache_file.exists():\n","            with open(cache_file, 'r', encoding='utf-8') as f:\n","                return json.load(f)\n","        return {}\n","\n","    def save_checkpoint(self, dataset_name: str, batch_num: int, translations_count: int):\n","        checkpoint_data = {\n","            \"last_batch\": batch_num,\n","            \"translations_count\": translations_count,\n","            \"timestamp\": datetime.now().isoformat()\n","        }\n","        checkpoint_file = self.get_checkpoint_file(dataset_name)\n","        with open(checkpoint_file, 'w', encoding='utf-8') as f:\n","            json.dump(checkpoint_data, f, indent=2)\n","\n","    def load_checkpoint(self, dataset_name: str) -> Dict:\n","        checkpoint_file = self.get_checkpoint_file(dataset_name)\n","        if checkpoint_file.exists():\n","            with open(checkpoint_file, 'r', encoding='utf-8') as f:\n","                return json.load(f)\n","        return {\"last_batch\": -1, \"translations_count\": 0}\n","\n","    def translate_batch(self, texts: List[str], batch_id: str) -> Tuple[List[str], Optional[ChatCompletion]]:\n","        if not texts:\n","            return [], None\n","\n","        try:\n","            cache = self._load_cache(batch_id)\n","            translations = [\"\"] * len(texts)  # Initialize with empty strings\n","            uncached_texts = []\n","            uncached_indices = []\n","\n","            for i, text in enumerate(texts):\n","                text = text.strip()\n","                if text in cache:\n","                    translations[i] = cache[text]\n","                else:\n","                    uncached_texts.append(text)\n","                    uncached_indices.append(i)\n","\n","            if uncached_texts:\n","                retry_attempts = 3\n","                for attempt in range(retry_attempts):\n","                    try:\n","                        response = self.client.chat.completions.create(\n","                            model=\"gpt-3.5-turbo\",\n","                            messages=[\n","                                {\"role\": \"system\", \"content\": \"Translate the following English texts to Slovenian:\"},\n","                                {\"role\": \"user\", \"content\": \"\\n-\\n\".join(uncached_texts)}\n","                            ],\n","                            temperature=0.3\n","                        )\n","\n","                        new_translations = [choice.message.content for choice in response.choices]\n","\n","                        # Ensure we have the same number of translations as input texts\n","                        if len(new_translations) != len(uncached_texts):\n","                            new_translations = new_translations[:len(uncached_texts)]\n","                            if len(new_translations) < len(uncached_texts):\n","                                new_translations.extend([\"\"] * (len(uncached_texts) - len(new_translations)))\n","\n","                        for text, trans in zip(uncached_texts, new_translations):\n","                            self.batch_cache[text] = trans\n","                            self.current_cache_size += 1\n","\n","                        for idx, trans in zip(uncached_indices, new_translations):\n","                            translations[idx] = trans\n","\n","                        if self.current_cache_size >= self.max_cache_size:\n","                            self._save_batch_cache(batch_id)\n","\n","                        return translations, response\n","\n","                    except Exception as e:\n","                        print(f\"Error in API call (attempt {attempt + 1}/{retry_attempts}): {str(e)}\")\n","                        if attempt < retry_attempts - 1:\n","                            time.sleep(2)  # Wait before retrying\n","                        else:\n","                            # If all attempts fail, log the error and return partial results\n","                            for idx in uncached_indices:\n","                                translations[idx] = f\"ERROR: {str(e)}\"\n","                            return translations, None\n","\n","            return translations, None\n","\n","        except Exception as e:\n","            print(f\"Error in batch processing: {str(e)}\")\n","            return [f\"ERROR: {str(e)}\"] * len(texts), None\n","\n","\n","class DatasetIterator:\n","    def __init__(self, file_path: str, batch_size: int, start_line: int = 0, text_column_index: int = 1, max_sentences: int = 10949):\n","        self.file_path = file_path\n","        self.batch_size = batch_size\n","        self.text_column_index = text_column_index  # For TSV files, specify which column contains the text\n","        self.max_sentences = max_sentences\n","        self.total_lines = min(self._count_lines(), max_sentences)  # Limit total lines\n","        # Add 1 to account for header in TSV\n","        self.start_line = min(start_line + 1, max(0, self.total_lines - 1))\n","\n","    def _count_lines(self) -> int:\n","        try:\n","            with open(self.file_path, \"r\", encoding=\"utf-8\") as f:\n","                return sum(1 for _ in f)\n","        except Exception as e:\n","            print(f\"Error counting lines: {str(e)}\")\n","            return 0\n","\n","    def __iter__(self) -> Iterator[List[str]]:\n","        current_batch = []\n","        processed_lines = 0\n","\n","        try:\n","            with open(self.file_path, \"r\", encoding=\"utf-8\") as f:\n","                # Skip header\n","                header = next(f, None)\n","                if not header:\n","                    raise ValueError(\"Empty file or no header found\")\n","\n","                # Skip to start line (accounting for already skipped header)\n","                for _ in range(self.start_line - 1):\n","                    next(f, None)\n","\n","                for line in f:\n","                    if processed_lines >= self.max_sentences:\n","                        break\n","\n","                    try:\n","                        columns = line.strip().split('\\t')\n","                        if len(columns) > self.text_column_index:\n","                            text = columns[self.text_column_index].strip()\n","                            if text:  # Only add non-empty texts\n","                                current_batch.append(text)\n","                                processed_lines += 1\n","\n","                                if len(current_batch) == self.batch_size:\n","                                    yield current_batch\n","                                    current_batch = []\n","                    except Exception as e:\n","                        print(f\"Error processing line: {line.strip()}\")\n","                        print(f\"Error details: {str(e)}\")\n","                        continue\n","\n","                if current_batch:  # Don't forget last partial batch\n","                    yield current_batch\n","\n","        except Exception as e:\n","            print(f\"Error reading file: {str(e)}\")\n","            if current_batch:  # Yield any remaining batch on error\n","                yield current_batch\n","\n","class CostTracker:\n","    def __init__(self):\n","        self.requests = 0\n","        self.total_tokens = 0\n","        self.price_per_1k_tokens = 0.002\n","\n","    def update(self, response: ChatCompletion):\n","        self.requests += 1\n","        self.total_tokens += response.usage.completion_tokens + response.usage.prompt_tokens\n","\n","    def get_cost(self) -> float:\n","        return (self.total_tokens / 1000) * self.price_per_1k_tokens\n","\n","    def report(self) -> str:\n","        return f\"\"\"\n","        API Calls: {self.requests}\n","        Total Tokens: {self.total_tokens}\n","        Estimated Cost: ${self.get_cost():.2f}\n","        \"\"\"\n","\n","def save_pairs(originals: List[str], translations: List[str], dataset_name: str, mode: str = \"a\"):\n","    base_path = Path(\"/content/drive/My Drive/Colab Notebooks\")\n","\n","    for filename, data in [\n","        (f\"{dataset_name}_originals_GPT3.5.txt\", originals),\n","        (f\"{dataset_name}_translations_GPT3.5.txt\", translations),\n","    ]:\n","        try:\n","            with open(base_path / filename, mode, encoding=\"utf-8\") as f:\n","                for item in data:\n","                    f.write(f\"{item}\\n\")\n","        except Exception as e:\n","            print(f\"Error saving to {filename}: {str(e)}\")\n","\n","    try:\n","        with open(base_path / f\"{dataset_name}_aligned_pairs_GPT3.5.txt\", mode, encoding=\"utf-8\") as f:\n","            for orig, trans in zip(originals, translations):\n","                f.write(f\"Original: {orig}\\nTranslation: {trans}\\n---\\n\")\n","    except Exception as e:\n","        print(f\"Error saving aligned pairs: {str(e)}\")\n","\n","def process_dataset(\n","    input_file: str,\n","    dataset_name: str,\n","    api_key: str,\n","    batch_size: int = 32,\n","    checkpoint_interval: int = 5,\n","    max_sentences: int = 49402,\n","    text_column_index: int = 1\n","):\n","    translator = TranslationManager(api_key=api_key)\n","\n","    # Load checkpoint if exists\n","    checkpoint = translator.load_checkpoint(dataset_name)\n","    start_batch = checkpoint[\"last_batch\"] + 1\n","    translations_count = checkpoint[\"translations_count\"]\n","\n","    # Calculate starting line\n","    start_line = start_batch * batch_size\n","\n","    # Create iterator with sentence limit and TSV column index\n","    dataset_iterator = DatasetIterator(\n","        file_path=input_file,\n","        batch_size=batch_size,\n","        start_line=start_line,\n","        text_column_index=text_column_index,\n","        max_sentences=max_sentences\n","    )\n","\n","    cost_tracker = CostTracker()\n","    total_batches = max(1, min(dataset_iterator.total_lines, max_sentences) // batch_size)\n","\n","    print(f\"Starting from batch {start_batch}, line {start_line}\")\n","    print(f\"Will process up to {max_sentences} sentences\")\n","    print(f\"Total lines to process: {min(dataset_iterator.total_lines, max_sentences)}\")\n","    print(f\"Reading text from column index: {text_column_index}\")\n","\n","    for batch_num, batch in enumerate(dataset_iterator, start=start_batch):\n","        try:\n","            batch_id = f\"{dataset_name}_{batch_num}\"\n","            translations, response = translator.translate_batch(batch, batch_id)\n","\n","            if response is not None:\n","                cost_tracker.update(response)\n","\n","            save_pairs(batch, translations, dataset_name, mode=\"a\")\n","            translations_count += len(translations)\n","\n","            if batch_num % checkpoint_interval == 0:\n","                translator.save_checkpoint(dataset_name, batch_num, translations_count)\n","                print(f\"Checkpoint saved at batch {batch_num}\")\n","\n","            print(f\"Processed batch {batch_num}/{total_batches} ({len(batch)} items)\")\n","            if batch_num % 10 == 0:\n","                print(cost_tracker.report())\n","\n","            # Add a small delay to avoid rate limiting\n","            time.sleep(0.5)\n","\n","        except Exception as e:\n","            print(f\"Error processing batch {batch_num}: {str(e)}\")\n","            translator.save_checkpoint(dataset_name, batch_num-1, translations_count)\n","            time.sleep(1)  # Longer delay on error\n","            continue\n","\n","    # Final checkpoint and report\n","    translator.save_checkpoint(dataset_name, total_batches-1, translations_count)\n","    print(\"\\nFinal Statistics:\")\n","    print(cost_tracker.report())\n","    print(f\"Total translations: {translations_count}\")\n"],"metadata":{"id":"fo_M6FGuBgLR","executionInfo":{"status":"ok","timestamp":1739522496499,"user_tz":-60,"elapsed":1039,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["#### Execution of the code"],"metadata":{"id":"2F5tExbJ_kNs"}},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    input_file = \"/content/drive/My Drive/Colab Notebooks/paws_train.tsv\"\n","    dataset_name = \"paws_paraphrase_test\"\n","    max_sentences = 49402  # Total number of sentences to process\n","\n","    try:\n","        from google.colab import userdata\n","        api_key = userdata.get('OPENAI_API_KEY')\n","    except ImportError:\n","        api_key = os.getenv('OPENAI_API_KEY')\n","\n","    if not api_key:\n","        raise ValueError(\"API key not found. Please set the OPENAI_API_KEY in Colab secrets or environment variables.\")\n","\n","    process_dataset(\n","        input_file=input_file,\n","        dataset_name=dataset_name,\n","        api_key=api_key,\n","        batch_size=32,\n","        checkpoint_interval=10,  # Increased for larger dataset\n","        max_sentences=max_sentences,\n","        text_column_index=1  # Specify which column contains the text to translate\n","    )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pvsa3wqq6LwP","executionInfo":{"status":"ok","timestamp":1739542445602,"user_tz":-60,"elapsed":4463916,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"b7ea0967-2706-4f0e-bd35-bd7405c97d10"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting from batch 0, line 0\n","Will process up to 49402 sentences\n","Total lines to process: 49402\n","Reading text from column index: 1\n","Checkpoint saved at batch 0\n","Processed batch 0/1543 (32 items)\n","\n","        API Calls: 1\n","        Total Tokens: 1261\n","        Estimated Cost: $0.00\n","        \n","Processed batch 1/1543 (32 items)\n","Processed batch 2/1543 (32 items)\n","Processed batch 3/1543 (32 items)\n","Processed batch 4/1543 (32 items)\n","Processed batch 5/1543 (32 items)\n","Processed batch 6/1543 (32 items)\n","Processed batch 7/1543 (32 items)\n","Processed batch 8/1543 (32 items)\n","Processed batch 9/1543 (32 items)\n","Checkpoint saved at batch 10\n","Processed batch 10/1543 (32 items)\n","\n","        API Calls: 11\n","        Total Tokens: 22738\n","        Estimated Cost: $0.05\n","        \n","Processed batch 11/1543 (32 items)\n","Processed batch 12/1543 (32 items)\n","Processed batch 13/1543 (32 items)\n","Processed batch 14/1543 (32 items)\n","Processed batch 15/1543 (32 items)\n","Processed batch 16/1543 (32 items)\n","Processed batch 17/1543 (32 items)\n","Processed batch 18/1543 (32 items)\n","Processed batch 19/1543 (32 items)\n","Checkpoint saved at batch 20\n","Processed batch 20/1543 (32 items)\n","\n","        API Calls: 21\n","        Total Tokens: 44534\n","        Estimated Cost: $0.09\n","        \n","Processed batch 21/1543 (32 items)\n","Processed batch 22/1543 (32 items)\n","Processed batch 23/1543 (32 items)\n","Processed batch 24/1543 (32 items)\n","Processed batch 25/1543 (32 items)\n","Processed batch 26/1543 (32 items)\n","Processed batch 27/1543 (32 items)\n","Processed batch 28/1543 (32 items)\n","Processed batch 29/1543 (32 items)\n","Checkpoint saved at batch 30\n","Processed batch 30/1543 (32 items)\n","\n","        API Calls: 31\n","        Total Tokens: 66503\n","        Estimated Cost: $0.13\n","        \n","Processed batch 31/1543 (32 items)\n","Processed batch 32/1543 (32 items)\n","Processed batch 33/1543 (32 items)\n","Processed batch 34/1543 (32 items)\n","Processed batch 35/1543 (32 items)\n","Processed batch 36/1543 (32 items)\n","Processed batch 37/1543 (32 items)\n","Processed batch 38/1543 (32 items)\n","Processed batch 39/1543 (32 items)\n","Checkpoint saved at batch 40\n","Processed batch 40/1543 (32 items)\n","\n","        API Calls: 41\n","        Total Tokens: 87893\n","        Estimated Cost: $0.18\n","        \n","Processed batch 41/1543 (32 items)\n","Processed batch 42/1543 (32 items)\n","Processed batch 43/1543 (32 items)\n","Processed batch 44/1543 (32 items)\n","Processed batch 45/1543 (32 items)\n","Processed batch 46/1543 (32 items)\n","Processed batch 47/1543 (32 items)\n","Processed batch 48/1543 (32 items)\n","Processed batch 49/1543 (32 items)\n","Checkpoint saved at batch 50\n","Processed batch 50/1543 (32 items)\n","\n","        API Calls: 51\n","        Total Tokens: 109450\n","        Estimated Cost: $0.22\n","        \n","Processed batch 51/1543 (32 items)\n","Processed batch 52/1543 (32 items)\n","Processed batch 53/1543 (32 items)\n","Processed batch 54/1543 (32 items)\n","Processed batch 55/1543 (32 items)\n","Processed batch 56/1543 (32 items)\n","Processed batch 57/1543 (32 items)\n","Processed batch 58/1543 (32 items)\n","Processed batch 59/1543 (32 items)\n","Checkpoint saved at batch 60\n","Processed batch 60/1543 (32 items)\n","\n","        API Calls: 61\n","        Total Tokens: 131845\n","        Estimated Cost: $0.26\n","        \n","Processed batch 61/1543 (32 items)\n","Processed batch 62/1543 (32 items)\n","Processed batch 63/1543 (32 items)\n","Processed batch 64/1543 (32 items)\n","Processed batch 65/1543 (32 items)\n","Processed batch 66/1543 (32 items)\n","Processed batch 67/1543 (32 items)\n","Processed batch 68/1543 (32 items)\n","Processed batch 69/1543 (32 items)\n","Checkpoint saved at batch 70\n","Processed batch 70/1543 (32 items)\n","\n","        API Calls: 71\n","        Total Tokens: 153995\n","        Estimated Cost: $0.31\n","        \n","Processed batch 71/1543 (32 items)\n","Processed batch 72/1543 (32 items)\n","Processed batch 73/1543 (32 items)\n","Processed batch 74/1543 (32 items)\n","Processed batch 75/1543 (32 items)\n","Processed batch 76/1543 (32 items)\n","Processed batch 77/1543 (32 items)\n","Processed batch 78/1543 (32 items)\n","Processed batch 79/1543 (32 items)\n","Checkpoint saved at batch 80\n","Processed batch 80/1543 (32 items)\n","\n","        API Calls: 81\n","        Total Tokens: 175908\n","        Estimated Cost: $0.35\n","        \n","Processed batch 81/1543 (32 items)\n","Processed batch 82/1543 (32 items)\n","Processed batch 83/1543 (32 items)\n","Processed batch 84/1543 (32 items)\n","Processed batch 85/1543 (32 items)\n","Processed batch 86/1543 (32 items)\n","Processed batch 87/1543 (32 items)\n","Processed batch 88/1543 (32 items)\n","Processed batch 89/1543 (32 items)\n","Checkpoint saved at batch 90\n","Processed batch 90/1543 (32 items)\n","\n","        API Calls: 91\n","        Total Tokens: 198077\n","        Estimated Cost: $0.40\n","        \n","Processed batch 91/1543 (32 items)\n","Processed batch 92/1543 (32 items)\n","Processed batch 93/1543 (32 items)\n","Processed batch 94/1543 (32 items)\n","Processed batch 95/1543 (32 items)\n","Processed batch 96/1543 (32 items)\n","Processed batch 97/1543 (32 items)\n","Processed batch 98/1543 (32 items)\n","Processed batch 99/1543 (32 items)\n","Checkpoint saved at batch 100\n","Processed batch 100/1543 (32 items)\n","\n","        API Calls: 101\n","        Total Tokens: 220576\n","        Estimated Cost: $0.44\n","        \n","Processed batch 101/1543 (32 items)\n","Processed batch 102/1543 (32 items)\n","Processed batch 103/1543 (32 items)\n","Processed batch 104/1543 (32 items)\n","Processed batch 105/1543 (32 items)\n","Processed batch 106/1543 (32 items)\n","Processed batch 107/1543 (32 items)\n","Processed batch 108/1543 (32 items)\n","Processed batch 109/1543 (32 items)\n","Checkpoint saved at batch 110\n","Processed batch 110/1543 (32 items)\n","\n","        API Calls: 111\n","        Total Tokens: 242390\n","        Estimated Cost: $0.48\n","        \n","Processed batch 111/1543 (32 items)\n","Processed batch 112/1543 (32 items)\n","Processed batch 113/1543 (32 items)\n","Processed batch 114/1543 (32 items)\n","Processed batch 115/1543 (32 items)\n","Processed batch 116/1543 (32 items)\n","Processed batch 117/1543 (32 items)\n","Processed batch 118/1543 (32 items)\n","Processed batch 119/1543 (32 items)\n","Checkpoint saved at batch 120\n","Processed batch 120/1543 (32 items)\n","\n","        API Calls: 121\n","        Total Tokens: 263317\n","        Estimated Cost: $0.53\n","        \n","Processed batch 121/1543 (32 items)\n","Processed batch 122/1543 (32 items)\n","Processed batch 123/1543 (32 items)\n","Processed batch 124/1543 (32 items)\n","Processed batch 125/1543 (32 items)\n","Processed batch 126/1543 (32 items)\n","Processed batch 127/1543 (32 items)\n","Processed batch 128/1543 (32 items)\n","Processed batch 129/1543 (32 items)\n","Checkpoint saved at batch 130\n","Processed batch 130/1543 (32 items)\n","\n","        API Calls: 131\n","        Total Tokens: 283807\n","        Estimated Cost: $0.57\n","        \n","Processed batch 131/1543 (32 items)\n","Processed batch 132/1543 (32 items)\n","Processed batch 133/1543 (32 items)\n","Processed batch 134/1543 (32 items)\n","Processed batch 135/1543 (32 items)\n","Processed batch 136/1543 (32 items)\n","Processed batch 137/1543 (32 items)\n","Processed batch 138/1543 (32 items)\n","Processed batch 139/1543 (32 items)\n","Checkpoint saved at batch 140\n","Processed batch 140/1543 (32 items)\n","\n","        API Calls: 141\n","        Total Tokens: 306141\n","        Estimated Cost: $0.61\n","        \n","Processed batch 141/1543 (32 items)\n","Processed batch 142/1543 (32 items)\n","Processed batch 143/1543 (32 items)\n","Processed batch 144/1543 (32 items)\n","Processed batch 145/1543 (32 items)\n","Processed batch 146/1543 (32 items)\n","Processed batch 147/1543 (32 items)\n","Processed batch 148/1543 (32 items)\n","Processed batch 149/1543 (32 items)\n","Checkpoint saved at batch 150\n","Processed batch 150/1543 (32 items)\n","\n","        API Calls: 151\n","        Total Tokens: 328121\n","        Estimated Cost: $0.66\n","        \n","Processed batch 151/1543 (32 items)\n","Processed batch 152/1543 (32 items)\n","Processed batch 153/1543 (32 items)\n","Processed batch 154/1543 (32 items)\n","Processed batch 155/1543 (32 items)\n","Processed batch 156/1543 (32 items)\n","Processed batch 157/1543 (32 items)\n","Processed batch 158/1543 (32 items)\n","Processed batch 159/1543 (32 items)\n","Checkpoint saved at batch 160\n","Processed batch 160/1543 (32 items)\n","\n","        API Calls: 161\n","        Total Tokens: 349066\n","        Estimated Cost: $0.70\n","        \n","Processed batch 161/1543 (32 items)\n","Processed batch 162/1543 (32 items)\n","Processed batch 163/1543 (32 items)\n","Processed batch 164/1543 (32 items)\n","Processed batch 165/1543 (32 items)\n","Processed batch 166/1543 (32 items)\n","Processed batch 167/1543 (32 items)\n","Processed batch 168/1543 (32 items)\n","Processed batch 169/1543 (32 items)\n","Checkpoint saved at batch 170\n","Processed batch 170/1543 (32 items)\n","\n","        API Calls: 171\n","        Total Tokens: 370972\n","        Estimated Cost: $0.74\n","        \n","Processed batch 171/1543 (32 items)\n","Processed batch 172/1543 (32 items)\n","Processed batch 173/1543 (32 items)\n","Processed batch 174/1543 (32 items)\n","Processed batch 175/1543 (32 items)\n","Processed batch 176/1543 (32 items)\n","Processed batch 177/1543 (32 items)\n","Processed batch 178/1543 (32 items)\n","Processed batch 179/1543 (32 items)\n","Checkpoint saved at batch 180\n","Processed batch 180/1543 (32 items)\n","\n","        API Calls: 181\n","        Total Tokens: 393065\n","        Estimated Cost: $0.79\n","        \n","Processed batch 181/1543 (32 items)\n","Processed batch 182/1543 (32 items)\n","Processed batch 183/1543 (32 items)\n","Processed batch 184/1543 (32 items)\n","Processed batch 185/1543 (32 items)\n","Processed batch 186/1543 (32 items)\n","Processed batch 187/1543 (32 items)\n","Processed batch 188/1543 (32 items)\n","Processed batch 189/1543 (32 items)\n","Checkpoint saved at batch 190\n","Processed batch 190/1543 (32 items)\n","\n","        API Calls: 191\n","        Total Tokens: 415349\n","        Estimated Cost: $0.83\n","        \n","Processed batch 191/1543 (32 items)\n","Processed batch 192/1543 (32 items)\n","Processed batch 193/1543 (32 items)\n","Processed batch 194/1543 (32 items)\n","Processed batch 195/1543 (32 items)\n","Processed batch 196/1543 (32 items)\n","Processed batch 197/1543 (32 items)\n","Processed batch 198/1543 (32 items)\n","Processed batch 199/1543 (32 items)\n","Checkpoint saved at batch 200\n","Processed batch 200/1543 (32 items)\n","\n","        API Calls: 201\n","        Total Tokens: 437662\n","        Estimated Cost: $0.88\n","        \n","Processed batch 201/1543 (32 items)\n","Processed batch 202/1543 (32 items)\n","Processed batch 203/1543 (32 items)\n","Processed batch 204/1543 (32 items)\n","Processed batch 205/1543 (32 items)\n","Processed batch 206/1543 (32 items)\n","Processed batch 207/1543 (32 items)\n","Processed batch 208/1543 (32 items)\n","Processed batch 209/1543 (32 items)\n","Checkpoint saved at batch 210\n","Processed batch 210/1543 (32 items)\n","\n","        API Calls: 211\n","        Total Tokens: 459628\n","        Estimated Cost: $0.92\n","        \n","Processed batch 211/1543 (32 items)\n","Processed batch 212/1543 (32 items)\n","Processed batch 213/1543 (32 items)\n","Processed batch 214/1543 (32 items)\n","Processed batch 215/1543 (32 items)\n","Processed batch 216/1543 (32 items)\n","Processed batch 217/1543 (32 items)\n","Processed batch 218/1543 (32 items)\n","Processed batch 219/1543 (32 items)\n","Checkpoint saved at batch 220\n","Processed batch 220/1543 (32 items)\n","\n","        API Calls: 221\n","        Total Tokens: 481803\n","        Estimated Cost: $0.96\n","        \n","Processed batch 221/1543 (32 items)\n","Processed batch 222/1543 (32 items)\n","Processed batch 223/1543 (32 items)\n","Processed batch 224/1543 (32 items)\n","Processed batch 225/1543 (32 items)\n","Processed batch 226/1543 (32 items)\n","Processed batch 227/1543 (32 items)\n","Processed batch 228/1543 (32 items)\n","Processed batch 229/1543 (32 items)\n","Checkpoint saved at batch 230\n","Processed batch 230/1543 (32 items)\n","\n","        API Calls: 231\n","        Total Tokens: 503564\n","        Estimated Cost: $1.01\n","        \n","Processed batch 231/1543 (32 items)\n","Processed batch 232/1543 (32 items)\n","Processed batch 233/1543 (32 items)\n","Processed batch 234/1543 (32 items)\n","Processed batch 235/1543 (32 items)\n","Processed batch 236/1543 (32 items)\n","Processed batch 237/1543 (32 items)\n","Processed batch 238/1543 (32 items)\n","Processed batch 239/1543 (32 items)\n","Checkpoint saved at batch 240\n","Processed batch 240/1543 (32 items)\n","\n","        API Calls: 241\n","        Total Tokens: 525735\n","        Estimated Cost: $1.05\n","        \n","Processed batch 241/1543 (32 items)\n","Processed batch 242/1543 (32 items)\n","Processed batch 243/1543 (32 items)\n","Processed batch 244/1543 (32 items)\n","Processed batch 245/1543 (32 items)\n","Processed batch 246/1543 (32 items)\n","Processed batch 247/1543 (32 items)\n","Processed batch 248/1543 (32 items)\n","Processed batch 249/1543 (32 items)\n","Checkpoint saved at batch 250\n","Processed batch 250/1543 (32 items)\n","\n","        API Calls: 251\n","        Total Tokens: 547449\n","        Estimated Cost: $1.09\n","        \n","Processed batch 251/1543 (32 items)\n","Processed batch 252/1543 (32 items)\n","Processed batch 253/1543 (32 items)\n","Processed batch 254/1543 (32 items)\n","Processed batch 255/1543 (32 items)\n","Processed batch 256/1543 (32 items)\n","Processed batch 257/1543 (32 items)\n","Processed batch 258/1543 (32 items)\n","Processed batch 259/1543 (32 items)\n","Checkpoint saved at batch 260\n","Processed batch 260/1543 (32 items)\n","\n","        API Calls: 261\n","        Total Tokens: 569673\n","        Estimated Cost: $1.14\n","        \n","Processed batch 261/1543 (32 items)\n","Processed batch 262/1543 (32 items)\n","Processed batch 263/1543 (32 items)\n","Processed batch 264/1543 (32 items)\n","Processed batch 265/1543 (32 items)\n","Processed batch 266/1543 (32 items)\n","Processed batch 267/1543 (32 items)\n","Processed batch 268/1543 (32 items)\n","Processed batch 269/1543 (32 items)\n","Checkpoint saved at batch 270\n","Processed batch 270/1543 (32 items)\n","\n","        API Calls: 271\n","        Total Tokens: 591797\n","        Estimated Cost: $1.18\n","        \n","Processed batch 271/1543 (32 items)\n","Processed batch 272/1543 (32 items)\n","Processed batch 273/1543 (32 items)\n","Processed batch 274/1543 (32 items)\n","Processed batch 275/1543 (32 items)\n","Processed batch 276/1543 (32 items)\n","Processed batch 277/1543 (32 items)\n","Processed batch 278/1543 (32 items)\n","Processed batch 279/1543 (32 items)\n","Checkpoint saved at batch 280\n","Processed batch 280/1543 (32 items)\n","\n","        API Calls: 281\n","        Total Tokens: 613714\n","        Estimated Cost: $1.23\n","        \n","Processed batch 281/1543 (32 items)\n","Processed batch 282/1543 (32 items)\n","Processed batch 283/1543 (32 items)\n","Processed batch 284/1543 (32 items)\n","Processed batch 285/1543 (32 items)\n","Processed batch 286/1543 (32 items)\n","Processed batch 287/1543 (32 items)\n","Processed batch 288/1543 (32 items)\n","Processed batch 289/1543 (32 items)\n","Checkpoint saved at batch 290\n","Processed batch 290/1543 (32 items)\n","\n","        API Calls: 291\n","        Total Tokens: 635777\n","        Estimated Cost: $1.27\n","        \n","Processed batch 291/1543 (32 items)\n","Processed batch 292/1543 (32 items)\n","Processed batch 293/1543 (32 items)\n","Processed batch 294/1543 (32 items)\n","Processed batch 295/1543 (32 items)\n","Processed batch 296/1543 (32 items)\n","Processed batch 297/1543 (32 items)\n","Processed batch 298/1543 (32 items)\n","Processed batch 299/1543 (32 items)\n","Checkpoint saved at batch 300\n","Processed batch 300/1543 (32 items)\n","\n","        API Calls: 301\n","        Total Tokens: 657433\n","        Estimated Cost: $1.31\n","        \n","Processed batch 301/1543 (32 items)\n","Processed batch 302/1543 (32 items)\n","Processed batch 303/1543 (32 items)\n","Processed batch 304/1543 (32 items)\n","Processed batch 305/1543 (32 items)\n","Processed batch 306/1543 (32 items)\n","Processed batch 307/1543 (32 items)\n","Processed batch 308/1543 (32 items)\n","Processed batch 309/1543 (32 items)\n","Checkpoint saved at batch 310\n","Processed batch 310/1543 (32 items)\n","\n","        API Calls: 311\n","        Total Tokens: 678459\n","        Estimated Cost: $1.36\n","        \n","Processed batch 311/1543 (32 items)\n","Processed batch 312/1543 (32 items)\n","Processed batch 313/1543 (32 items)\n","Processed batch 314/1543 (32 items)\n","Processed batch 315/1543 (32 items)\n","Processed batch 316/1543 (32 items)\n","Processed batch 317/1543 (32 items)\n","Processed batch 318/1543 (32 items)\n","Processed batch 319/1543 (32 items)\n","Checkpoint saved at batch 320\n","Processed batch 320/1543 (32 items)\n","\n","        API Calls: 321\n","        Total Tokens: 700766\n","        Estimated Cost: $1.40\n","        \n","Processed batch 321/1543 (32 items)\n","Processed batch 322/1543 (32 items)\n","Processed batch 323/1543 (32 items)\n","Processed batch 324/1543 (32 items)\n","Processed batch 325/1543 (32 items)\n","Processed batch 326/1543 (32 items)\n","Processed batch 327/1543 (32 items)\n","Processed batch 328/1543 (32 items)\n","Processed batch 329/1543 (32 items)\n","Checkpoint saved at batch 330\n","Processed batch 330/1543 (32 items)\n","\n","        API Calls: 331\n","        Total Tokens: 722555\n","        Estimated Cost: $1.45\n","        \n","Processed batch 331/1543 (32 items)\n","Processed batch 332/1543 (32 items)\n","Processed batch 333/1543 (32 items)\n","Processed batch 334/1543 (32 items)\n","Processed batch 335/1543 (32 items)\n","Processed batch 336/1543 (32 items)\n","Processed batch 337/1543 (32 items)\n","Processed batch 338/1543 (32 items)\n","Processed batch 339/1543 (32 items)\n","Checkpoint saved at batch 340\n","Processed batch 340/1543 (32 items)\n","\n","        API Calls: 341\n","        Total Tokens: 744144\n","        Estimated Cost: $1.49\n","        \n","Processed batch 341/1543 (32 items)\n","Processed batch 342/1543 (32 items)\n","Processed batch 343/1543 (32 items)\n","Processed batch 344/1543 (32 items)\n","Processed batch 345/1543 (32 items)\n","Processed batch 346/1543 (32 items)\n","Processed batch 347/1543 (32 items)\n","Processed batch 348/1543 (32 items)\n","Processed batch 349/1543 (32 items)\n","Checkpoint saved at batch 350\n","Processed batch 350/1543 (32 items)\n","\n","        API Calls: 351\n","        Total Tokens: 765062\n","        Estimated Cost: $1.53\n","        \n","Processed batch 351/1543 (32 items)\n","Processed batch 352/1543 (32 items)\n","Processed batch 353/1543 (32 items)\n","Processed batch 354/1543 (32 items)\n","Processed batch 355/1543 (32 items)\n","Processed batch 356/1543 (32 items)\n","Processed batch 357/1543 (32 items)\n","Processed batch 358/1543 (32 items)\n","Processed batch 359/1543 (32 items)\n","Checkpoint saved at batch 360\n","Processed batch 360/1543 (32 items)\n","\n","        API Calls: 361\n","        Total Tokens: 786576\n","        Estimated Cost: $1.57\n","        \n","Processed batch 361/1543 (32 items)\n","Processed batch 362/1543 (32 items)\n","Processed batch 363/1543 (32 items)\n","Processed batch 364/1543 (32 items)\n","Processed batch 365/1543 (32 items)\n","Processed batch 366/1543 (32 items)\n","Processed batch 367/1543 (32 items)\n","Processed batch 368/1543 (32 items)\n","Processed batch 369/1543 (32 items)\n","Checkpoint saved at batch 370\n","Processed batch 370/1543 (32 items)\n","\n","        API Calls: 371\n","        Total Tokens: 808379\n","        Estimated Cost: $1.62\n","        \n","Processed batch 371/1543 (32 items)\n","Processed batch 372/1543 (32 items)\n","Processed batch 373/1543 (32 items)\n","Processed batch 374/1543 (32 items)\n","Processed batch 375/1543 (32 items)\n","Processed batch 376/1543 (32 items)\n","Processed batch 377/1543 (32 items)\n","Processed batch 378/1543 (32 items)\n","Processed batch 379/1543 (32 items)\n","Checkpoint saved at batch 380\n","Processed batch 380/1543 (32 items)\n","\n","        API Calls: 381\n","        Total Tokens: 830597\n","        Estimated Cost: $1.66\n","        \n","Processed batch 381/1543 (32 items)\n","Processed batch 382/1543 (32 items)\n","Processed batch 383/1543 (32 items)\n","Processed batch 384/1543 (32 items)\n","Processed batch 385/1543 (32 items)\n","Processed batch 386/1543 (32 items)\n","Processed batch 387/1543 (32 items)\n","Processed batch 388/1543 (32 items)\n","Processed batch 389/1543 (32 items)\n","Checkpoint saved at batch 390\n","Processed batch 390/1543 (32 items)\n","\n","        API Calls: 391\n","        Total Tokens: 852648\n","        Estimated Cost: $1.71\n","        \n","Processed batch 391/1543 (32 items)\n","Processed batch 392/1543 (32 items)\n","Processed batch 393/1543 (32 items)\n","Processed batch 394/1543 (32 items)\n","Processed batch 395/1543 (32 items)\n","Processed batch 396/1543 (32 items)\n","Processed batch 397/1543 (32 items)\n","Processed batch 398/1543 (32 items)\n","Processed batch 399/1543 (32 items)\n","Checkpoint saved at batch 400\n","Processed batch 400/1543 (32 items)\n","\n","        API Calls: 401\n","        Total Tokens: 874781\n","        Estimated Cost: $1.75\n","        \n","Processed batch 401/1543 (32 items)\n","Processed batch 402/1543 (32 items)\n","Processed batch 403/1543 (32 items)\n","Processed batch 404/1543 (32 items)\n","Processed batch 405/1543 (32 items)\n","Processed batch 406/1543 (32 items)\n","Processed batch 407/1543 (32 items)\n","Processed batch 408/1543 (32 items)\n","Processed batch 409/1543 (32 items)\n","Checkpoint saved at batch 410\n","Processed batch 410/1543 (32 items)\n","\n","        API Calls: 411\n","        Total Tokens: 896334\n","        Estimated Cost: $1.79\n","        \n","Processed batch 411/1543 (32 items)\n","Processed batch 412/1543 (32 items)\n","Processed batch 413/1543 (32 items)\n","Processed batch 414/1543 (32 items)\n","Processed batch 415/1543 (32 items)\n","Processed batch 416/1543 (32 items)\n","Processed batch 417/1543 (32 items)\n","Processed batch 418/1543 (32 items)\n","Processed batch 419/1543 (32 items)\n","Checkpoint saved at batch 420\n","Processed batch 420/1543 (32 items)\n","\n","        API Calls: 421\n","        Total Tokens: 918745\n","        Estimated Cost: $1.84\n","        \n","Processed batch 421/1543 (32 items)\n","Processed batch 422/1543 (32 items)\n","Processed batch 423/1543 (32 items)\n","Processed batch 424/1543 (32 items)\n","Processed batch 425/1543 (32 items)\n","Processed batch 426/1543 (32 items)\n","Processed batch 427/1543 (32 items)\n","Processed batch 428/1543 (32 items)\n","Processed batch 429/1543 (32 items)\n","Checkpoint saved at batch 430\n","Processed batch 430/1543 (32 items)\n","\n","        API Calls: 431\n","        Total Tokens: 940847\n","        Estimated Cost: $1.88\n","        \n","Processed batch 431/1543 (32 items)\n","Processed batch 432/1543 (32 items)\n","Processed batch 433/1543 (32 items)\n","Processed batch 434/1543 (32 items)\n","Processed batch 435/1543 (32 items)\n","Processed batch 436/1543 (32 items)\n","Processed batch 437/1543 (32 items)\n","Processed batch 438/1543 (32 items)\n","Processed batch 439/1543 (32 items)\n","Checkpoint saved at batch 440\n","Processed batch 440/1543 (32 items)\n","\n","        API Calls: 441\n","        Total Tokens: 961866\n","        Estimated Cost: $1.92\n","        \n","Processed batch 441/1543 (32 items)\n","Processed batch 442/1543 (32 items)\n","Processed batch 443/1543 (32 items)\n","Processed batch 444/1543 (32 items)\n","Processed batch 445/1543 (32 items)\n","Processed batch 446/1543 (32 items)\n","Processed batch 447/1543 (32 items)\n","Processed batch 448/1543 (32 items)\n","Processed batch 449/1543 (32 items)\n","Checkpoint saved at batch 450\n","Processed batch 450/1543 (32 items)\n","\n","        API Calls: 451\n","        Total Tokens: 983973\n","        Estimated Cost: $1.97\n","        \n","Processed batch 451/1543 (32 items)\n","Processed batch 452/1543 (32 items)\n","Processed batch 453/1543 (32 items)\n","Processed batch 454/1543 (32 items)\n","Processed batch 455/1543 (32 items)\n","Processed batch 456/1543 (32 items)\n","Processed batch 457/1543 (32 items)\n","Processed batch 458/1543 (32 items)\n","Processed batch 459/1543 (32 items)\n","Checkpoint saved at batch 460\n","Processed batch 460/1543 (32 items)\n","\n","        API Calls: 461\n","        Total Tokens: 1004189\n","        Estimated Cost: $2.01\n","        \n","Processed batch 461/1543 (32 items)\n","Processed batch 462/1543 (32 items)\n","Processed batch 463/1543 (32 items)\n","Processed batch 464/1543 (32 items)\n","Processed batch 465/1543 (32 items)\n","Processed batch 466/1543 (32 items)\n","Processed batch 467/1543 (32 items)\n","Processed batch 468/1543 (32 items)\n","Processed batch 469/1543 (32 items)\n","Checkpoint saved at batch 470\n","Processed batch 470/1543 (32 items)\n","\n","        API Calls: 471\n","        Total Tokens: 1026331\n","        Estimated Cost: $2.05\n","        \n","Processed batch 471/1543 (32 items)\n","Processed batch 472/1543 (32 items)\n","Processed batch 473/1543 (32 items)\n","Processed batch 474/1543 (32 items)\n","Processed batch 475/1543 (32 items)\n","Processed batch 476/1543 (32 items)\n","Processed batch 477/1543 (32 items)\n","Processed batch 478/1543 (32 items)\n","Processed batch 479/1543 (32 items)\n","Checkpoint saved at batch 480\n","Processed batch 480/1543 (32 items)\n","\n","        API Calls: 481\n","        Total Tokens: 1047549\n","        Estimated Cost: $2.10\n","        \n","Processed batch 481/1543 (32 items)\n","Processed batch 482/1543 (32 items)\n","Processed batch 483/1543 (32 items)\n","Processed batch 484/1543 (32 items)\n","Processed batch 485/1543 (32 items)\n","Processed batch 486/1543 (32 items)\n","Processed batch 487/1543 (32 items)\n","Processed batch 488/1543 (32 items)\n","Processed batch 489/1543 (32 items)\n","Checkpoint saved at batch 490\n","Processed batch 490/1543 (32 items)\n","\n","        API Calls: 491\n","        Total Tokens: 1069554\n","        Estimated Cost: $2.14\n","        \n","Processed batch 491/1543 (32 items)\n","Processed batch 492/1543 (32 items)\n","Processed batch 493/1543 (32 items)\n","Processed batch 494/1543 (32 items)\n","Processed batch 495/1543 (32 items)\n","Processed batch 496/1543 (32 items)\n","Processed batch 497/1543 (32 items)\n","Processed batch 498/1543 (32 items)\n","Processed batch 499/1543 (32 items)\n","Checkpoint saved at batch 500\n","Processed batch 500/1543 (32 items)\n","\n","        API Calls: 501\n","        Total Tokens: 1090985\n","        Estimated Cost: $2.18\n","        \n","Processed batch 501/1543 (32 items)\n","Processed batch 502/1543 (32 items)\n","Processed batch 503/1543 (32 items)\n","Processed batch 504/1543 (32 items)\n","Processed batch 505/1543 (32 items)\n","Processed batch 506/1543 (32 items)\n","Processed batch 507/1543 (32 items)\n","Processed batch 508/1543 (32 items)\n","Processed batch 509/1543 (32 items)\n","Checkpoint saved at batch 510\n","Processed batch 510/1543 (32 items)\n","\n","        API Calls: 511\n","        Total Tokens: 1113185\n","        Estimated Cost: $2.23\n","        \n","Processed batch 511/1543 (32 items)\n","Processed batch 512/1543 (32 items)\n","Processed batch 513/1543 (32 items)\n","Processed batch 514/1543 (32 items)\n","Processed batch 515/1543 (32 items)\n","Processed batch 516/1543 (32 items)\n","Processed batch 517/1543 (32 items)\n","Processed batch 518/1543 (32 items)\n","Processed batch 519/1543 (32 items)\n","Checkpoint saved at batch 520\n","Processed batch 520/1543 (32 items)\n","\n","        API Calls: 521\n","        Total Tokens: 1134660\n","        Estimated Cost: $2.27\n","        \n","Processed batch 521/1543 (32 items)\n","Processed batch 522/1543 (32 items)\n","Processed batch 523/1543 (32 items)\n","Processed batch 524/1543 (32 items)\n","Processed batch 525/1543 (32 items)\n","Processed batch 526/1543 (32 items)\n","Processed batch 527/1543 (32 items)\n","Processed batch 528/1543 (32 items)\n","Processed batch 529/1543 (32 items)\n","Checkpoint saved at batch 530\n","Processed batch 530/1543 (32 items)\n","\n","        API Calls: 531\n","        Total Tokens: 1156547\n","        Estimated Cost: $2.31\n","        \n","Processed batch 531/1543 (32 items)\n","Processed batch 532/1543 (32 items)\n","Processed batch 533/1543 (32 items)\n","Processed batch 534/1543 (32 items)\n","Processed batch 535/1543 (32 items)\n","Processed batch 536/1543 (32 items)\n","Processed batch 537/1543 (32 items)\n","Processed batch 538/1543 (32 items)\n","Processed batch 539/1543 (32 items)\n","Checkpoint saved at batch 540\n","Processed batch 540/1543 (32 items)\n","\n","        API Calls: 541\n","        Total Tokens: 1178510\n","        Estimated Cost: $2.36\n","        \n","Processed batch 541/1543 (32 items)\n","Processed batch 542/1543 (32 items)\n","Processed batch 543/1543 (32 items)\n","Processed batch 544/1543 (32 items)\n","Processed batch 545/1543 (32 items)\n","Processed batch 546/1543 (32 items)\n","Processed batch 547/1543 (32 items)\n","Processed batch 548/1543 (32 items)\n","Processed batch 549/1543 (32 items)\n","Checkpoint saved at batch 550\n","Processed batch 550/1543 (32 items)\n","\n","        API Calls: 551\n","        Total Tokens: 1200210\n","        Estimated Cost: $2.40\n","        \n","Processed batch 551/1543 (32 items)\n","Processed batch 552/1543 (32 items)\n","Processed batch 553/1543 (32 items)\n","Processed batch 554/1543 (32 items)\n","Processed batch 555/1543 (32 items)\n","Processed batch 556/1543 (32 items)\n","Processed batch 557/1543 (32 items)\n","Processed batch 558/1543 (32 items)\n","Processed batch 559/1543 (32 items)\n","Checkpoint saved at batch 560\n","Processed batch 560/1543 (32 items)\n","\n","        API Calls: 561\n","        Total Tokens: 1222266\n","        Estimated Cost: $2.44\n","        \n","Processed batch 561/1543 (32 items)\n","Processed batch 562/1543 (32 items)\n","Processed batch 563/1543 (32 items)\n","Processed batch 564/1543 (32 items)\n","Processed batch 565/1543 (32 items)\n","Processed batch 566/1543 (32 items)\n","Processed batch 567/1543 (32 items)\n","Processed batch 568/1543 (32 items)\n","Processed batch 569/1543 (32 items)\n","Checkpoint saved at batch 570\n","Processed batch 570/1543 (32 items)\n","\n","        API Calls: 571\n","        Total Tokens: 1243197\n","        Estimated Cost: $2.49\n","        \n","Processed batch 571/1543 (32 items)\n","Processed batch 572/1543 (32 items)\n","Processed batch 573/1543 (32 items)\n","Processed batch 574/1543 (32 items)\n","Processed batch 575/1543 (32 items)\n","Processed batch 576/1543 (32 items)\n","Processed batch 577/1543 (32 items)\n","Processed batch 578/1543 (32 items)\n","Processed batch 579/1543 (32 items)\n","Checkpoint saved at batch 580\n","Processed batch 580/1543 (32 items)\n","\n","        API Calls: 581\n","        Total Tokens: 1265201\n","        Estimated Cost: $2.53\n","        \n","Processed batch 581/1543 (32 items)\n","Processed batch 582/1543 (32 items)\n","Processed batch 583/1543 (32 items)\n","Processed batch 584/1543 (32 items)\n","Processed batch 585/1543 (32 items)\n","Processed batch 586/1543 (32 items)\n","Processed batch 587/1543 (32 items)\n","Processed batch 588/1543 (32 items)\n","Processed batch 589/1543 (32 items)\n","Checkpoint saved at batch 590\n","Processed batch 590/1543 (32 items)\n","\n","        API Calls: 591\n","        Total Tokens: 1287108\n","        Estimated Cost: $2.57\n","        \n","Processed batch 591/1543 (32 items)\n","Processed batch 592/1543 (32 items)\n","Processed batch 593/1543 (32 items)\n","Processed batch 594/1543 (32 items)\n","Processed batch 595/1543 (32 items)\n","Processed batch 596/1543 (32 items)\n","Processed batch 597/1543 (32 items)\n","Processed batch 598/1543 (32 items)\n","Processed batch 599/1543 (32 items)\n","Checkpoint saved at batch 600\n","Processed batch 600/1543 (32 items)\n","\n","        API Calls: 601\n","        Total Tokens: 1309051\n","        Estimated Cost: $2.62\n","        \n","Processed batch 601/1543 (32 items)\n","Processed batch 602/1543 (32 items)\n","Processed batch 603/1543 (32 items)\n","Processed batch 604/1543 (32 items)\n","Processed batch 605/1543 (32 items)\n","Processed batch 606/1543 (32 items)\n","Processed batch 607/1543 (32 items)\n","Processed batch 608/1543 (32 items)\n","Processed batch 609/1543 (32 items)\n","Checkpoint saved at batch 610\n","Processed batch 610/1543 (32 items)\n","\n","        API Calls: 611\n","        Total Tokens: 1330521\n","        Estimated Cost: $2.66\n","        \n","Processed batch 611/1543 (32 items)\n","Processed batch 612/1543 (32 items)\n","Processed batch 613/1543 (32 items)\n","Processed batch 614/1543 (32 items)\n","Processed batch 615/1543 (32 items)\n","Processed batch 616/1543 (32 items)\n","Processed batch 617/1543 (32 items)\n","Processed batch 618/1543 (32 items)\n","Processed batch 619/1543 (32 items)\n","Checkpoint saved at batch 620\n","Processed batch 620/1543 (32 items)\n","\n","        API Calls: 621\n","        Total Tokens: 1352547\n","        Estimated Cost: $2.71\n","        \n","Processed batch 621/1543 (32 items)\n","Processed batch 622/1543 (32 items)\n","Processed batch 623/1543 (32 items)\n","Processed batch 624/1543 (32 items)\n","Processed batch 625/1543 (32 items)\n","Processed batch 626/1543 (32 items)\n","Processed batch 627/1543 (32 items)\n","Processed batch 628/1543 (32 items)\n","Processed batch 629/1543 (32 items)\n","Checkpoint saved at batch 630\n","Processed batch 630/1543 (32 items)\n","\n","        API Calls: 631\n","        Total Tokens: 1374981\n","        Estimated Cost: $2.75\n","        \n","Processed batch 631/1543 (32 items)\n","Processed batch 632/1543 (32 items)\n","Processed batch 633/1543 (32 items)\n","Processed batch 634/1543 (32 items)\n","Processed batch 635/1543 (32 items)\n","Processed batch 636/1543 (32 items)\n","Processed batch 637/1543 (32 items)\n","Processed batch 638/1543 (32 items)\n","Processed batch 639/1543 (32 items)\n","Checkpoint saved at batch 640\n","Processed batch 640/1543 (32 items)\n","\n","        API Calls: 641\n","        Total Tokens: 1397043\n","        Estimated Cost: $2.79\n","        \n","Processed batch 641/1543 (32 items)\n","Processed batch 642/1543 (32 items)\n","Processed batch 643/1543 (32 items)\n","Processed batch 644/1543 (32 items)\n","Processed batch 645/1543 (32 items)\n","Processed batch 646/1543 (32 items)\n","Processed batch 647/1543 (32 items)\n","Processed batch 648/1543 (32 items)\n","Processed batch 649/1543 (32 items)\n","Checkpoint saved at batch 650\n","Processed batch 650/1543 (32 items)\n","\n","        API Calls: 651\n","        Total Tokens: 1419153\n","        Estimated Cost: $2.84\n","        \n","Processed batch 651/1543 (32 items)\n","Processed batch 652/1543 (32 items)\n","Processed batch 653/1543 (32 items)\n","Processed batch 654/1543 (32 items)\n","Processed batch 655/1543 (32 items)\n","Processed batch 656/1543 (32 items)\n","Processed batch 657/1543 (32 items)\n","Processed batch 658/1543 (32 items)\n","Processed batch 659/1543 (32 items)\n","Checkpoint saved at batch 660\n","Processed batch 660/1543 (32 items)\n","\n","        API Calls: 661\n","        Total Tokens: 1440105\n","        Estimated Cost: $2.88\n","        \n","Processed batch 661/1543 (32 items)\n","Processed batch 662/1543 (32 items)\n","Processed batch 663/1543 (32 items)\n","Processed batch 664/1543 (32 items)\n","Processed batch 665/1543 (32 items)\n","Processed batch 666/1543 (32 items)\n","Processed batch 667/1543 (32 items)\n","Processed batch 668/1543 (32 items)\n","Processed batch 669/1543 (32 items)\n","Checkpoint saved at batch 670\n","Processed batch 670/1543 (32 items)\n","\n","        API Calls: 671\n","        Total Tokens: 1461834\n","        Estimated Cost: $2.92\n","        \n","Processed batch 671/1543 (32 items)\n","Processed batch 672/1543 (32 items)\n","Processed batch 673/1543 (32 items)\n","Processed batch 674/1543 (32 items)\n","Processed batch 675/1543 (32 items)\n","Processed batch 676/1543 (32 items)\n","Processed batch 677/1543 (32 items)\n","Processed batch 678/1543 (32 items)\n","Processed batch 679/1543 (32 items)\n","Checkpoint saved at batch 680\n","Processed batch 680/1543 (32 items)\n","\n","        API Calls: 681\n","        Total Tokens: 1484245\n","        Estimated Cost: $2.97\n","        \n","Processed batch 681/1543 (32 items)\n","Processed batch 682/1543 (32 items)\n","Processed batch 683/1543 (32 items)\n","Processed batch 684/1543 (32 items)\n","Processed batch 685/1543 (32 items)\n","Processed batch 686/1543 (32 items)\n","Processed batch 687/1543 (32 items)\n","Processed batch 688/1543 (32 items)\n","Processed batch 689/1543 (32 items)\n","Checkpoint saved at batch 690\n","Processed batch 690/1543 (32 items)\n","\n","        API Calls: 691\n","        Total Tokens: 1505419\n","        Estimated Cost: $3.01\n","        \n","Processed batch 691/1543 (32 items)\n","Processed batch 692/1543 (32 items)\n","Processed batch 693/1543 (32 items)\n","Processed batch 694/1543 (32 items)\n","Processed batch 695/1543 (32 items)\n","Processed batch 696/1543 (32 items)\n","Processed batch 697/1543 (32 items)\n","Processed batch 698/1543 (32 items)\n","Processed batch 699/1543 (32 items)\n","Checkpoint saved at batch 700\n","Processed batch 700/1543 (32 items)\n","\n","        API Calls: 701\n","        Total Tokens: 1526554\n","        Estimated Cost: $3.05\n","        \n","Processed batch 701/1543 (32 items)\n","Processed batch 702/1543 (32 items)\n","Processed batch 703/1543 (32 items)\n","Processed batch 704/1543 (32 items)\n","Processed batch 705/1543 (32 items)\n","Processed batch 706/1543 (32 items)\n","Processed batch 707/1543 (32 items)\n","Processed batch 708/1543 (32 items)\n","Processed batch 709/1543 (32 items)\n","Checkpoint saved at batch 710\n","Processed batch 710/1543 (32 items)\n","\n","        API Calls: 711\n","        Total Tokens: 1548249\n","        Estimated Cost: $3.10\n","        \n","Processed batch 711/1543 (32 items)\n","Processed batch 712/1543 (32 items)\n","Processed batch 713/1543 (32 items)\n","Processed batch 714/1543 (32 items)\n","Processed batch 715/1543 (32 items)\n","Processed batch 716/1543 (32 items)\n","Processed batch 717/1543 (32 items)\n","Processed batch 718/1543 (32 items)\n","Processed batch 719/1543 (32 items)\n","Checkpoint saved at batch 720\n","Processed batch 720/1543 (32 items)\n","\n","        API Calls: 721\n","        Total Tokens: 1570608\n","        Estimated Cost: $3.14\n","        \n","Processed batch 721/1543 (32 items)\n","Processed batch 722/1543 (32 items)\n","Processed batch 723/1543 (32 items)\n","Processed batch 724/1543 (32 items)\n","Processed batch 725/1543 (32 items)\n","Processed batch 726/1543 (32 items)\n","Processed batch 727/1543 (32 items)\n","Processed batch 728/1543 (32 items)\n","Processed batch 729/1543 (32 items)\n","Checkpoint saved at batch 730\n","Processed batch 730/1543 (32 items)\n","\n","        API Calls: 731\n","        Total Tokens: 1591582\n","        Estimated Cost: $3.18\n","        \n","Processed batch 731/1543 (32 items)\n","Processed batch 732/1543 (32 items)\n","Processed batch 733/1543 (32 items)\n","Processed batch 734/1543 (32 items)\n","Processed batch 735/1543 (32 items)\n","Processed batch 736/1543 (32 items)\n","Processed batch 737/1543 (32 items)\n","Processed batch 738/1543 (32 items)\n","Processed batch 739/1543 (32 items)\n","Checkpoint saved at batch 740\n","Processed batch 740/1543 (32 items)\n","\n","        API Calls: 741\n","        Total Tokens: 1613135\n","        Estimated Cost: $3.23\n","        \n","Processed batch 741/1543 (32 items)\n","Processed batch 742/1543 (32 items)\n","Processed batch 743/1543 (32 items)\n","Processed batch 744/1543 (32 items)\n","Processed batch 745/1543 (32 items)\n","Processed batch 746/1543 (32 items)\n","Processed batch 747/1543 (32 items)\n","Processed batch 748/1543 (32 items)\n","Processed batch 749/1543 (32 items)\n","Checkpoint saved at batch 750\n","Processed batch 750/1543 (32 items)\n","\n","        API Calls: 751\n","        Total Tokens: 1635098\n","        Estimated Cost: $3.27\n","        \n","Processed batch 751/1543 (32 items)\n","Processed batch 752/1543 (32 items)\n","Processed batch 753/1543 (32 items)\n","Processed batch 754/1543 (32 items)\n","Processed batch 755/1543 (32 items)\n","Processed batch 756/1543 (32 items)\n","Processed batch 757/1543 (32 items)\n","Processed batch 758/1543 (32 items)\n","Processed batch 759/1543 (32 items)\n","Checkpoint saved at batch 760\n","Processed batch 760/1543 (32 items)\n","\n","        API Calls: 761\n","        Total Tokens: 1656899\n","        Estimated Cost: $3.31\n","        \n","Processed batch 761/1543 (32 items)\n","Processed batch 762/1543 (32 items)\n","Processed batch 763/1543 (32 items)\n","Processed batch 764/1543 (32 items)\n","Processed batch 765/1543 (32 items)\n","Processed batch 766/1543 (32 items)\n","Processed batch 767/1543 (32 items)\n","Processed batch 768/1543 (32 items)\n","Processed batch 769/1543 (32 items)\n","Checkpoint saved at batch 770\n","Processed batch 770/1543 (32 items)\n","\n","        API Calls: 771\n","        Total Tokens: 1679389\n","        Estimated Cost: $3.36\n","        \n","Processed batch 771/1543 (32 items)\n","Processed batch 772/1543 (32 items)\n","Processed batch 773/1543 (32 items)\n","Processed batch 774/1543 (32 items)\n","Processed batch 775/1543 (32 items)\n","Processed batch 776/1543 (32 items)\n","Processed batch 777/1543 (32 items)\n","Processed batch 778/1543 (32 items)\n","Processed batch 779/1543 (32 items)\n","Checkpoint saved at batch 780\n","Processed batch 780/1543 (32 items)\n","\n","        API Calls: 781\n","        Total Tokens: 1700952\n","        Estimated Cost: $3.40\n","        \n","Processed batch 781/1543 (32 items)\n","Processed batch 782/1543 (32 items)\n","Processed batch 783/1543 (32 items)\n","Processed batch 784/1543 (32 items)\n","Processed batch 785/1543 (32 items)\n","Processed batch 786/1543 (32 items)\n","Processed batch 787/1543 (32 items)\n","Processed batch 788/1543 (32 items)\n","Processed batch 789/1543 (32 items)\n","Checkpoint saved at batch 790\n","Processed batch 790/1543 (32 items)\n","\n","        API Calls: 791\n","        Total Tokens: 1723044\n","        Estimated Cost: $3.45\n","        \n","Processed batch 791/1543 (32 items)\n","Processed batch 792/1543 (32 items)\n","Processed batch 793/1543 (32 items)\n","Processed batch 794/1543 (32 items)\n","Processed batch 795/1543 (32 items)\n","Processed batch 796/1543 (32 items)\n","Processed batch 797/1543 (32 items)\n","Processed batch 798/1543 (32 items)\n","Processed batch 799/1543 (32 items)\n","Checkpoint saved at batch 800\n","Processed batch 800/1543 (32 items)\n","\n","        API Calls: 801\n","        Total Tokens: 1744836\n","        Estimated Cost: $3.49\n","        \n","Processed batch 801/1543 (32 items)\n","Processed batch 802/1543 (32 items)\n","Processed batch 803/1543 (32 items)\n","Processed batch 804/1543 (32 items)\n","Processed batch 805/1543 (32 items)\n","Processed batch 806/1543 (32 items)\n","Processed batch 807/1543 (32 items)\n","Processed batch 808/1543 (32 items)\n","Processed batch 809/1543 (32 items)\n","Checkpoint saved at batch 810\n","Processed batch 810/1543 (32 items)\n","\n","        API Calls: 811\n","        Total Tokens: 1766603\n","        Estimated Cost: $3.53\n","        \n","Processed batch 811/1543 (32 items)\n","Processed batch 812/1543 (32 items)\n","Processed batch 813/1543 (32 items)\n","Processed batch 814/1543 (32 items)\n","Processed batch 815/1543 (32 items)\n","Processed batch 816/1543 (32 items)\n","Processed batch 817/1543 (32 items)\n","Processed batch 818/1543 (32 items)\n","Processed batch 819/1543 (32 items)\n","Checkpoint saved at batch 820\n","Processed batch 820/1543 (32 items)\n","\n","        API Calls: 821\n","        Total Tokens: 1788191\n","        Estimated Cost: $3.58\n","        \n","Processed batch 821/1543 (32 items)\n","Processed batch 822/1543 (32 items)\n","Processed batch 823/1543 (32 items)\n","Processed batch 824/1543 (32 items)\n","Processed batch 825/1543 (32 items)\n","Processed batch 826/1543 (32 items)\n","Processed batch 827/1543 (32 items)\n","Processed batch 828/1543 (32 items)\n","Processed batch 829/1543 (32 items)\n","Checkpoint saved at batch 830\n","Processed batch 830/1543 (32 items)\n","\n","        API Calls: 831\n","        Total Tokens: 1809767\n","        Estimated Cost: $3.62\n","        \n","Processed batch 831/1543 (32 items)\n","Processed batch 832/1543 (32 items)\n","Processed batch 833/1543 (32 items)\n","Processed batch 834/1543 (32 items)\n","Processed batch 835/1543 (32 items)\n","Processed batch 836/1543 (32 items)\n","Processed batch 837/1543 (32 items)\n","Processed batch 838/1543 (32 items)\n","Processed batch 839/1543 (32 items)\n","Checkpoint saved at batch 840\n","Processed batch 840/1543 (32 items)\n","\n","        API Calls: 841\n","        Total Tokens: 1832555\n","        Estimated Cost: $3.67\n","        \n","Processed batch 841/1543 (32 items)\n","Processed batch 842/1543 (32 items)\n","Processed batch 843/1543 (32 items)\n","Processed batch 844/1543 (32 items)\n","Processed batch 845/1543 (32 items)\n","Processed batch 846/1543 (32 items)\n","Processed batch 847/1543 (32 items)\n","Processed batch 848/1543 (32 items)\n","Processed batch 849/1543 (32 items)\n","Checkpoint saved at batch 850\n","Processed batch 850/1543 (32 items)\n","\n","        API Calls: 851\n","        Total Tokens: 1854085\n","        Estimated Cost: $3.71\n","        \n","Processed batch 851/1543 (32 items)\n","Processed batch 852/1543 (32 items)\n","Processed batch 853/1543 (32 items)\n","Processed batch 854/1543 (32 items)\n","Processed batch 855/1543 (32 items)\n","Processed batch 856/1543 (32 items)\n","Processed batch 857/1543 (32 items)\n","Processed batch 858/1543 (32 items)\n","Processed batch 859/1543 (32 items)\n","Checkpoint saved at batch 860\n","Processed batch 860/1543 (32 items)\n","\n","        API Calls: 861\n","        Total Tokens: 1874854\n","        Estimated Cost: $3.75\n","        \n","Processed batch 861/1543 (32 items)\n","Processed batch 862/1543 (32 items)\n","Processed batch 863/1543 (32 items)\n","Processed batch 864/1543 (32 items)\n","Processed batch 865/1543 (32 items)\n","Processed batch 866/1543 (32 items)\n","Processed batch 867/1543 (32 items)\n","Processed batch 868/1543 (32 items)\n","Processed batch 869/1543 (32 items)\n","Checkpoint saved at batch 870\n","Processed batch 870/1543 (32 items)\n","\n","        API Calls: 871\n","        Total Tokens: 1896621\n","        Estimated Cost: $3.79\n","        \n","Processed batch 871/1543 (32 items)\n","Processed batch 872/1543 (32 items)\n","Processed batch 873/1543 (32 items)\n","Processed batch 874/1543 (32 items)\n","Processed batch 875/1543 (32 items)\n","Processed batch 876/1543 (32 items)\n","Processed batch 877/1543 (32 items)\n","Processed batch 878/1543 (32 items)\n","Processed batch 879/1543 (32 items)\n","Checkpoint saved at batch 880\n","Processed batch 880/1543 (32 items)\n","\n","        API Calls: 881\n","        Total Tokens: 1918337\n","        Estimated Cost: $3.84\n","        \n","Processed batch 881/1543 (32 items)\n","Processed batch 882/1543 (32 items)\n","Processed batch 883/1543 (32 items)\n","Processed batch 884/1543 (32 items)\n","Processed batch 885/1543 (32 items)\n","Processed batch 886/1543 (32 items)\n","Processed batch 887/1543 (32 items)\n","Processed batch 888/1543 (32 items)\n","Processed batch 889/1543 (32 items)\n","Checkpoint saved at batch 890\n","Processed batch 890/1543 (32 items)\n","\n","        API Calls: 891\n","        Total Tokens: 1940161\n","        Estimated Cost: $3.88\n","        \n","Processed batch 891/1543 (32 items)\n","Processed batch 892/1543 (32 items)\n","Processed batch 893/1543 (32 items)\n","Processed batch 894/1543 (32 items)\n","Processed batch 895/1543 (32 items)\n","Processed batch 896/1543 (32 items)\n","Processed batch 897/1543 (32 items)\n","Processed batch 898/1543 (32 items)\n","Processed batch 899/1543 (32 items)\n","Checkpoint saved at batch 900\n","Processed batch 900/1543 (32 items)\n","\n","        API Calls: 901\n","        Total Tokens: 1962339\n","        Estimated Cost: $3.92\n","        \n","Processed batch 901/1543 (32 items)\n","Processed batch 902/1543 (32 items)\n","Processed batch 903/1543 (32 items)\n","Processed batch 904/1543 (32 items)\n","Processed batch 905/1543 (32 items)\n","Processed batch 906/1543 (32 items)\n","Processed batch 907/1543 (32 items)\n","Processed batch 908/1543 (32 items)\n","Processed batch 909/1543 (32 items)\n","Checkpoint saved at batch 910\n","Processed batch 910/1543 (32 items)\n","\n","        API Calls: 911\n","        Total Tokens: 1984590\n","        Estimated Cost: $3.97\n","        \n","Processed batch 911/1543 (32 items)\n","Processed batch 912/1543 (32 items)\n","Processed batch 913/1543 (32 items)\n","Processed batch 914/1543 (32 items)\n","Processed batch 915/1543 (32 items)\n","Processed batch 916/1543 (32 items)\n","Processed batch 917/1543 (32 items)\n","Processed batch 918/1543 (32 items)\n","Processed batch 919/1543 (32 items)\n","Checkpoint saved at batch 920\n","Processed batch 920/1543 (32 items)\n","\n","        API Calls: 921\n","        Total Tokens: 2005699\n","        Estimated Cost: $4.01\n","        \n","Processed batch 921/1543 (32 items)\n","Processed batch 922/1543 (32 items)\n","Processed batch 923/1543 (32 items)\n","Processed batch 924/1543 (32 items)\n","Processed batch 925/1543 (32 items)\n","Processed batch 926/1543 (32 items)\n","Processed batch 927/1543 (32 items)\n","Processed batch 928/1543 (32 items)\n","Processed batch 929/1543 (32 items)\n","Checkpoint saved at batch 930\n","Processed batch 930/1543 (32 items)\n","\n","        API Calls: 931\n","        Total Tokens: 2027120\n","        Estimated Cost: $4.05\n","        \n","Processed batch 931/1543 (32 items)\n","Processed batch 932/1543 (32 items)\n","Processed batch 933/1543 (32 items)\n","Processed batch 934/1543 (32 items)\n","Processed batch 935/1543 (32 items)\n","Processed batch 936/1543 (32 items)\n","Processed batch 937/1543 (32 items)\n","Processed batch 938/1543 (32 items)\n","Processed batch 939/1543 (32 items)\n","Checkpoint saved at batch 940\n","Processed batch 940/1543 (32 items)\n","\n","        API Calls: 941\n","        Total Tokens: 2049421\n","        Estimated Cost: $4.10\n","        \n","Processed batch 941/1543 (32 items)\n","Processed batch 942/1543 (32 items)\n","Processed batch 943/1543 (32 items)\n","Processed batch 944/1543 (32 items)\n","Processed batch 945/1543 (32 items)\n","Processed batch 946/1543 (32 items)\n","Processed batch 947/1543 (32 items)\n","Processed batch 948/1543 (32 items)\n","Processed batch 949/1543 (32 items)\n","Checkpoint saved at batch 950\n","Processed batch 950/1543 (32 items)\n","\n","        API Calls: 951\n","        Total Tokens: 2071378\n","        Estimated Cost: $4.14\n","        \n","Processed batch 951/1543 (32 items)\n","Processed batch 952/1543 (32 items)\n","Processed batch 953/1543 (32 items)\n","Processed batch 954/1543 (32 items)\n","Processed batch 955/1543 (32 items)\n","Processed batch 956/1543 (32 items)\n","Processed batch 957/1543 (32 items)\n","Processed batch 958/1543 (32 items)\n","Processed batch 959/1543 (32 items)\n","Checkpoint saved at batch 960\n","Processed batch 960/1543 (32 items)\n","\n","        API Calls: 961\n","        Total Tokens: 2092994\n","        Estimated Cost: $4.19\n","        \n","Processed batch 961/1543 (32 items)\n","Processed batch 962/1543 (32 items)\n","Processed batch 963/1543 (32 items)\n","Processed batch 964/1543 (32 items)\n","Processed batch 965/1543 (32 items)\n","Processed batch 966/1543 (32 items)\n","Processed batch 967/1543 (32 items)\n","Processed batch 968/1543 (32 items)\n","Processed batch 969/1543 (32 items)\n","Checkpoint saved at batch 970\n","Processed batch 970/1543 (32 items)\n","\n","        API Calls: 971\n","        Total Tokens: 2114202\n","        Estimated Cost: $4.23\n","        \n","Processed batch 971/1543 (32 items)\n","Processed batch 972/1543 (32 items)\n","Processed batch 973/1543 (32 items)\n","Processed batch 974/1543 (32 items)\n","Processed batch 975/1543 (32 items)\n","Processed batch 976/1543 (32 items)\n","Processed batch 977/1543 (32 items)\n","Processed batch 978/1543 (32 items)\n","Processed batch 979/1543 (32 items)\n","Checkpoint saved at batch 980\n","Processed batch 980/1543 (32 items)\n","\n","        API Calls: 981\n","        Total Tokens: 2136657\n","        Estimated Cost: $4.27\n","        \n","Processed batch 981/1543 (32 items)\n","Processed batch 982/1543 (32 items)\n","Processed batch 983/1543 (32 items)\n","Processed batch 984/1543 (32 items)\n","Processed batch 985/1543 (32 items)\n","Processed batch 986/1543 (32 items)\n","Processed batch 987/1543 (32 items)\n","Processed batch 988/1543 (32 items)\n","Processed batch 989/1543 (32 items)\n","Checkpoint saved at batch 990\n","Processed batch 990/1543 (32 items)\n","\n","        API Calls: 991\n","        Total Tokens: 2158668\n","        Estimated Cost: $4.32\n","        \n","Processed batch 991/1543 (32 items)\n","Processed batch 992/1543 (32 items)\n","Processed batch 993/1543 (32 items)\n","Processed batch 994/1543 (32 items)\n","Processed batch 995/1543 (32 items)\n","Processed batch 996/1543 (32 items)\n","Processed batch 997/1543 (32 items)\n","Processed batch 998/1543 (32 items)\n","Processed batch 999/1543 (32 items)\n","Checkpoint saved at batch 1000\n","Processed batch 1000/1543 (32 items)\n","\n","        API Calls: 1001\n","        Total Tokens: 2180478\n","        Estimated Cost: $4.36\n","        \n","Processed batch 1001/1543 (32 items)\n","Processed batch 1002/1543 (32 items)\n","Processed batch 1003/1543 (32 items)\n","Processed batch 1004/1543 (32 items)\n","Processed batch 1005/1543 (32 items)\n","Processed batch 1006/1543 (32 items)\n","Processed batch 1007/1543 (32 items)\n","Processed batch 1008/1543 (32 items)\n","Processed batch 1009/1543 (32 items)\n","Checkpoint saved at batch 1010\n","Processed batch 1010/1543 (32 items)\n","\n","        API Calls: 1011\n","        Total Tokens: 2202673\n","        Estimated Cost: $4.41\n","        \n","Processed batch 1011/1543 (32 items)\n","Processed batch 1012/1543 (32 items)\n","Processed batch 1013/1543 (32 items)\n","Processed batch 1014/1543 (32 items)\n","Processed batch 1015/1543 (32 items)\n","Processed batch 1016/1543 (32 items)\n","Processed batch 1017/1543 (32 items)\n","Processed batch 1018/1543 (32 items)\n","Processed batch 1019/1543 (32 items)\n","Checkpoint saved at batch 1020\n","Processed batch 1020/1543 (32 items)\n","\n","        API Calls: 1021\n","        Total Tokens: 2224190\n","        Estimated Cost: $4.45\n","        \n","Processed batch 1021/1543 (32 items)\n","Processed batch 1022/1543 (32 items)\n","Processed batch 1023/1543 (32 items)\n","Processed batch 1024/1543 (32 items)\n","Processed batch 1025/1543 (32 items)\n","Processed batch 1026/1543 (32 items)\n","Processed batch 1027/1543 (32 items)\n","Processed batch 1028/1543 (32 items)\n","Processed batch 1029/1543 (32 items)\n","Checkpoint saved at batch 1030\n","Processed batch 1030/1543 (32 items)\n","\n","        API Calls: 1031\n","        Total Tokens: 2245466\n","        Estimated Cost: $4.49\n","        \n","Processed batch 1031/1543 (32 items)\n","Processed batch 1032/1543 (32 items)\n","Processed batch 1033/1543 (32 items)\n","Processed batch 1034/1543 (32 items)\n","Processed batch 1035/1543 (32 items)\n","Processed batch 1036/1543 (32 items)\n","Processed batch 1037/1543 (32 items)\n","Processed batch 1038/1543 (32 items)\n","Processed batch 1039/1543 (32 items)\n","Checkpoint saved at batch 1040\n","Processed batch 1040/1543 (32 items)\n","\n","        API Calls: 1041\n","        Total Tokens: 2267588\n","        Estimated Cost: $4.54\n","        \n","Processed batch 1041/1543 (32 items)\n","Processed batch 1042/1543 (32 items)\n","Processed batch 1043/1543 (32 items)\n","Processed batch 1044/1543 (32 items)\n","Processed batch 1045/1543 (32 items)\n","Processed batch 1046/1543 (32 items)\n","Processed batch 1047/1543 (32 items)\n","Processed batch 1048/1543 (32 items)\n","Processed batch 1049/1543 (32 items)\n","Checkpoint saved at batch 1050\n","Processed batch 1050/1543 (32 items)\n","\n","        API Calls: 1051\n","        Total Tokens: 2289705\n","        Estimated Cost: $4.58\n","        \n","Processed batch 1051/1543 (32 items)\n","Processed batch 1052/1543 (32 items)\n","Processed batch 1053/1543 (32 items)\n","Processed batch 1054/1543 (32 items)\n","Processed batch 1055/1543 (32 items)\n","Processed batch 1056/1543 (32 items)\n","Processed batch 1057/1543 (32 items)\n","Processed batch 1058/1543 (32 items)\n","Processed batch 1059/1543 (32 items)\n","Checkpoint saved at batch 1060\n","Processed batch 1060/1543 (32 items)\n","\n","        API Calls: 1061\n","        Total Tokens: 2311566\n","        Estimated Cost: $4.62\n","        \n","Processed batch 1061/1543 (32 items)\n","Processed batch 1062/1543 (32 items)\n","Processed batch 1063/1543 (32 items)\n","Processed batch 1064/1543 (32 items)\n","Processed batch 1065/1543 (32 items)\n","Processed batch 1066/1543 (32 items)\n","Processed batch 1067/1543 (32 items)\n","Processed batch 1068/1543 (32 items)\n","Processed batch 1069/1543 (32 items)\n","Checkpoint saved at batch 1070\n","Processed batch 1070/1543 (32 items)\n","\n","        API Calls: 1071\n","        Total Tokens: 2332682\n","        Estimated Cost: $4.67\n","        \n","Processed batch 1071/1543 (32 items)\n","Processed batch 1072/1543 (32 items)\n","Processed batch 1073/1543 (32 items)\n","Processed batch 1074/1543 (32 items)\n","Processed batch 1075/1543 (32 items)\n","Processed batch 1076/1543 (32 items)\n","Processed batch 1077/1543 (32 items)\n","Processed batch 1078/1543 (32 items)\n","Processed batch 1079/1543 (32 items)\n","Checkpoint saved at batch 1080\n","Processed batch 1080/1543 (32 items)\n","\n","        API Calls: 1081\n","        Total Tokens: 2354953\n","        Estimated Cost: $4.71\n","        \n","Processed batch 1081/1543 (32 items)\n","Processed batch 1082/1543 (32 items)\n","Processed batch 1083/1543 (32 items)\n","Processed batch 1084/1543 (32 items)\n","Processed batch 1085/1543 (32 items)\n","Processed batch 1086/1543 (32 items)\n","Processed batch 1087/1543 (32 items)\n","Processed batch 1088/1543 (32 items)\n","Processed batch 1089/1543 (32 items)\n","Checkpoint saved at batch 1090\n","Processed batch 1090/1543 (32 items)\n","\n","        API Calls: 1091\n","        Total Tokens: 2377245\n","        Estimated Cost: $4.75\n","        \n","Processed batch 1091/1543 (32 items)\n","Processed batch 1092/1543 (32 items)\n","Processed batch 1093/1543 (32 items)\n","Processed batch 1094/1543 (32 items)\n","Processed batch 1095/1543 (32 items)\n","Processed batch 1096/1543 (32 items)\n","Processed batch 1097/1543 (32 items)\n","Processed batch 1098/1543 (32 items)\n","Processed batch 1099/1543 (32 items)\n","Checkpoint saved at batch 1100\n","Processed batch 1100/1543 (32 items)\n","\n","        API Calls: 1101\n","        Total Tokens: 2399111\n","        Estimated Cost: $4.80\n","        \n","Processed batch 1101/1543 (32 items)\n","Processed batch 1102/1543 (32 items)\n","Processed batch 1103/1543 (32 items)\n","Processed batch 1104/1543 (32 items)\n","Processed batch 1105/1543 (32 items)\n","Processed batch 1106/1543 (32 items)\n","Processed batch 1107/1543 (32 items)\n","Processed batch 1108/1543 (32 items)\n","Processed batch 1109/1543 (32 items)\n","Checkpoint saved at batch 1110\n","Processed batch 1110/1543 (32 items)\n","\n","        API Calls: 1111\n","        Total Tokens: 2421403\n","        Estimated Cost: $4.84\n","        \n","Processed batch 1111/1543 (32 items)\n","Processed batch 1112/1543 (32 items)\n","Processed batch 1113/1543 (32 items)\n","Processed batch 1114/1543 (32 items)\n","Processed batch 1115/1543 (32 items)\n","Processed batch 1116/1543 (32 items)\n","Processed batch 1117/1543 (32 items)\n","Processed batch 1118/1543 (32 items)\n","Processed batch 1119/1543 (32 items)\n","Checkpoint saved at batch 1120\n","Processed batch 1120/1543 (32 items)\n","\n","        API Calls: 1121\n","        Total Tokens: 2443658\n","        Estimated Cost: $4.89\n","        \n","Processed batch 1121/1543 (32 items)\n","Processed batch 1122/1543 (32 items)\n","Processed batch 1123/1543 (32 items)\n","Processed batch 1124/1543 (32 items)\n","Processed batch 1125/1543 (32 items)\n","Processed batch 1126/1543 (32 items)\n","Processed batch 1127/1543 (32 items)\n","Processed batch 1128/1543 (32 items)\n","Processed batch 1129/1543 (32 items)\n","Checkpoint saved at batch 1130\n","Processed batch 1130/1543 (32 items)\n","\n","        API Calls: 1131\n","        Total Tokens: 2465375\n","        Estimated Cost: $4.93\n","        \n","Processed batch 1131/1543 (32 items)\n","Processed batch 1132/1543 (32 items)\n","Processed batch 1133/1543 (32 items)\n","Processed batch 1134/1543 (32 items)\n","Processed batch 1135/1543 (32 items)\n","Processed batch 1136/1543 (32 items)\n","Processed batch 1137/1543 (32 items)\n","Processed batch 1138/1543 (32 items)\n","Processed batch 1139/1543 (32 items)\n","Checkpoint saved at batch 1140\n","Processed batch 1140/1543 (32 items)\n","\n","        API Calls: 1141\n","        Total Tokens: 2487067\n","        Estimated Cost: $4.97\n","        \n","Processed batch 1141/1543 (32 items)\n","Processed batch 1142/1543 (32 items)\n","Processed batch 1143/1543 (32 items)\n","Processed batch 1144/1543 (32 items)\n","Processed batch 1145/1543 (32 items)\n","Processed batch 1146/1543 (32 items)\n","Processed batch 1147/1543 (32 items)\n","Processed batch 1148/1543 (32 items)\n","Processed batch 1149/1543 (32 items)\n","Checkpoint saved at batch 1150\n","Processed batch 1150/1543 (32 items)\n","\n","        API Calls: 1151\n","        Total Tokens: 2507991\n","        Estimated Cost: $5.02\n","        \n","Processed batch 1151/1543 (32 items)\n","Processed batch 1152/1543 (32 items)\n","Processed batch 1153/1543 (32 items)\n","Processed batch 1154/1543 (32 items)\n","Processed batch 1155/1543 (32 items)\n","Processed batch 1156/1543 (32 items)\n","Processed batch 1157/1543 (32 items)\n","Processed batch 1158/1543 (32 items)\n","Processed batch 1159/1543 (32 items)\n","Checkpoint saved at batch 1160\n","Processed batch 1160/1543 (32 items)\n","\n","        API Calls: 1161\n","        Total Tokens: 2530268\n","        Estimated Cost: $5.06\n","        \n","Processed batch 1161/1543 (32 items)\n","Processed batch 1162/1543 (32 items)\n","Processed batch 1163/1543 (32 items)\n","Processed batch 1164/1543 (32 items)\n","Processed batch 1165/1543 (32 items)\n","Processed batch 1166/1543 (32 items)\n","Processed batch 1167/1543 (32 items)\n","Processed batch 1168/1543 (32 items)\n","Processed batch 1169/1543 (32 items)\n","Checkpoint saved at batch 1170\n","Processed batch 1170/1543 (32 items)\n","\n","        API Calls: 1171\n","        Total Tokens: 2552391\n","        Estimated Cost: $5.10\n","        \n","Processed batch 1171/1543 (32 items)\n","Processed batch 1172/1543 (32 items)\n","Processed batch 1173/1543 (32 items)\n","Processed batch 1174/1543 (32 items)\n","Processed batch 1175/1543 (32 items)\n","Processed batch 1176/1543 (32 items)\n","Processed batch 1177/1543 (32 items)\n","Processed batch 1178/1543 (32 items)\n","Processed batch 1179/1543 (32 items)\n","Checkpoint saved at batch 1180\n","Processed batch 1180/1543 (32 items)\n","\n","        API Calls: 1181\n","        Total Tokens: 2573581\n","        Estimated Cost: $5.15\n","        \n","Processed batch 1181/1543 (32 items)\n","Processed batch 1182/1543 (32 items)\n","Processed batch 1183/1543 (32 items)\n","Processed batch 1184/1543 (32 items)\n","Processed batch 1185/1543 (32 items)\n","Processed batch 1186/1543 (32 items)\n","Processed batch 1187/1543 (32 items)\n","Processed batch 1188/1543 (32 items)\n","Processed batch 1189/1543 (32 items)\n","Checkpoint saved at batch 1190\n","Processed batch 1190/1543 (32 items)\n","\n","        API Calls: 1191\n","        Total Tokens: 2595931\n","        Estimated Cost: $5.19\n","        \n","Processed batch 1191/1543 (32 items)\n","Processed batch 1192/1543 (32 items)\n","Processed batch 1193/1543 (32 items)\n","Processed batch 1194/1543 (32 items)\n","Processed batch 1195/1543 (32 items)\n","Processed batch 1196/1543 (32 items)\n","Processed batch 1197/1543 (32 items)\n","Processed batch 1198/1543 (32 items)\n","Processed batch 1199/1543 (32 items)\n","Checkpoint saved at batch 1200\n","Processed batch 1200/1543 (32 items)\n","\n","        API Calls: 1201\n","        Total Tokens: 2618507\n","        Estimated Cost: $5.24\n","        \n","Processed batch 1201/1543 (32 items)\n","Processed batch 1202/1543 (32 items)\n","Processed batch 1203/1543 (32 items)\n","Processed batch 1204/1543 (32 items)\n","Processed batch 1205/1543 (32 items)\n","Processed batch 1206/1543 (32 items)\n","Processed batch 1207/1543 (32 items)\n","Processed batch 1208/1543 (32 items)\n","Processed batch 1209/1543 (32 items)\n","Checkpoint saved at batch 1210\n","Processed batch 1210/1543 (32 items)\n","\n","        API Calls: 1211\n","        Total Tokens: 2640420\n","        Estimated Cost: $5.28\n","        \n","Processed batch 1211/1543 (32 items)\n","Processed batch 1212/1543 (32 items)\n","Processed batch 1213/1543 (32 items)\n","Processed batch 1214/1543 (32 items)\n","Processed batch 1215/1543 (32 items)\n","Processed batch 1216/1543 (32 items)\n","Processed batch 1217/1543 (32 items)\n","Processed batch 1218/1543 (32 items)\n","Processed batch 1219/1543 (32 items)\n","Checkpoint saved at batch 1220\n","Processed batch 1220/1543 (32 items)\n","\n","        API Calls: 1221\n","        Total Tokens: 2661371\n","        Estimated Cost: $5.32\n","        \n","Processed batch 1221/1543 (32 items)\n","Processed batch 1222/1543 (32 items)\n","Processed batch 1223/1543 (32 items)\n","Processed batch 1224/1543 (32 items)\n","Processed batch 1225/1543 (32 items)\n","Processed batch 1226/1543 (32 items)\n","Processed batch 1227/1543 (32 items)\n","Processed batch 1228/1543 (32 items)\n","Processed batch 1229/1543 (32 items)\n","Checkpoint saved at batch 1230\n","Processed batch 1230/1543 (32 items)\n","\n","        API Calls: 1231\n","        Total Tokens: 2684113\n","        Estimated Cost: $5.37\n","        \n","Processed batch 1231/1543 (32 items)\n","Processed batch 1232/1543 (32 items)\n","Processed batch 1233/1543 (32 items)\n","Processed batch 1234/1543 (32 items)\n","Processed batch 1235/1543 (32 items)\n","Processed batch 1236/1543 (32 items)\n","Processed batch 1237/1543 (32 items)\n","Processed batch 1238/1543 (32 items)\n","Processed batch 1239/1543 (32 items)\n","Checkpoint saved at batch 1240\n","Processed batch 1240/1543 (32 items)\n","\n","        API Calls: 1241\n","        Total Tokens: 2704806\n","        Estimated Cost: $5.41\n","        \n","Processed batch 1241/1543 (32 items)\n","Processed batch 1242/1543 (32 items)\n","Processed batch 1243/1543 (32 items)\n","Processed batch 1244/1543 (32 items)\n","Processed batch 1245/1543 (32 items)\n","Processed batch 1246/1543 (32 items)\n","Processed batch 1247/1543 (32 items)\n","Processed batch 1248/1543 (32 items)\n","Processed batch 1249/1543 (32 items)\n","Checkpoint saved at batch 1250\n","Processed batch 1250/1543 (32 items)\n","\n","        API Calls: 1251\n","        Total Tokens: 2726659\n","        Estimated Cost: $5.45\n","        \n","Processed batch 1251/1543 (32 items)\n","Processed batch 1252/1543 (32 items)\n","Processed batch 1253/1543 (32 items)\n","Processed batch 1254/1543 (32 items)\n","Processed batch 1255/1543 (32 items)\n","Processed batch 1256/1543 (32 items)\n","Processed batch 1257/1543 (32 items)\n","Processed batch 1258/1543 (32 items)\n","Processed batch 1259/1543 (32 items)\n","Checkpoint saved at batch 1260\n","Processed batch 1260/1543 (32 items)\n","\n","        API Calls: 1261\n","        Total Tokens: 2749422\n","        Estimated Cost: $5.50\n","        \n","Processed batch 1261/1543 (32 items)\n","Processed batch 1262/1543 (32 items)\n","Processed batch 1263/1543 (32 items)\n","Processed batch 1264/1543 (32 items)\n","Processed batch 1265/1543 (32 items)\n","Processed batch 1266/1543 (32 items)\n","Processed batch 1267/1543 (32 items)\n","Processed batch 1268/1543 (32 items)\n","Processed batch 1269/1543 (32 items)\n","Checkpoint saved at batch 1270\n","Processed batch 1270/1543 (32 items)\n","\n","        API Calls: 1271\n","        Total Tokens: 2770749\n","        Estimated Cost: $5.54\n","        \n","Processed batch 1271/1543 (32 items)\n","Processed batch 1272/1543 (32 items)\n","Processed batch 1273/1543 (32 items)\n","Processed batch 1274/1543 (32 items)\n","Processed batch 1275/1543 (32 items)\n","Processed batch 1276/1543 (32 items)\n","Processed batch 1277/1543 (32 items)\n","Processed batch 1278/1543 (32 items)\n","Processed batch 1279/1543 (32 items)\n","Checkpoint saved at batch 1280\n","Processed batch 1280/1543 (32 items)\n","\n","        API Calls: 1281\n","        Total Tokens: 2792909\n","        Estimated Cost: $5.59\n","        \n","Processed batch 1281/1543 (32 items)\n","Processed batch 1282/1543 (32 items)\n","Processed batch 1283/1543 (32 items)\n","Processed batch 1284/1543 (32 items)\n","Processed batch 1285/1543 (32 items)\n","Processed batch 1286/1543 (32 items)\n","Processed batch 1287/1543 (32 items)\n","Processed batch 1288/1543 (32 items)\n","Processed batch 1289/1543 (32 items)\n","Checkpoint saved at batch 1290\n","Processed batch 1290/1543 (32 items)\n","\n","        API Calls: 1291\n","        Total Tokens: 2814646\n","        Estimated Cost: $5.63\n","        \n","Processed batch 1291/1543 (32 items)\n","Processed batch 1292/1543 (32 items)\n","Processed batch 1293/1543 (32 items)\n","Processed batch 1294/1543 (32 items)\n","Processed batch 1295/1543 (32 items)\n","Processed batch 1296/1543 (32 items)\n","Processed batch 1297/1543 (32 items)\n","Processed batch 1298/1543 (32 items)\n","Processed batch 1299/1543 (32 items)\n","Checkpoint saved at batch 1300\n","Processed batch 1300/1543 (32 items)\n","\n","        API Calls: 1301\n","        Total Tokens: 2837369\n","        Estimated Cost: $5.67\n","        \n","Processed batch 1301/1543 (32 items)\n","Processed batch 1302/1543 (32 items)\n","Processed batch 1303/1543 (32 items)\n","Processed batch 1304/1543 (32 items)\n","Processed batch 1305/1543 (32 items)\n","Processed batch 1306/1543 (32 items)\n","Processed batch 1307/1543 (32 items)\n","Processed batch 1308/1543 (32 items)\n","Processed batch 1309/1543 (32 items)\n","Checkpoint saved at batch 1310\n","Processed batch 1310/1543 (32 items)\n","\n","        API Calls: 1311\n","        Total Tokens: 2859571\n","        Estimated Cost: $5.72\n","        \n","Processed batch 1311/1543 (32 items)\n","Processed batch 1312/1543 (32 items)\n","Processed batch 1313/1543 (32 items)\n","Processed batch 1314/1543 (32 items)\n","Processed batch 1315/1543 (32 items)\n","Processed batch 1316/1543 (32 items)\n","Processed batch 1317/1543 (32 items)\n","Processed batch 1318/1543 (32 items)\n","Processed batch 1319/1543 (32 items)\n","Checkpoint saved at batch 1320\n","Processed batch 1320/1543 (32 items)\n","\n","        API Calls: 1321\n","        Total Tokens: 2881348\n","        Estimated Cost: $5.76\n","        \n","Processed batch 1321/1543 (32 items)\n","Processed batch 1322/1543 (32 items)\n","Processed batch 1323/1543 (32 items)\n","Processed batch 1324/1543 (32 items)\n","Processed batch 1325/1543 (32 items)\n","Processed batch 1326/1543 (32 items)\n","Processed batch 1327/1543 (32 items)\n","Processed batch 1328/1543 (32 items)\n","Processed batch 1329/1543 (32 items)\n","Checkpoint saved at batch 1330\n","Processed batch 1330/1543 (32 items)\n","\n","        API Calls: 1331\n","        Total Tokens: 2903554\n","        Estimated Cost: $5.81\n","        \n","Processed batch 1331/1543 (32 items)\n","Processed batch 1332/1543 (32 items)\n","Processed batch 1333/1543 (32 items)\n","Processed batch 1334/1543 (32 items)\n","Processed batch 1335/1543 (32 items)\n","Processed batch 1336/1543 (32 items)\n","Processed batch 1337/1543 (32 items)\n","Processed batch 1338/1543 (32 items)\n","Processed batch 1339/1543 (32 items)\n","Checkpoint saved at batch 1340\n","Processed batch 1340/1543 (32 items)\n","\n","        API Calls: 1341\n","        Total Tokens: 2925367\n","        Estimated Cost: $5.85\n","        \n","Processed batch 1341/1543 (32 items)\n","Processed batch 1342/1543 (32 items)\n","Processed batch 1343/1543 (32 items)\n","Processed batch 1344/1543 (32 items)\n","Processed batch 1345/1543 (32 items)\n","Processed batch 1346/1543 (32 items)\n","Processed batch 1347/1543 (32 items)\n","Processed batch 1348/1543 (32 items)\n","Processed batch 1349/1543 (32 items)\n","Checkpoint saved at batch 1350\n","Processed batch 1350/1543 (32 items)\n","\n","        API Calls: 1351\n","        Total Tokens: 2947333\n","        Estimated Cost: $5.89\n","        \n","Processed batch 1351/1543 (32 items)\n","Processed batch 1352/1543 (32 items)\n","Processed batch 1353/1543 (32 items)\n","Processed batch 1354/1543 (32 items)\n","Processed batch 1355/1543 (32 items)\n","Processed batch 1356/1543 (32 items)\n","Processed batch 1357/1543 (32 items)\n","Processed batch 1358/1543 (32 items)\n","Processed batch 1359/1543 (32 items)\n","Checkpoint saved at batch 1360\n","Processed batch 1360/1543 (32 items)\n","\n","        API Calls: 1361\n","        Total Tokens: 2968608\n","        Estimated Cost: $5.94\n","        \n","Processed batch 1361/1543 (32 items)\n","Processed batch 1362/1543 (32 items)\n","Processed batch 1363/1543 (32 items)\n","Processed batch 1364/1543 (32 items)\n","Processed batch 1365/1543 (32 items)\n","Processed batch 1366/1543 (32 items)\n","Processed batch 1367/1543 (32 items)\n","Processed batch 1368/1543 (32 items)\n","Processed batch 1369/1543 (32 items)\n","Checkpoint saved at batch 1370\n","Processed batch 1370/1543 (32 items)\n","\n","        API Calls: 1371\n","        Total Tokens: 2990261\n","        Estimated Cost: $5.98\n","        \n","Processed batch 1371/1543 (32 items)\n","Processed batch 1372/1543 (32 items)\n","Processed batch 1373/1543 (32 items)\n","Processed batch 1374/1543 (32 items)\n","Processed batch 1375/1543 (32 items)\n","Processed batch 1376/1543 (32 items)\n","Processed batch 1377/1543 (32 items)\n","Processed batch 1378/1543 (32 items)\n","Processed batch 1379/1543 (32 items)\n","Checkpoint saved at batch 1380\n","Processed batch 1380/1543 (32 items)\n","\n","        API Calls: 1381\n","        Total Tokens: 3010937\n","        Estimated Cost: $6.02\n","        \n","Processed batch 1381/1543 (32 items)\n","Processed batch 1382/1543 (32 items)\n","Processed batch 1383/1543 (32 items)\n","Processed batch 1384/1543 (32 items)\n","Processed batch 1385/1543 (32 items)\n","Processed batch 1386/1543 (32 items)\n","Processed batch 1387/1543 (32 items)\n","Processed batch 1388/1543 (32 items)\n","Processed batch 1389/1543 (32 items)\n","Checkpoint saved at batch 1390\n","Processed batch 1390/1543 (32 items)\n","\n","        API Calls: 1391\n","        Total Tokens: 3032824\n","        Estimated Cost: $6.07\n","        \n","Processed batch 1391/1543 (32 items)\n","Processed batch 1392/1543 (32 items)\n","Processed batch 1393/1543 (32 items)\n","Processed batch 1394/1543 (32 items)\n","Processed batch 1395/1543 (32 items)\n","Processed batch 1396/1543 (32 items)\n","Processed batch 1397/1543 (32 items)\n","Processed batch 1398/1543 (32 items)\n","Processed batch 1399/1543 (32 items)\n","Checkpoint saved at batch 1400\n","Processed batch 1400/1543 (32 items)\n","\n","        API Calls: 1401\n","        Total Tokens: 3054934\n","        Estimated Cost: $6.11\n","        \n","Processed batch 1401/1543 (32 items)\n","Processed batch 1402/1543 (32 items)\n","Processed batch 1403/1543 (32 items)\n","Processed batch 1404/1543 (32 items)\n","Processed batch 1405/1543 (32 items)\n","Processed batch 1406/1543 (32 items)\n","Processed batch 1407/1543 (32 items)\n","Processed batch 1408/1543 (32 items)\n","Processed batch 1409/1543 (32 items)\n","Checkpoint saved at batch 1410\n","Processed batch 1410/1543 (32 items)\n","\n","        API Calls: 1411\n","        Total Tokens: 3075976\n","        Estimated Cost: $6.15\n","        \n","Processed batch 1411/1543 (32 items)\n","Processed batch 1412/1543 (32 items)\n","Processed batch 1413/1543 (32 items)\n","Processed batch 1414/1543 (32 items)\n","Processed batch 1415/1543 (32 items)\n","Processed batch 1416/1543 (32 items)\n","Processed batch 1417/1543 (32 items)\n","Processed batch 1418/1543 (32 items)\n","Processed batch 1419/1543 (32 items)\n","Checkpoint saved at batch 1420\n","Processed batch 1420/1543 (32 items)\n","\n","        API Calls: 1421\n","        Total Tokens: 3098375\n","        Estimated Cost: $6.20\n","        \n","Processed batch 1421/1543 (32 items)\n","Processed batch 1422/1543 (32 items)\n","Processed batch 1423/1543 (32 items)\n","Processed batch 1424/1543 (32 items)\n","Processed batch 1425/1543 (32 items)\n","Processed batch 1426/1543 (32 items)\n","Processed batch 1427/1543 (32 items)\n","Processed batch 1428/1543 (32 items)\n","Processed batch 1429/1543 (32 items)\n","Checkpoint saved at batch 1430\n","Processed batch 1430/1543 (32 items)\n","\n","        API Calls: 1431\n","        Total Tokens: 3119849\n","        Estimated Cost: $6.24\n","        \n","Processed batch 1431/1543 (32 items)\n","Processed batch 1432/1543 (32 items)\n","Processed batch 1433/1543 (32 items)\n","Processed batch 1434/1543 (32 items)\n","Processed batch 1435/1543 (32 items)\n","Processed batch 1436/1543 (32 items)\n","Processed batch 1437/1543 (32 items)\n","Processed batch 1438/1543 (32 items)\n","Processed batch 1439/1543 (32 items)\n","Checkpoint saved at batch 1440\n","Processed batch 1440/1543 (32 items)\n","\n","        API Calls: 1441\n","        Total Tokens: 3140864\n","        Estimated Cost: $6.28\n","        \n","Processed batch 1441/1543 (32 items)\n","Processed batch 1442/1543 (32 items)\n","Processed batch 1443/1543 (32 items)\n","Processed batch 1444/1543 (32 items)\n","Processed batch 1445/1543 (32 items)\n","Processed batch 1446/1543 (32 items)\n","Processed batch 1447/1543 (32 items)\n","Processed batch 1448/1543 (32 items)\n","Processed batch 1449/1543 (32 items)\n","Checkpoint saved at batch 1450\n","Processed batch 1450/1543 (32 items)\n","\n","        API Calls: 1451\n","        Total Tokens: 3162772\n","        Estimated Cost: $6.33\n","        \n","Processed batch 1451/1543 (32 items)\n","Processed batch 1452/1543 (32 items)\n","Processed batch 1453/1543 (32 items)\n","Processed batch 1454/1543 (32 items)\n","Processed batch 1455/1543 (32 items)\n","Processed batch 1456/1543 (32 items)\n","Processed batch 1457/1543 (32 items)\n","Processed batch 1458/1543 (32 items)\n","Processed batch 1459/1543 (32 items)\n","Checkpoint saved at batch 1460\n","Processed batch 1460/1543 (32 items)\n","\n","        API Calls: 1461\n","        Total Tokens: 3185094\n","        Estimated Cost: $6.37\n","        \n","Processed batch 1461/1543 (32 items)\n","Processed batch 1462/1543 (32 items)\n","Processed batch 1463/1543 (32 items)\n","Processed batch 1464/1543 (32 items)\n","Processed batch 1465/1543 (32 items)\n","Processed batch 1466/1543 (32 items)\n","Processed batch 1467/1543 (32 items)\n","Processed batch 1468/1543 (32 items)\n","Processed batch 1469/1543 (32 items)\n","Checkpoint saved at batch 1470\n","Processed batch 1470/1543 (32 items)\n","\n","        API Calls: 1471\n","        Total Tokens: 3205898\n","        Estimated Cost: $6.41\n","        \n","Processed batch 1471/1543 (32 items)\n","Processed batch 1472/1543 (32 items)\n","Processed batch 1473/1543 (32 items)\n","Processed batch 1474/1543 (32 items)\n","Processed batch 1475/1543 (32 items)\n","Processed batch 1476/1543 (32 items)\n","Processed batch 1477/1543 (32 items)\n","Processed batch 1478/1543 (32 items)\n","Processed batch 1479/1543 (32 items)\n","Checkpoint saved at batch 1480\n","Processed batch 1480/1543 (32 items)\n","\n","        API Calls: 1481\n","        Total Tokens: 3227346\n","        Estimated Cost: $6.45\n","        \n","Processed batch 1481/1543 (32 items)\n","Processed batch 1482/1543 (32 items)\n","Processed batch 1483/1543 (32 items)\n","Processed batch 1484/1543 (32 items)\n","Processed batch 1485/1543 (32 items)\n","Processed batch 1486/1543 (32 items)\n","Processed batch 1487/1543 (32 items)\n","Processed batch 1488/1543 (32 items)\n","Processed batch 1489/1543 (32 items)\n","Checkpoint saved at batch 1490\n","Processed batch 1490/1543 (32 items)\n","\n","        API Calls: 1491\n","        Total Tokens: 3249024\n","        Estimated Cost: $6.50\n","        \n","Processed batch 1491/1543 (32 items)\n","Processed batch 1492/1543 (32 items)\n","Processed batch 1493/1543 (32 items)\n","Processed batch 1494/1543 (32 items)\n","Processed batch 1495/1543 (32 items)\n","Processed batch 1496/1543 (32 items)\n","Processed batch 1497/1543 (32 items)\n","Processed batch 1498/1543 (32 items)\n","Processed batch 1499/1543 (32 items)\n","Checkpoint saved at batch 1500\n","Processed batch 1500/1543 (32 items)\n","\n","        API Calls: 1501\n","        Total Tokens: 3270960\n","        Estimated Cost: $6.54\n","        \n","Processed batch 1501/1543 (32 items)\n","Processed batch 1502/1543 (32 items)\n","Processed batch 1503/1543 (32 items)\n","Processed batch 1504/1543 (32 items)\n","Processed batch 1505/1543 (32 items)\n","Processed batch 1506/1543 (32 items)\n","Processed batch 1507/1543 (32 items)\n","Processed batch 1508/1543 (32 items)\n","Processed batch 1509/1543 (32 items)\n","Checkpoint saved at batch 1510\n","Processed batch 1510/1543 (32 items)\n","\n","        API Calls: 1511\n","        Total Tokens: 3291448\n","        Estimated Cost: $6.58\n","        \n","Processed batch 1511/1543 (32 items)\n","Processed batch 1512/1543 (32 items)\n","Processed batch 1513/1543 (32 items)\n","Processed batch 1514/1543 (32 items)\n","Processed batch 1515/1543 (32 items)\n","Processed batch 1516/1543 (32 items)\n","Processed batch 1517/1543 (32 items)\n","Processed batch 1518/1543 (32 items)\n","Processed batch 1519/1543 (32 items)\n","Checkpoint saved at batch 1520\n","Processed batch 1520/1543 (32 items)\n","\n","        API Calls: 1521\n","        Total Tokens: 3314435\n","        Estimated Cost: $6.63\n","        \n","Processed batch 1521/1543 (32 items)\n","Processed batch 1522/1543 (32 items)\n","Processed batch 1523/1543 (32 items)\n","Processed batch 1524/1543 (32 items)\n","Processed batch 1525/1543 (32 items)\n","Processed batch 1526/1543 (32 items)\n","Processed batch 1527/1543 (32 items)\n","Processed batch 1528/1543 (32 items)\n","Processed batch 1529/1543 (32 items)\n","Checkpoint saved at batch 1530\n","Processed batch 1530/1543 (32 items)\n","\n","        API Calls: 1531\n","        Total Tokens: 3336584\n","        Estimated Cost: $6.67\n","        \n","Processed batch 1531/1543 (32 items)\n","Processed batch 1532/1543 (32 items)\n","Processed batch 1533/1543 (32 items)\n","Processed batch 1534/1543 (32 items)\n","Processed batch 1535/1543 (32 items)\n","Processed batch 1536/1543 (32 items)\n","Processed batch 1537/1543 (32 items)\n","Processed batch 1538/1543 (32 items)\n","Processed batch 1539/1543 (32 items)\n","Checkpoint saved at batch 1540\n","Processed batch 1540/1543 (32 items)\n","\n","        API Calls: 1541\n","        Total Tokens: 3358551\n","        Estimated Cost: $6.72\n","        \n","Processed batch 1541/1543 (32 items)\n","Processed batch 1542/1543 (32 items)\n","Processed batch 1543/1543 (25 items)\n","\n","Final Statistics:\n","\n","        API Calls: 1544\n","        Total Tokens: 3364654\n","        Estimated Cost: $6.73\n","        \n","Total translations: 49401\n"]}]},{"cell_type":"markdown","metadata":{"id":"faVNT2NCBkXu"},"source":["#### Check the number of lines in the file"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4976,"status":"ok","timestamp":1734602901137,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"},"user_tz":-60},"outputId":"53d36e7d-e4e4-4048-bf6d-b1ca44406f92","id":"sFJknMiJBkXu"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","File found!\n","The file has 49402 rows.\n"]}],"source":["# Chech the size of the file\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","#file_path = \"/content/drive/My Drive/Colab Notebooks/paws_train.tsv\"\n","file_path = \"/content/drive/My Drive/Colab Notebooks/paws_paraphrase_test_originals_GPT3.5.txt\"\n","\n","# Check if file exists\n","import os\n","if os.path.exists(file_path):\n","    print(\"File found!\")\n","else:\n","    print(\"File not found. Check the path!\")\n","\n","#file_path = \"/content/drive/My Drive/Colab Notebooks/paws_train.tsv\"\n","file_path = \"/content/drive/My Drive/Colab Notebooks/paws_paraphrase_test_originals_GPT3.5.txt\"\n","\n","# Count lines in the file\n","with open(file_path, \"r\", encoding=\"utf-8\") as file:\n","    line_count = sum(1 for line in file if line.strip())  # Excludes empty lines\n","\n","print(f\"The file has {line_count} rows.\")\n"]},{"cell_type":"markdown","metadata":{"id":"E3utXiV_BkXv"},"source":[]},{"cell_type":"markdown","metadata":{"id":"fdUr6j_0BkXz"},"source":["## **Quora Duplicate Questions**"]},{"cell_type":"markdown","metadata":{"id":"xVsiYu9eBkXz"},"source":["#### Checking the size of the file"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739542567486,"user_tz":-60,"elapsed":121787,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"acbcff30-d8fc-4059-ed9a-cfd50af946f7","id":"w1RGOCsPBkXz"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","File found!\n","The file has 200032 rows.\n"]}],"source":["# Check the size of the file\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","#file_path = \"/content/drive/My Drive/Colab Notebooks/quora_duplicate_questions.tsv\"\n","#file_path = \"/content/drive/My Drive/Colab Notebooks/quora_test_translations_GPT3.5.txt\"\n","file_path = \"/content/drive/My Drive/Colab Notebooks/quora_test_originals_GPT3.5.txt\"\n","\n","# Check if file exists\n","import os\n","if os.path.exists(file_path):\n","    print(\"File found!\")\n","else:\n","    print(\"File not found. Check the path!\")\n","\n","#file_path = \"/content/drive/My Drive/Colab Notebooks/quora_duplicate_questions.tsv\"\n","#file_path = \"/content/drive/My Drive/Colab Notebooks/quora_test_translations_GPT3.5.txt\"\n","file_path = \"/content/drive/My Drive/Colab Notebooks/quora_test_originals_GPT3.5.txt\"\n","\n","# Count lines in the file\n","with open(file_path, \"r\", encoding=\"utf-8\") as file:\n","    line_count = sum(1 for line in file if line.strip())  # Excludes empty lines\n","\n","print(f\"The file has {line_count} rows.\")\n"]},{"cell_type":"markdown","source":["#### Translate with in-between checkpoints (because it is the biggest file of all)"],"metadata":{"id":"4_qBaj9Tq3wH"}},{"cell_type":"code","source":["from typing import Iterator, List, Dict, Any, Tuple, Optional\n","import json\n","import os\n","from pathlib import Path\n","from datetime import datetime\n","from openai import OpenAI\n","from openai.types.chat import ChatCompletion\n","import time\n","import logging\n","from concurrent.futures import ThreadPoolExecutor, as_completed\n","\n","# Configure logging\n","logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n","\n","class TranslationManager:\n","    def __init__(self, api_key: str, cache_dir: str = \"translation_cache\", checkpoint_dir: str = \"checkpoints\"):\n","        self.client = OpenAI(api_key=api_key)\n","        self.cache_dir = Path(cache_dir)\n","        self.checkpoint_dir = Path(checkpoint_dir)\n","        self.cache_dir.mkdir(exist_ok=True)\n","        self.checkpoint_dir.mkdir(exist_ok=True)\n","        self.batch_cache = {}\n","        self.current_cache_size = 0\n","        self.max_cache_size = 1000\n","\n","    def _get_cache_file(self, batch_id: str) -> Path:\n","        return self.cache_dir / f\"cache_{batch_id}.json\"\n","\n","    def get_checkpoint_file(self, dataset_name: str) -> Path:\n","        return self.checkpoint_dir / f\"{dataset_name}_checkpoint.json\"\n","\n","    def _save_batch_cache(self, batch_id: str):\n","        cache_file = self._get_cache_file(batch_id)\n","        with open(cache_file, 'w', encoding='utf-8') as f:\n","            json.dump(self.batch_cache, f, ensure_ascii=False, indent=2)\n","        self.batch_cache = {}\n","        self.current_cache_size = 0\n","\n","    def _load_cache(self, batch_id: str) -> Dict:\n","        cache_file = self._get_cache_file(batch_id)\n","        if cache_file.exists():\n","            with open(cache_file, 'r', encoding='utf-8') as f:\n","                return json.load(f)\n","        return {}\n","\n","    def save_checkpoint(self, dataset_name: str, batch_num: int, translations_count: int):\n","        checkpoint_data = {\n","            \"last_batch\": batch_num,\n","            \"translations_count\": translations_count,\n","            \"timestamp\": datetime.now().isoformat()\n","        }\n","        checkpoint_file = self.get_checkpoint_file(dataset_name)\n","        with open(checkpoint_file, 'w', encoding='utf-8') as f:\n","            json.dump(checkpoint_data, f, indent=2)\n","        logging.info(f\"Checkpoint saved to {checkpoint_file}\")\n","\n","    def load_checkpoint(self, dataset_name: str) -> Dict:\n","        checkpoint_file = self.get_checkpoint_file(dataset_name)\n","        if checkpoint_file.exists():\n","            with open(checkpoint_file, 'r', encoding='utf-8') as f:\n","                return json.load(f)\n","        return {\"last_batch\": -1, \"translations_count\": 0}\n","\n","    def translate_batch(self, texts: List[str], batch_id: str) -> Tuple[List[str], Optional[ChatCompletion]]:\n","        if not texts:\n","            return [], None\n","\n","        try:\n","            cache = self._load_cache(batch_id)\n","            translations = []\n","            uncached_texts = []\n","            uncached_indices = []\n","\n","            for i, text in enumerate(texts):\n","                text = text.strip()\n","                if not text:  # Skip empty strings\n","                    translations.append(\"\")\n","                    continue\n","                if text in cache:\n","                    translations.append(cache[text])\n","                else:\n","                    uncached_texts.append(text)\n","                    uncached_indices.append(i)\n","\n","            if uncached_texts:\n","                retry_attempts = 3\n","                for attempt in range(retry_attempts):\n","                    try:\n","                        response = self.client.chat.completions.create(\n","                            model=\"gpt-3.5-turbo\",\n","                            messages=[\n","                                {\"role\": \"system\", \"content\": \"Translate the following English texts to Slovenian:\"},\n","                                {\"role\": \"user\", \"content\": \"\\n-\\n\".join(uncached_texts)}\n","                            ],\n","                            temperature=0.3\n","                        )\n","\n","                        new_translations = [choice.message.content for choice in response.choices]\n","\n","                        # Ensure we have the same number of translations as input texts\n","                        if len(new_translations) != len(uncached_texts):\n","                            new_translations = new_translations[:len(uncached_texts)]\n","                            if len(new_translations) < len(uncached_texts):\n","                                new_translations.extend([\"\"] * (len(uncached_texts) - len(new_translations)))\n","\n","                        for text, trans in zip(uncached_texts, new_translations):\n","                            self.batch_cache[text] = trans\n","                            self.current_cache_size += 1\n","\n","                        for idx, trans in zip(uncached_indices, new_translations):\n","                            translations.insert(idx, trans)\n","\n","                        if self.current_cache_size >= self.max_cache_size:\n","                            self._save_batch_cache(batch_id)\n","\n","                        return translations, response\n","\n","                    except Exception as e:\n","                        logging.error(f\"Error in API call (attempt {attempt + 1}/{retry_attempts}): {str(e)}\")\n","                        if attempt < retry_attempts - 1:\n","                            time.sleep(2 ** attempt)  # Exponential backoff\n","                        else:\n","                            # If all attempts fail, log the error and return partial results\n","                            for idx in uncached_indices:\n","                                translations.insert(idx, f\"ERROR: {str(e)}\")\n","                            return translations, None\n","\n","            return translations, None\n","\n","        except Exception as e:\n","            logging.error(f\"Error in batch processing: {str(e)}\")\n","            return [f\"ERROR: {str(e)}\"] * len(texts), None\n","\n","class DatasetIterator:\n","    def __init__(self, file_path: str, batch_size: int, start_line: int = 0, max_sentences: int = 400000):\n","        self.file_path = file_path\n","        self.batch_size = batch_size\n","        self.max_sentences = max_sentences\n","        self.total_lines = min(self._count_lines(), max_sentences)  # Limit total lines\n","        self.start_line = min(start_line, max(0, self.total_lines - 1))\n","\n","    def _count_lines(self) -> int:\n","        try:\n","            with open(self.file_path, \"r\", encoding=\"utf-8\") as f:\n","                return sum(1 for _ in f)\n","        except Exception as e:\n","            logging.error(f\"Error counting lines: {str(e)}\")\n","            return 0\n","\n","    def __iter__(self) -> Iterator[List[str]]:\n","        current_batch = []\n","        processed_lines = 0\n","\n","        try:\n","            with open(self.file_path, \"r\", encoding=\"utf-8\") as f:\n","                # Skip to start line\n","                for _ in range(self.start_line):\n","                    next(f, None)\n","\n","                for line in f:\n","                    if processed_lines >= self.max_sentences:\n","                        break\n","\n","                    line = line.strip()\n","                    if line:  # Only add non-empty lines\n","                        current_batch.append(line)\n","                        processed_lines += 1\n","\n","                        if len(current_batch) == self.batch_size:\n","                            yield current_batch\n","                            current_batch = []\n","\n","                    if processed_lines >= self.max_sentences:\n","                        break\n","\n","                if current_batch:  # Don't forget last partial batch\n","                    yield current_batch\n","\n","        except Exception as e:\n","            logging.error(f\"Error reading file: {str(e)}\")\n","            if current_batch:  # Yield any remaining batch on error\n","                yield current_batch\n","\n","class CostTracker:\n","    def __init__(self):\n","        self.requests = 0\n","        self.total_tokens = 0\n","        self.price_per_1k_tokens = 0.002\n","\n","    def update(self, response: ChatCompletion):\n","        self.requests += 1\n","        self.total_tokens += response.usage.completion_tokens + response.usage.prompt_tokens\n","\n","    def get_cost(self) -> float:\n","        return (self.total_tokens / 1000) * self.price_per_1k_tokens\n","\n","    def report(self) -> str:\n","        return f\"\"\"\n","        API Calls: {self.requests}\n","        Total Tokens: {self.total_tokens}\n","        Estimated Cost: ${self.get_cost():.2f}\n","        \"\"\"\n","\n","def save_pairs(originals: List[str], translations: List[str], dataset_name: str, mode: str = \"a\"):\n","    base_path = Path(\"/content/drive/My Drive/Colab Notebooks\")\n","\n","    for filename, data in [\n","        (f\"{dataset_name}_originals_GPT3.5.txt\", originals),\n","        (f\"{dataset_name}_translations_GPT3.5.txt\", translations),\n","    ]:\n","        try:\n","            with open(base_path / filename, mode, encoding=\"utf-8\") as f:\n","                for item in data:\n","                    f.write(f\"{item}\\n\")\n","        except Exception as e:\n","            logging.error(f\"Error saving to {filename}: {str(e)}\")\n","\n","    try:\n","        with open(base_path / f\"{dataset_name}_aligned_pairs_GPT3.5.txt\", mode, encoding=\"utf-8\") as f:\n","            for orig, trans in zip(originals, translations):\n","                f.write(f\"Original: {orig}\\nTranslation: {trans}\\n---\\n\")\n","    except Exception as e:\n","        logging.error(f\"Error saving aligned pairs: {str(e)}\")\n","\n","def process_dataset(\n","    input_file: str,\n","    dataset_name: str,\n","    api_key: str,\n","    batch_size: int = 32,\n","    checkpoint_interval: int = 10,\n","    max_sentences: int = 404302\n","):\n","    translator = TranslationManager(api_key=api_key)\n","\n","    # Load checkpoint if exists\n","    checkpoint = translator.load_checkpoint(dataset_name)\n","    start_batch = checkpoint[\"last_batch\"] + 1\n","    translations_count = checkpoint[\"translations_count\"]\n","\n","    # Calculate starting line\n","    start_line = start_batch * batch_size\n","\n","    # Create iterator with sentence limit\n","    dataset_iterator = DatasetIterator(\n","        file_path=input_file,\n","        batch_size=batch_size,\n","        start_line=start_line,\n","        max_sentences=max_sentences\n","    )\n","\n","    cost_tracker = CostTracker()\n","    total_batches = max(1, min(dataset_iterator.total_lines, max_sentences) // batch_size)\n","\n","    logging.info(f\"Starting from batch {start_batch}, line {start_line}\")\n","    logging.info(f\"Will process up to {max_sentences} sentences\")\n","    logging.info(f\"Total lines to process: {min(dataset_iterator.total_lines, max_sentences)}\")\n","\n","    for batch_num, batch in enumerate(dataset_iterator, start=start_batch):\n","        try:\n","            batch_id = f\"{dataset_name}_{batch_num}\"\n","            translations, response = translator.translate_batch(batch, batch_id)\n","\n","            if response is not None:\n","                cost_tracker.update(response)\n","\n","            save_pairs(batch, translations, dataset_name, mode=\"a\")\n","            translations_count += len(translations)\n","\n","            if batch_num % checkpoint_interval == 0:\n","                translator.save_checkpoint(dataset_name, batch_num, translations_count)\n","                logging.info(f\"Checkpoint saved at batch {batch_num}\")\n","\n","            logging.info(f\"Processed batch {batch_num}/{total_batches} ({len(batch)} items)\")\n","            if batch_num % 10 == 0:\n","                logging.info(cost_tracker.report())\n","\n","            # Add a small delay to avoid rate limiting\n","            time.sleep(0.5)\n","\n","        except Exception as e:\n","            logging.error(f\"Error processing batch {batch_num}: {str(e)}\")\n","            translator.save_checkpoint(dataset_name, batch_num-1, translations_count)\n","            time.sleep(1)  # Longer delay on error\n","            continue\n","\n","    # Final checkpoint and report\n","    translator.save_checkpoint(dataset_name, total_batches-1, translations_count)\n","    logging.info(\"\\nFinal Statistics:\")\n","    logging.info(cost_tracker.report())\n","    logging.info(f\"Total translations: {translations_count}\")\n"],"metadata":{"id":"tlKxaHfcq8-I","executionInfo":{"status":"ok","timestamp":1739440115323,"user_tz":-60,"elapsed":1310,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    input_file = \"/content/drive/My Drive/Colab Notebooks/quora_duplicate_questions.tsv\"\n","    dataset_name = \"quora_test\"\n","    max_sentences = 404302  # Total number of sentences to process\n","\n","    try:\n","        from google.colab import userdata\n","        api_key = userdata.get('OPENAI_API_KEY')\n","    except ImportError:\n","        api_key = os.getenv('OPENAI_API_KEY')\n","\n","    if not api_key:\n","        raise ValueError(\"API key not found. Please set the OPENAI_API_KEY in Colab secrets or environment variables.\")\n","\n","    process_dataset(\n","        input_file=input_file,\n","        dataset_name=dataset_name,\n","        api_key=api_key,\n","        batch_size=32,\n","        checkpoint_interval=10,  # Save checkpoints frequently\n","        max_sentences=max_sentences,\n","    )"],"metadata":{"id":"GZRABuXWseyA"},"execution_count":null,"outputs":[]}]}