{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["8rUN7eCZBkXU","-BPcvwxZBkXY","WGlYsC5--jrt","rqxIWhx9KjHf","F4zPCMFybEjr","XQaBTuD2gYuV","0ZI23corEO87","xmSpvXmqEaup","FBvSHFhkNC13","A-OSOdPAD7a9","-kyeulRnpPUQ","y2rWRZKQ_-GX"],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyMDX5x7hYlHSSQ5pd31gKF2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"d5ea5c60ffb146ee92a8f7f797e98d84":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_88925edbe6d64d338c70837a04033dd7","IPY_MODEL_d06d823ef62b4c0eb50e9580b7bb7f16","IPY_MODEL_538e93d0af774b45a2084de734c592df"],"layout":"IPY_MODEL_5f584a40ff9f40299d635aaa8e830710"}},"88925edbe6d64d338c70837a04033dd7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a4bc236de604c8b8e506c086b53a6cf","placeholder":"​","style":"IPY_MODEL_27a06956a84c4a9bb1233751ec4e09af","value":"Processing batches: 100%"}},"d06d823ef62b4c0eb50e9580b7bb7f16":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_042d3bbbec634a1b92f473c63d5f78fe","max":30,"min":0,"orientation":"horizontal","style":"IPY_MODEL_258cbce6fecb45db852489edd9ba7cae","value":30}},"538e93d0af774b45a2084de734c592df":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9d274a1776e4b248df32b6273673c06","placeholder":"​","style":"IPY_MODEL_2b33a83cd24a4b3688062bd27cb05771","value":" 30/30 [04:03&lt;00:00,  5.04s/it]"}},"5f584a40ff9f40299d635aaa8e830710":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a4bc236de604c8b8e506c086b53a6cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27a06956a84c4a9bb1233751ec4e09af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"042d3bbbec634a1b92f473c63d5f78fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"258cbce6fecb45db852489edd9ba7cae":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f9d274a1776e4b248df32b6273673c06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b33a83cd24a4b3688062bd27cb05771":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f7c604680eb0449585cdc0be1dc92bdf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_deb162482986433ea34ff79463194b2b","IPY_MODEL_0eda439bfbd94e5baf173d078fbfb002","IPY_MODEL_5f101e0a6e034227828955b1605b4bc4"],"layout":"IPY_MODEL_72ae29eb5f9d4b8381df7f614bce70da"}},"deb162482986433ea34ff79463194b2b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_376f6f13d1df492b879131562b525178","placeholder":"​","style":"IPY_MODEL_6382ee4e63b247d487677fe72f7b4141","value":"100%"}},"0eda439bfbd94e5baf173d078fbfb002":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7a487a9e8554ad59bfbf58db4dd4c1e","max":15625,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dbe12e6a5a834759a8c2ca18a3d6a780","value":15625}},"5f101e0a6e034227828955b1605b4bc4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7ef4f3248784490bc873d5b35c496e4","placeholder":"​","style":"IPY_MODEL_cac0d1acc1bf41378ca3640d2ee3adec","value":" 15625/15625 [05:26&lt;00:00, 46.21it/s]"}},"72ae29eb5f9d4b8381df7f614bce70da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"376f6f13d1df492b879131562b525178":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6382ee4e63b247d487677fe72f7b4141":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f7a487a9e8554ad59bfbf58db4dd4c1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dbe12e6a5a834759a8c2ca18a3d6a780":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a7ef4f3248784490bc873d5b35c496e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cac0d1acc1bf41378ca3640d2ee3adec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cbe755f789df4150b44eca81c7272a8e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_629ecbb5d7d5405b805e307a64656da4","IPY_MODEL_eb401c48e452472399e144567ccf517d","IPY_MODEL_b5562fdbd1b5466dbfc5b630f76a4512"],"layout":"IPY_MODEL_45f00cce07384502997e21f6f87a8665"}},"629ecbb5d7d5405b805e307a64656da4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8252dc5cb6e14ab3ac3b616ac0dbc30d","placeholder":"​","style":"IPY_MODEL_e04aefacdde64ef286bcc50f66677f6f","value":"100%"}},"eb401c48e452472399e144567ccf517d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb59746519ca4bec88d2af34a881bd86","max":15625,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b334019243b04b30b2e9ddc11e141b4c","value":15625}},"b5562fdbd1b5466dbfc5b630f76a4512":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_69e03c6398ec436eb0b268fc0f995c17","placeholder":"​","style":"IPY_MODEL_1454a7c0837144669982c830cd2373d9","value":" 15625/15625 [06:29&lt;00:00, 41.35it/s]"}},"45f00cce07384502997e21f6f87a8665":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8252dc5cb6e14ab3ac3b616ac0dbc30d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e04aefacdde64ef286bcc50f66677f6f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bb59746519ca4bec88d2af34a881bd86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b334019243b04b30b2e9ddc11e141b4c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"69e03c6398ec436eb0b268fc0f995c17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1454a7c0837144669982c830cd2373d9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5184c5effb8c48ab86f4c822323bb4f4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3a2ed0a7420f4470bc104e5ecd811219","IPY_MODEL_a88ba9a7d07b485c8536556ddb9ec4e1","IPY_MODEL_6388f5abae4c435eb4323fca5e356c8a"],"layout":"IPY_MODEL_16e5e789a59e4b04af86ac4d469831b2"}},"3a2ed0a7420f4470bc104e5ecd811219":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_62b15f533c714266bb8569759e555bf0","placeholder":"​","style":"IPY_MODEL_d3b8102ae7144c4796045f37ecfd5178","value":"100%"}},"a88ba9a7d07b485c8536556ddb9ec4e1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b6be3fff88242f6b69d70916b1f68ae","max":15625,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1a3c13747995487ab8aa0dcd97a1d5cd","value":15625}},"6388f5abae4c435eb4323fca5e356c8a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0738a1ca7bc84a0687656d4a0aa3a873","placeholder":"​","style":"IPY_MODEL_5c1126610b4a4ba6835aa77dffac7112","value":" 15625/15625 [10:30&lt;00:00, 24.43it/s]"}},"16e5e789a59e4b04af86ac4d469831b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62b15f533c714266bb8569759e555bf0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3b8102ae7144c4796045f37ecfd5178":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0b6be3fff88242f6b69d70916b1f68ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a3c13747995487ab8aa0dcd97a1d5cd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0738a1ca7bc84a0687656d4a0aa3a873":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c1126610b4a4ba6835aa77dffac7112":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6cda1a10158b40b5addf593c00fb31e0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8b862bd8f33a4f7fa0f589f415f6cfa3","IPY_MODEL_baecdefadca740beb01a21086d42e76d","IPY_MODEL_f174fb46c0bc4e18b34299b118728981"],"layout":"IPY_MODEL_8c33b28d87934a1a82264c7db9747a47"}},"8b862bd8f33a4f7fa0f589f415f6cfa3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1fa91898583d4014b1e941ea714844f2","placeholder":"​","style":"IPY_MODEL_a6b2b061e475414fb0f4c7f0c3d77cd0","value":"100%"}},"baecdefadca740beb01a21086d42e76d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e954e04348a4d1a9948f6cda49b87ec","max":15625,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1771c0dabac04710a3c00f222100a693","value":15625}},"f174fb46c0bc4e18b34299b118728981":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4acfdbdb24842c7ab72b6a041bfa188","placeholder":"​","style":"IPY_MODEL_1fd3a0244da34920b1431423d43efbbb","value":" 15625/15625 [06:42&lt;00:00, 39.81it/s]"}},"8c33b28d87934a1a82264c7db9747a47":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fa91898583d4014b1e941ea714844f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6b2b061e475414fb0f4c7f0c3d77cd0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6e954e04348a4d1a9948f6cda49b87ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1771c0dabac04710a3c00f222100a693":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c4acfdbdb24842c7ab72b6a041bfa188":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fd3a0244da34920b1431423d43efbbb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"B7cJnBTxBa3h"},"source":["#### Code is using SpaCy to first lemmatize and then tokenize big excel file (200.000 row or more) in google colab with the use of GPU. First read the excel file from google drive which is mounted, then tokenized and lemmatized while semantically and lexically filtered in a pipeline for checking the strenght of sentences (column 1) and their paraphrases (column 2) in slovene language. Tokenization is make with CUDA cache and parallel processing."]},{"cell_type":"markdown","metadata":{"id":"j9NLS82cGq5F"},"source":["## Mount Google Drive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"msAJWILyGttj"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"markdown","metadata":{"id":"8rUN7eCZBkXU"},"source":["## Git add and commit"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7735,"status":"ok","timestamp":1742887687504,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"},"user_tz":-60},"id":"9s71E83_BkXU","outputId":"65d2ae20-83ec-497a-f467-9c3bf7b9a0fb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'paraphrase-categorization'...\n","remote: Enumerating objects: 184, done.\u001b[K\n","remote: Counting objects: 100% (41/41), done.\u001b[K\n","remote: Compressing objects: 100% (32/32), done.\u001b[K\n","remote: Total 184 (delta 14), reused 34 (delta 9), pack-reused 143 (from 1)\u001b[K\n","Receiving objects: 100% (184/184), 90.23 MiB | 21.06 MiB/s, done.\n","Resolving deltas: 100% (75/75), done.\n"]}],"source":["!git clone https://alikova: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@github.com/alikova/paraphrase-categorization.git\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":211,"status":"ok","timestamp":1742887688752,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"},"user_tz":-60},"id":"tAfkbrc3BkXV","outputId":"c2367d28-c5f7-4b8c-acd9-86e1e1c68c5f"},"outputs":[{"output_type":"stream","name":"stdout","text":["drive  paraphrase-categorization  sample_data\n"]}],"source":["!ls /content\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":140,"status":"ok","timestamp":1742887691787,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"},"user_tz":-60},"id":"-tcdAMSyBkXV","outputId":"df0b2b40-8a90-4782-a9db-ab44bca0eb7b"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/paraphrase-categorization\n","/content/paraphrase-categorization\n"]}],"source":["%cd /content/paraphrase-categorization\n","!pwd"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":719,"status":"ok","timestamp":1742887694616,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"},"user_tz":-60},"id":"uVLQ8AlpBkXW","outputId":"bcb2a16a-b827-4ff3-d974-78c7efd61b26"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/Preprocessing_Datasets_withMetrics.ipynb\n","/content/paraphrase-categorization/Preprocessing_Datasets_withMetrics.ipynb\n"," kaggle_prevajajanje_zbirk.html\n"," kategorije_parafraz_draft\n"," library_ontology\n","'Load and translate Paraphrases with GaMS _ Kaggle.html'\n"," paraphrase_categorization\n"," paraphrase_datasets_translation_GaMS_gpu\n"," Paraphrase_Datasets_Translations_GaMS.ipynb\n"," Paraphrase_Datasets_Translations_GPT3.5_GPU.ipynb\n"," Paraphrase_Datasets_Translations_GPT3.5.ipynb\n"," paraphrase_datasets_translations_gpt3_5.py\n"," paraphrase_read-and-translate.py\n"," Preprocessing_Datasets_withMetrics.ipynb\n"," README.md\n","'Colab Notebooks'   Translated_Datasets\n"]}],"source":["!find /content -name \"Preprocessing_Datasets_withMetrics.ipynb\"\n","\n","!ls /content/paraphrase-categorization/\n","\n","!ls /content/drive/MyDrive/\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":102,"status":"ok","timestamp":1742887697017,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"},"user_tz":-60},"id":"bLpfCqYYHay-","outputId":"a7a28120-4436-4082-9242-2f91ec3a75a3"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/Preprocessing_Datasets_withMetrics.ipynb\n"]}],"source":["!find /content/drive/ -name \"Preprocessing_Datasets_withMetrics.ipynb\"\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1109,"status":"ok","timestamp":1742887700488,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"},"user_tz":-60},"id":"HlEcO_pxBkXW","outputId":"04469ff4-1314-475d-bd22-14d72d130f76"},"outputs":[{"output_type":"stream","name":"stdout","text":[" kaggle_prevajajanje_zbirk.html\n"," kategorije_parafraz_draft\n"," library_ontology\n","'Load and translate Paraphrases with GaMS _ Kaggle.html'\n"," paraphrase_categorization\n"," paraphrase_datasets_translation_GaMS_gpu\n"," Paraphrase_Datasets_Translations_GaMS.ipynb\n"," Paraphrase_Datasets_Translations_GPT3.5_GPU.ipynb\n"," Paraphrase_Datasets_Translations_GPT3.5.ipynb\n"," paraphrase_datasets_translations_gpt3_5.py\n"," paraphrase_read-and-translate.py\n"," Preprocessing_Datasets_withMetrics.ipynb\n"," README.md\n","/content/paraphrase-categorization\n"]}],"source":["!cp \"/content/drive/MyDrive/Colab Notebooks/Preprocessing_Datasets_withMetrics.ipynb\" /content/paraphrase-categorization/\n","\n","!ls /content/paraphrase-categorization/\n","%cd /content/paraphrase-categorization\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":639,"status":"ok","timestamp":1742887703699,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"},"user_tz":-60},"id":"sZYez0CLBkXX","outputId":"77e6dc59-1f26-4213-8e23-8621f9d8a2b2"},"outputs":[{"output_type":"stream","name":"stdout","text":[" .\n"," ..\n"," .DS_Store\n"," .git\n"," kaggle_prevajajanje_zbirk.html\n"," kategorije_parafraz_draft\n"," library_ontology\n","'Load and translate Paraphrases with GaMS _ Kaggle.html'\n"," paraphrase_categorization\n"," paraphrase_datasets_translation_GaMS_gpu\n"," Paraphrase_Datasets_Translations_GaMS.ipynb\n"," Paraphrase_Datasets_Translations_GPT3.5_GPU.ipynb\n"," Paraphrase_Datasets_Translations_GPT3.5.ipynb\n"," paraphrase_datasets_translations_gpt3_5.py\n"," paraphrase_read-and-translate.py\n"," Preprocessing_Datasets_withMetrics.ipynb\n"," README.md\n","On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes to be committed:\n","  (use \"git restore --staged <file>...\" to unstage)\n","\t\u001b[32mmodified:   Preprocessing_Datasets_withMetrics.ipynb\u001b[m\n","\n"]}],"source":["!ls -a\n","\n","!git add Preprocessing_Datasets_withMetrics.ipynb\n","!git status\n"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"95QXRLcUBkXX","executionInfo":{"status":"ok","timestamp":1742887708013,"user_tz":-60,"elapsed":210,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}}},"outputs":[],"source":["!git config --global user.email \"z.alenka7@gmail.com\"\n","!git config --global user.name \"alikova\"\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":148,"status":"ok","timestamp":1742887710416,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"},"user_tz":-60},"id":"GcR-ZHLjBkXX","outputId":"ea212fba-cb27-44b1-aaa9-6d3be8e608e8"},"outputs":[{"output_type":"stream","name":"stdout","text":["[main 13d7a57] Preprocessing_Datasets_withMetrics.ipynb\n"," 1 file changed, 1 insertion(+), 1 deletion(-)\n"," rewrite Preprocessing_Datasets_withMetrics.ipynb (92%)\n"]}],"source":["!git commit -m \"Preprocessing_Datasets_withMetrics.ipynb\"\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1212,"status":"ok","timestamp":1742887713865,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"},"user_tz":-60},"id":"sj0U_6hoBkXY","outputId":"0e8fd8ee-bfd0-4db8-f411-9a4f4d12b316"},"outputs":[{"output_type":"stream","name":"stdout","text":["Enumerating objects: 5, done.\n","Counting objects:  20% (1/5)\rCounting objects:  40% (2/5)\rCounting objects:  60% (3/5)\rCounting objects:  80% (4/5)\rCounting objects: 100% (5/5)\rCounting objects: 100% (5/5), done.\n","Delta compression using up to 8 threads\n","Compressing objects:  33% (1/3)\rCompressing objects:  66% (2/3)\rCompressing objects: 100% (3/3)\rCompressing objects: 100% (3/3), done.\n","Writing objects:  33% (1/3)\rWriting objects:  66% (2/3)\rWriting objects: 100% (3/3)\rWriting objects: 100% (3/3), 5.54 KiB | 945.00 KiB/s, done.\n","Total 3 (delta 2), reused 0 (delta 0), pack-reused 0\n","remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n","To https://github.com/alikova/paraphrase-categorization.git\n","   b12400d..13d7a57  main -> main\n"]}],"source":["!git push origin main  # or the appropriate branch name if it's not 'main'\n"]},{"cell_type":"markdown","metadata":{"id":"-BPcvwxZBkXY"},"source":["## Installations"]},{"cell_type":"code","source":["!pip install python-Levenshtein"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yvqlphE3uDYT","executionInfo":{"status":"ok","timestamp":1742885427915,"user_tz":-60,"elapsed":4842,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"8249ab3c-7b0b-4301-b98a-a36b3edc27ef"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting python-Levenshtein\n","  Downloading python_levenshtein-0.27.1-py3-none-any.whl.metadata (3.7 kB)\n","Collecting Levenshtein==0.27.1 (from python-Levenshtein)\n","  Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n","Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.27.1->python-Levenshtein)\n","  Downloading rapidfuzz-3.12.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Downloading python_levenshtein-0.27.1-py3-none-any.whl (9.4 kB)\n","Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading rapidfuzz-3.12.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n","Successfully installed Levenshtein-0.27.1 python-Levenshtein-0.27.1 rapidfuzz-3.12.2\n"]}]},{"cell_type":"code","source":["!pip install classla"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cANb_wliyNTy","executionInfo":{"status":"ok","timestamp":1742828319069,"user_tz":-60,"elapsed":86022,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"bf49c23a-3a95-4eec-b772-a2f096bf333d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting classla\n","  Downloading classla-2.2-py3-none-any.whl.metadata (20 kB)\n","Collecting numpy==1.23.0 (from classla)\n","  Downloading numpy-1.23.0.tar.gz (10.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting protobuf==4.21.2 (from classla)\n","  Downloading protobuf-4.21.2-cp37-abi3-manylinux2014_x86_64.whl.metadata (540 bytes)\n","Collecting requests==2.28.0 (from classla)\n","  Downloading requests-2.28.0-py3-none-any.whl.metadata (4.6 kB)\n","INFO: pip is looking at multiple versions of classla to determine which version is compatible with other requirements. This could take a while.\n","Collecting classla\n","  Downloading classla-2.1.1-py3-none-any.whl.metadata (20 kB)\n","  Downloading classla-2.1-py3-none-any.whl.metadata (20 kB)\n","  Downloading classla-2.0-py3-none-any.whl.metadata (19 kB)\n","  Downloading classla-1.2.0-py3-none-any.whl.metadata (18 kB)\n","  Downloading classla-1.1.1-py3-none-any.whl.metadata (19 kB)\n","Collecting numpy==1.22.0 (from classla)\n","  Downloading numpy-1.22.0.zip (11.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting protobuf==3.19.3 (from classla)\n","  Downloading protobuf-3.19.3-py2.py3-none-any.whl.metadata (828 bytes)\n","Collecting requests==2.27.1 (from classla)\n","  Downloading requests-2.27.1-py2.py3-none-any.whl.metadata (5.0 kB)\n","Collecting classla\n","  Downloading classla-1.1.0-py3-none-any.whl.metadata (18 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from classla) (2.0.2)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from classla) (5.29.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from classla) (2.32.3)\n","Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from classla) (2.6.0+cu124)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from classla) (4.67.1)\n","Collecting obeliks>=1.1.3 (from classla)\n","  Downloading obeliks-1.1.6-py3-none-any.whl.metadata (1.6 kB)\n","Collecting reldi-tokeniser (from classla)\n","  Downloading reldi_tokeniser-1.0.3-py3-none-any.whl.metadata (3.9 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from obeliks>=1.1.3->classla) (5.3.1)\n","Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from obeliks>=1.1.3->classla) (2024.11.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->classla) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->classla) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->classla) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->classla) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->classla) (2025.3.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.3.0->classla)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.3.0->classla)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.3.0->classla)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.3.0->classla)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.3.0->classla)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.3.0->classla)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.3.0->classla)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.3.0->classla)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.3.0->classla)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->classla) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->classla) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->classla) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.3.0->classla)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->classla) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->classla) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.3.0->classla) (1.3.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->classla) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->classla) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->classla) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->classla) (2025.1.31)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.3.0->classla) (3.0.2)\n","Downloading classla-1.1.0-py3-none-any.whl (262 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.8/262.8 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading obeliks-1.1.6-py3-none-any.whl (18 kB)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m114.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading reldi_tokeniser-1.0.3-py3-none-any.whl (16 kB)\n","Installing collected packages: reldi-tokeniser, obeliks, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, classla\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed classla-1.1.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 obeliks-1.1.6 reldi-tokeniser-1.0.3\n"]}]},{"cell_type":"code","source":["from lemmagen3 import Lemmatizer\n","lemmatizer = Lemmatizer('sl')\n","text = \"Delnice Tab so se zvišale za 20 centov\"\n","lemmatized = \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n","print(f\"Original: {text}\")\n","print(f\"Lemmatized: {lemmatized}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UCt7dAitSIpb","executionInfo":{"status":"ok","timestamp":1742369145472,"user_tz":-60,"elapsed":10,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"9ee444d5-1e88-4683-e2c0-992e36405add"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Original: Delnice Tab so se zvišale za 20 centov\n","Lemmatized: Delnice Taba biti se zvišati za 20 cent\n"]}]},{"cell_type":"code","source":["# not needed, we use CLASSLA instead\n","!pip uninstall -y lemmagen\n","!pip install lemmagen3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OWZ51UGHSBZ7","executionInfo":{"status":"ok","timestamp":1742369136870,"user_tz":-60,"elapsed":5139,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"5518f0c2-e9fd-49a6-9cfe-4317b2579ae5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: Lemmagen 1.3.2\n","Uninstalling Lemmagen-1.3.2:\n","  Successfully uninstalled Lemmagen-1.3.2\n","Collecting lemmagen3\n","  Downloading lemmagen3-3.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n","Collecting pybind11>=2.4 (from lemmagen3)\n","  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n","Downloading lemmagen3-3.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pybind11, lemmagen3\n","Successfully installed lemmagen3-3.5.1 pybind11-2.13.6\n"]}]},{"cell_type":"code","source":["!pip install laserembeddings\n","!python -m laserembeddings download-models"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bsBFUumh-stz","executionInfo":{"status":"ok","timestamp":1741877448010,"user_tz":-60,"elapsed":85313,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"85682021-4a3c-4588-a7fc-0bf27090e7ca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting laserembeddings\n","  Downloading laserembeddings-1.1.2-py3-none-any.whl.metadata (5.1 kB)\n","Requirement already satisfied: numpy<2.0.0,>=1.15.4 in /usr/local/lib/python3.11/dist-packages (from laserembeddings) (1.26.4)\n","Collecting sacremoses==0.0.35 (from laserembeddings)\n","  Downloading sacremoses-0.0.35.tar.gz (859 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m859.8/859.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting subword-nmt<0.4.0,>=0.3.6 (from laserembeddings)\n","  Downloading subword_nmt-0.3.8-py3-none-any.whl.metadata (9.2 kB)\n","Collecting torch<2.0.0,>=1.0.1.post2 (from laserembeddings)\n","  Downloading torch-1.13.1-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n","Collecting transliterate==1.10.2 (from laserembeddings)\n","  Downloading transliterate-1.10.2-py2.py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from sacremoses==0.0.35->laserembeddings) (1.17.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from sacremoses==0.0.35->laserembeddings) (8.1.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from sacremoses==0.0.35->laserembeddings) (1.4.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sacremoses==0.0.35->laserembeddings) (4.67.1)\n","Collecting mock (from subword-nmt<0.4.0,>=0.3.6->laserembeddings)\n","  Downloading mock-5.2.0-py3-none-any.whl.metadata (3.1 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch<2.0.0,>=1.0.1.post2->laserembeddings) (4.12.2)\n","Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch<2.0.0,>=1.0.1.post2->laserembeddings)\n","  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch<2.0.0,>=1.0.1.post2->laserembeddings)\n","  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu11==11.10.3.66 (from torch<2.0.0,>=1.0.1.post2->laserembeddings)\n","  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch<2.0.0,>=1.0.1.post2->laserembeddings)\n","  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2.0.0,>=1.0.1.post2->laserembeddings) (75.1.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2.0.0,>=1.0.1.post2->laserembeddings) (0.45.1)\n","Downloading laserembeddings-1.1.2-py3-none-any.whl (13 kB)\n","Downloading transliterate-1.10.2-py2.py3-none-any.whl (45 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading subword_nmt-0.3.8-py3-none-any.whl (27 kB)\n","Downloading torch-1.13.1-cp311-cp311-manylinux1_x86_64.whl (887.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.4/887.4 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mock-5.2.0-py3-none-any.whl (31 kB)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.35-py3-none-any.whl size=883961 sha256=242776caefca21ce6be321eaca98038100e74a090e07012d14e1cc9131b8227b\n","  Stored in directory: /root/.cache/pip/wheels/38/dd/61/9feb9767a39c2d6683b4cf2eb4e568d9c0a8228e9120c80e27\n","Successfully built sacremoses\n","Installing collected packages: transliterate, sacremoses, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, mock, subword-nmt, nvidia-cudnn-cu11, torch, laserembeddings\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.5.1+cu124\n","    Uninstalling torch-2.5.1+cu124:\n","      Successfully uninstalled torch-2.5.1+cu124\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.20.1+cu124 requires torch==2.5.1, but you have torch 1.13.1 which is incompatible.\n","torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 1.13.1 which is incompatible.\n","accelerate 1.3.0 requires torch>=2.0.0, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed laserembeddings-1.1.2 mock-5.2.0 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 sacremoses-0.0.35 subword-nmt-0.3.8 torch-1.13.1 transliterate-1.10.2\n","Downloading models into /usr/local/lib/python3.11/dist-packages/laserembeddings/data\n","\n","✅   Downloaded https://dl.fbaipublicfiles.com/laser/models/93langs.fcodes    \n","✅   Downloaded https://dl.fbaipublicfiles.com/laser/models/93langs.fvocab    \n","✅   Downloaded https://dl.fbaipublicfiles.com/laser/models/bilstm.93langs.2018-12-26.pt    \n","\n","✨ You're all set!\n"]}]},{"cell_type":"code","source":["!pip install pyspark torch transformers sentence-transformers spacy nltk\n","!python -m spacy download sl_core_news_sm\n","!python -m spacy download en_core_web_sm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hj0G_rZL2LSM","executionInfo":{"status":"ok","timestamp":1741875281469,"user_tz":-60,"elapsed":85159,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"37c9713a-c680-4fc2-a0cf-4edf5f4e3eb6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n","Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.7.5)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.2.5)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.10.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.1.0)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n","Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m105.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","Collecting sl-core-news-sm==3.7.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/sl_core_news_sm-3.7.0/sl_core_news_sm-3.7.0-py3-none-any.whl (13.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from sl-core-news-sm==3.7.0) (3.7.5)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (1.0.12)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (2.0.11)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (8.2.5)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (2.5.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (0.15.2)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (4.67.1)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (2.32.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (2.10.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (3.1.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (75.1.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (24.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (3.5.0)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (1.26.4)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (1.3.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (2.27.2)\n","Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (2025.1.31)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (0.1.5)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (8.1.8)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (13.9.4)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (0.21.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (7.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (3.0.2)\n","Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (1.2.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (2.18.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (1.17.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (0.1.2)\n","Installing collected packages: sl-core-news-sm\n","Successfully installed sl-core-news-sm-3.7.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('sl_core_news_sm')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n","Collecting en-core-web-sm==3.7.1\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.11/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.12)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.11)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.15.2)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.67.1)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.10.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.27.2)\n","Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2025.1.31)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.8)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.4)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.21.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n","Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.17.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n"]}]},{"cell_type":"code","source":["# First, downgrade torch back to 1.13.1\n","!pip install torch==1.13.1 torchvision==0.14.1 --force-reinstall\n","\n","# Then, downgrade transformers to a compatible version\n","!pip install transformers==4.25.1 --force-reinstall"],"metadata":{"id":"Qu85u0ms-jHA","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1741799308539,"user_tz":-60,"elapsed":17801,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"83cde906-a928-421c-8b7a-e23d175d9c47"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch==1.13.1\n","  Using cached torch-1.13.1-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n","\u001b[31mERROR: Ignored the following yanked versions: 0.1.6, 0.1.7, 0.1.8, 0.1.9, 0.2.0, 0.2.1, 0.2.2, 0.2.2.post2, 0.2.2.post3, 0.15.0\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torchvision==0.14.1 (from versions: 0.15.1, 0.15.2, 0.16.0, 0.16.1, 0.16.2, 0.17.0, 0.17.1, 0.17.2, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 0.20.0, 0.20.1, 0.21.0)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for torchvision==0.14.1\u001b[0m\u001b[31m\n","\u001b[0mCollecting transformers==4.25.1\n","  Downloading transformers-4.25.1-py3-none-any.whl.metadata (93 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting filelock (from transformers==4.25.1)\n","  Using cached filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n","Collecting huggingface-hub<1.0,>=0.10.0 (from transformers==4.25.1)\n","  Downloading huggingface_hub-0.29.3-py3-none-any.whl.metadata (13 kB)\n","Collecting numpy>=1.17 (from transformers==4.25.1)\n","  Using cached numpy-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n","Collecting packaging>=20.0 (from transformers==4.25.1)\n","  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n","Collecting pyyaml>=5.1 (from transformers==4.25.1)\n","  Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n","Collecting regex!=2019.12.17 (from transformers==4.25.1)\n","  Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting requests (from transformers==4.25.1)\n","  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.25.1)\n","  Downloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Collecting tqdm>=4.27 (from transformers==4.25.1)\n","  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.10.0->transformers==4.25.1)\n","  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n","Collecting typing-extensions>=3.7.4.3 (from huggingface-hub<1.0,>=0.10.0->transformers==4.25.1)\n","  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n","Collecting charset-normalizer<4,>=2 (from requests->transformers==4.25.1)\n","  Using cached charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n","Collecting idna<4,>=2.5 (from requests->transformers==4.25.1)\n","  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n","Collecting urllib3<3,>=1.21.1 (from requests->transformers==4.25.1)\n","  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n","Collecting certifi>=2017.4.17 (from requests->transformers==4.25.1)\n","  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n","Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m117.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading huggingface_hub-0.29.3-py3-none-any.whl (468 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hUsing cached numpy-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n","Downloading packaging-24.2-py3-none-any.whl (65 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.0/763.0 kB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.7/792.7 kB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m119.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hUsing cached filelock-3.17.0-py3-none-any.whl (16 kB)\n","Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n","Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n","Using cached charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n","Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hUsing cached idna-3.10-py3-none-any.whl (70 kB)\n","Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n","Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n","Installing collected packages: tokenizers, urllib3, typing-extensions, tqdm, regex, pyyaml, packaging, numpy, idna, fsspec, filelock, charset-normalizer, certifi, requests, huggingface-hub, transformers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.21.0\n","    Uninstalling tokenizers-0.21.0:\n","      Successfully uninstalled tokenizers-0.21.0\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 2.3.0\n","    Uninstalling urllib3-2.3.0:\n","      Successfully uninstalled urllib3-2.3.0\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.12.2\n","    Uninstalling typing_extensions-4.12.2:\n","      Successfully uninstalled typing_extensions-4.12.2\n","  Attempting uninstall: tqdm\n","    Found existing installation: tqdm 4.67.1\n","    Uninstalling tqdm-4.67.1:\n","      Successfully uninstalled tqdm-4.67.1\n","  Attempting uninstall: regex\n","    Found existing installation: regex 2024.11.6\n","    Uninstalling regex-2024.11.6:\n","      Successfully uninstalled regex-2024.11.6\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 6.0.2\n","    Uninstalling PyYAML-6.0.2:\n","      Successfully uninstalled PyYAML-6.0.2\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 24.2\n","    Uninstalling packaging-24.2:\n","      Successfully uninstalled packaging-24.2\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.26.4\n","    Uninstalling numpy-1.26.4:\n","      Successfully uninstalled numpy-1.26.4\n","  Attempting uninstall: idna\n","    Found existing installation: idna 3.10\n","    Uninstalling idna-3.10:\n","      Successfully uninstalled idna-3.10\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.10.0\n","    Uninstalling fsspec-2024.10.0:\n","      Successfully uninstalled fsspec-2024.10.0\n","  Attempting uninstall: filelock\n","    Found existing installation: filelock 3.17.0\n","    Uninstalling filelock-3.17.0:\n","      Successfully uninstalled filelock-3.17.0\n","  Attempting uninstall: charset-normalizer\n","    Found existing installation: charset-normalizer 3.4.1\n","    Uninstalling charset-normalizer-3.4.1:\n","      Successfully uninstalled charset-normalizer-3.4.1\n","  Attempting uninstall: certifi\n","    Found existing installation: certifi 2025.1.31\n","    Uninstalling certifi-2025.1.31:\n","      Successfully uninstalled certifi-2025.1.31\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.32.3\n","    Uninstalling requests-2.32.3:\n","      Successfully uninstalled requests-2.32.3\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface-hub 0.28.1\n","    Uninstalling huggingface-hub-0.28.1:\n","      Successfully uninstalled huggingface-hub-0.28.1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.48.3\n","    Uninstalling transformers-4.48.3:\n","      Successfully uninstalled transformers-4.48.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","laserembeddings 1.1.2 requires numpy<2.0.0,>=1.15.4, but you have numpy 2.2.3 which is incompatible.\n","laserembeddings 1.1.2 requires torch<2.0.0,>=1.0.1.post2, but you have torch 2.0.0 which is incompatible.\n","numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.3 which is incompatible.\n","sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.25.1 which is incompatible.\n","gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2025.3.0 which is incompatible.\n","torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.0.0 which is incompatible.\n","tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.3 which is incompatible.\n","pytensor 2.27.1 requires numpy<2,>=1.17.0, but you have numpy 2.2.3 which is incompatible.\n","thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed certifi-2025.1.31 charset-normalizer-3.4.1 filelock-3.17.0 fsspec-2025.3.0 huggingface-hub-0.29.3 idna-3.10 numpy-2.2.3 packaging-24.2 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 tokenizers-0.13.3 tqdm-4.67.1 transformers-4.25.1 typing-extensions-4.12.2 urllib3-2.3.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["certifi"]},"id":"451e4da67cca4208acd91be4ea34d1a9"}},"metadata":{}}]},{"cell_type":"code","source":["# After downgrading PyTorch to 1.13.1\n","!pip install laserembeddings --force-reinstall"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"t4wm7RQcVbSI","executionInfo":{"status":"ok","timestamp":1741799464437,"user_tz":-60,"elapsed":56704,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"2290facb-8862-41b7-cbac-5c2374bdd2d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting laserembeddings\n","  Using cached laserembeddings-1.1.2-py3-none-any.whl.metadata (5.1 kB)\n","Collecting numpy<2.0.0,>=1.15.4 (from laserembeddings)\n","  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","Collecting sacremoses==0.0.35 (from laserembeddings)\n","  Using cached sacremoses-0.0.35-py3-none-any.whl\n","Collecting subword-nmt<0.4.0,>=0.3.6 (from laserembeddings)\n","  Using cached subword_nmt-0.3.8-py3-none-any.whl.metadata (9.2 kB)\n","Collecting torch<2.0.0,>=1.0.1.post2 (from laserembeddings)\n","  Using cached torch-1.13.1-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n","Collecting transliterate==1.10.2 (from laserembeddings)\n","  Using cached transliterate-1.10.2-py2.py3-none-any.whl.metadata (14 kB)\n","Collecting six (from sacremoses==0.0.35->laserembeddings)\n","  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n","Collecting click (from sacremoses==0.0.35->laserembeddings)\n","  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n","Collecting joblib (from sacremoses==0.0.35->laserembeddings)\n","  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n","Collecting tqdm (from sacremoses==0.0.35->laserembeddings)\n","  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n","Collecting mock (from subword-nmt<0.4.0,>=0.3.6->laserembeddings)\n","  Using cached mock-5.2.0-py3-none-any.whl.metadata (3.1 kB)\n","Collecting typing-extensions (from torch<2.0.0,>=1.0.1.post2->laserembeddings)\n","  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n","Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch<2.0.0,>=1.0.1.post2->laserembeddings)\n","  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch<2.0.0,>=1.0.1.post2->laserembeddings)\n","  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu11==11.10.3.66 (from torch<2.0.0,>=1.0.1.post2->laserembeddings)\n","  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch<2.0.0,>=1.0.1.post2->laserembeddings)\n","  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting setuptools (from nvidia-cublas-cu11==11.10.3.66->torch<2.0.0,>=1.0.1.post2->laserembeddings)\n","  Using cached setuptools-76.0.0-py3-none-any.whl.metadata (6.7 kB)\n","Collecting wheel (from nvidia-cublas-cu11==11.10.3.66->torch<2.0.0,>=1.0.1.post2->laserembeddings)\n","  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n","Using cached laserembeddings-1.1.2-py3-none-any.whl (13 kB)\n","Using cached transliterate-1.10.2-py2.py3-none-any.whl (45 kB)\n","Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n","Using cached subword_nmt-0.3.8-py3-none-any.whl (27 kB)\n","Using cached torch-1.13.1-cp311-cp311-manylinux1_x86_64.whl (887.4 MB)\n","Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n","Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n","Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n","Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n","Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n","Downloading click-8.1.8-py3-none-any.whl (98 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hUsing cached mock-5.2.0-py3-none-any.whl (31 kB)\n","Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n","Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n","Using cached setuptools-76.0.0-py3-none-any.whl (1.2 MB)\n","Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n","Installing collected packages: wheel, typing-extensions, tqdm, six, setuptools, nvidia-cuda-nvrtc-cu11, numpy, mock, joblib, click, transliterate, subword-nmt, sacremoses, nvidia-cuda-runtime-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch, laserembeddings\n","  Attempting uninstall: wheel\n","    Found existing installation: wheel 0.45.1\n","    Uninstalling wheel-0.45.1:\n","      Successfully uninstalled wheel-0.45.1\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.12.2\n","    Uninstalling typing_extensions-4.12.2:\n","      Successfully uninstalled typing_extensions-4.12.2\n","  Attempting uninstall: tqdm\n","    Found existing installation: tqdm 4.67.1\n","    Uninstalling tqdm-4.67.1:\n","      Successfully uninstalled tqdm-4.67.1\n","  Attempting uninstall: six\n","    Found existing installation: six 1.17.0\n","    Uninstalling six-1.17.0:\n","      Successfully uninstalled six-1.17.0\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 76.0.0\n","    Uninstalling setuptools-76.0.0:\n","      Successfully uninstalled setuptools-76.0.0\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu11\n","    Found existing installation: nvidia-cuda-nvrtc-cu11 11.7.99\n","    Uninstalling nvidia-cuda-nvrtc-cu11-11.7.99:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu11-11.7.99\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.26.4\n","    Uninstalling numpy-1.26.4:\n","      Successfully uninstalled numpy-1.26.4\n","  Attempting uninstall: mock\n","    Found existing installation: mock 5.2.0\n","    Uninstalling mock-5.2.0:\n","      Successfully uninstalled mock-5.2.0\n","  Attempting uninstall: joblib\n","    Found existing installation: joblib 1.4.2\n","    Uninstalling joblib-1.4.2:\n","      Successfully uninstalled joblib-1.4.2\n","  Attempting uninstall: click\n","    Found existing installation: click 8.1.8\n","    Uninstalling click-8.1.8:\n","      Successfully uninstalled click-8.1.8\n","  Attempting uninstall: transliterate\n","    Found existing installation: transliterate 1.10.2\n","    Uninstalling transliterate-1.10.2:\n","      Successfully uninstalled transliterate-1.10.2\n","  Attempting uninstall: subword-nmt\n","    Found existing installation: subword-nmt 0.3.8\n","    Uninstalling subword-nmt-0.3.8:\n","      Successfully uninstalled subword-nmt-0.3.8\n","  Attempting uninstall: sacremoses\n","    Found existing installation: sacremoses 0.0.35\n","    Uninstalling sacremoses-0.0.35:\n","      Successfully uninstalled sacremoses-0.0.35\n","  Attempting uninstall: nvidia-cuda-runtime-cu11\n","    Found existing installation: nvidia-cuda-runtime-cu11 11.7.99\n","    Uninstalling nvidia-cuda-runtime-cu11-11.7.99:\n","      Successfully uninstalled nvidia-cuda-runtime-cu11-11.7.99\n","  Attempting uninstall: nvidia-cublas-cu11\n","    Found existing installation: nvidia-cublas-cu11 11.10.3.66\n","    Uninstalling nvidia-cublas-cu11-11.10.3.66:\n","      Successfully uninstalled nvidia-cublas-cu11-11.10.3.66\n","  Attempting uninstall: nvidia-cudnn-cu11\n","    Found existing installation: nvidia-cudnn-cu11 8.5.0.96\n","    Uninstalling nvidia-cudnn-cu11-8.5.0.96:\n","      Successfully uninstalled nvidia-cudnn-cu11-8.5.0.96\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.0.0\n","    Uninstalling torch-2.0.0:\n","      Successfully uninstalled torch-2.0.0\n","  Attempting uninstall: laserembeddings\n","    Found existing installation: laserembeddings 1.1.2\n","    Uninstalling laserembeddings-1.1.2:\n","      Successfully uninstalled laserembeddings-1.1.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.34.0 requires jedi>=0.16, which is not installed.\n","torchvision 0.15.1 requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.\n","accelerate 1.3.0 requires torch>=2.0.0, but you have torch 1.13.1 which is incompatible.\n","sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.25.1 which is incompatible.\n","torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed click-8.1.8 joblib-1.4.2 laserembeddings-1.1.2 mock-5.2.0 numpy-1.26.4 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 sacremoses-0.0.35 setuptools-76.0.0 six-1.17.0 subword-nmt-0.3.8 torch-1.13.1 tqdm-4.67.1 transliterate-1.10.2 typing-extensions-4.12.2 wheel-0.45.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["_distutils_hack","six"]},"id":"eb40d5a8b6634e0f9e3f925bdc1973c2"}},"metadata":{}}]},{"cell_type":"code","source":["!python -m laserembeddings download-models"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fYZoE7CaXToD","executionInfo":{"status":"ok","timestamp":1741799920907,"user_tz":-60,"elapsed":13332,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"322fa2a9-8781-4855-9e00-c3994ed8266c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading models into /usr/local/lib/python3.11/dist-packages/laserembeddings/data\n","\n","✅   Downloaded https://dl.fbaipublicfiles.com/laser/models/93langs.fcodes    \n","✅   Downloaded https://dl.fbaipublicfiles.com/laser/models/93langs.fvocab    \n","✅   Downloaded https://dl.fbaipublicfiles.com/laser/models/bilstm.93langs.2018-12-26.pt    \n","\n","✨ You're all set!\n"]}]},{"cell_type":"code","source":["!pip install spacy\n","!python -m spacy download sl_core_news_sm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PTJ97AmqTjU9","executionInfo":{"status":"ok","timestamp":1741799366816,"user_tz":-60,"elapsed":15282,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"65a77e23-cf09-4d39-ffc5-d8a0c2dcc2db"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.7.5)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.2.5)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.10.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (76.0.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.2.3)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n","Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n","Collecting numpy>=1.19.0 (from spacy)\n","  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n","Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n","Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n","Installing collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.2.3\n","    Uninstalling numpy-2.2.3:\n","      Successfully uninstalled numpy-2.2.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","laserembeddings 1.1.2 requires torch<2.0.0,>=1.0.1.post2, but you have torch 2.0.0 which is incompatible.\n","sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.25.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-1.26.4\n","Collecting sl-core-news-sm==3.7.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/sl_core_news_sm-3.7.0/sl_core_news_sm-3.7.0-py3-none-any.whl (13.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from sl-core-news-sm==3.7.0) (3.7.5)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (1.0.12)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (2.0.11)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (8.2.5)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (2.5.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (0.15.2)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (4.67.1)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (2.32.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (2.10.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (3.1.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (76.0.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (24.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (3.5.0)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (1.26.4)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (1.3.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (2.27.2)\n","Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (2025.1.31)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (0.1.5)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (8.1.8)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (13.9.4)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (0.21.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (7.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (3.0.2)\n","Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (1.2.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (2.18.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (1.17.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->sl-core-news-sm==3.7.0) (0.1.2)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('sl_core_news_sm')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n"]}]},{"cell_type":"markdown","source":["### Test try on the PAWS dataset: METEOR - Lemmatization and tokenization functions"],"metadata":{"id":"WGlYsC5--jrt"}},{"cell_type":"code","source":["# First, let's verify the Excel file can be read at all\n","import pandas as pd\n","import os\n","\n","file_path = '/content/drive/MyDrive/Colab Notebooks/paws_nepodvojene_filtrirane_parafraze.xlsx'\n","\n","# Check if file exists and its size\n","if os.path.exists(file_path):\n","    print(f\"File exists, size: {os.path.getsize(file_path) / (1024*1024):.2f} MB\")\n","else:\n","    print(f\"File does not exist at path: {file_path}\")\n","    exit()\n","\n","# Try simple direct reading first\n","try:\n","    df = pd.read_excel(file_path)\n","    print(f\"Successfully read file directly. Shape: {df.shape}\")\n","    print(\"First few rows:\")\n","    print(df.head())\n","    print(\"Column names:\", df.columns.tolist())\n","except Exception as e:\n","    print(f\"Error reading file directly: {e}\")\n","\n","# Look at the problematic function\n","xl = pd.ExcelFile(file_path)\n","sheet_name = xl.sheet_names[0]\n","print(f\"Sheet name: {sheet_name}\")\n","\n","# This line is causing the issue - let's check what it returns\n","total_rows = pd.read_excel(xl, sheet_name=sheet_name, nrows=0).shape[0]\n","print(f\"Method returning total_rows: {total_rows}\")\n","\n","# Try a better way to get row count\n","df_sample = pd.read_excel(file_path, sheet_name=sheet_name)\n","print(f\"Actual row count: {len(df_sample)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bPMkKcT1TbBJ","executionInfo":{"status":"ok","timestamp":1741178129441,"user_tz":-60,"elapsed":3527,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"ce106735-6548-45fc-b1ee-55720f66e0b2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["File exists, size: 2.07 MB\n","Successfully read file directly. Shape: (29493, 3)\n","First few rows:\n","   ustreznost                                           original  \\\n","0         0.0  Vsebina prve nepoškodovane zbirke, vključno z ...   \n","1         NaN  \"Encrinus\" je bil opisan leta 1764 in je bil l...   \n","2         NaN  Billboard je o pesmi napisal: \"Poznaš ritem, z...   \n","3         NaN  Glasbo je sestavil Darsan Raman, besedilo pa n...   \n","4         1.0  Alfred Gregson (2. marec 1889 - marec 1968) je...   \n","\n","                                           parafraza  \n","0  Vsebina zadnje zbirke, vključno z prvim nepošk...  \n","1  Bil je opisan leta 1764 in mu je Jack Sepkoski...  \n","2  O pesmi je Billboard napisal: \"Ujameš ritem, z...  \n","3  Glasbo je napisala Mariamma Philip, besedilo p...  \n","4  Alfred Gregson (2. marec 1889 - marec 1968) je...  \n","Column names: ['ustreznost', 'original', 'parafraza']\n","Sheet name: Sheet1\n","Method returning total_rows: 0\n","Actual row count: 29493\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import spacy\n","import torch\n","import gc\n","import numpy as np\n","from tqdm.notebook import tqdm\n","from concurrent.futures import ThreadPoolExecutor\n","import nltk\n","from nltk.translate.meteor_score import meteor_score\n","from google.colab import drive\n","import os\n","\n","# Download NLTK data for METEOR\n","nltk.download('wordnet')\n","nltk.download('omw')  # Open Multilingual Wordnet\n","\n","# Load Slovene SpaCy model\n","# You might need to install it first: !python -m spacy download sl_core_news_lg\n","try:\n","    nlp = spacy.load(\"sl_core_news_lg\")\n","    print(\"Loaded Slovene language model\")\n","except:\n","    print(\"Installing Slovene language model...\")\n","    !python -m spacy download sl_core_news_lg\n","    nlp = spacy.load(\"sl_core_news_lg\")\n","    print(\"Loaded Slovene language model\")\n","\n","# Enable GPU for SpaCy if available\n","if torch.cuda.is_available():\n","    spacy.prefer_gpu()\n","    print(\"SpaCy is using GPU\")\n","\n","# Function to process a batch of rows\n","def process_batch(batch_df):\n","    # Get the exact column names from your dataframe structure\n","    columns = batch_df.columns.tolist()\n","\n","    # Find the appropriate columns (regardless of exact naming)\n","    original_col = [col for col in columns if 'original' in col.lower()][0]\n","    paraphrase_col = [col for col in columns if 'parafraza' in col.lower()][0]\n","\n","    print(f\"Using columns: '{original_col}' and '{paraphrase_col}'\")\n","\n","    # Handle any NaN values in the text columns\n","    sent1_series = batch_df[original_col].fillna('').astype(str)\n","    sent2_series = batch_df[paraphrase_col].fillna('').astype(str)\n","\n","    # Tokenize sentences and paraphrases\n","    sent1_docs = list(nlp.pipe(sent1_series.values, batch_size=32))\n","    sent2_docs = list(nlp.pipe(sent2_series.values, batch_size=32))\n","\n","    results = []\n","    for i, (doc1, doc2) in enumerate(zip(sent1_docs, sent2_docs)):\n","        # Get raw tokens\n","        tokens1 = [token.text for token in doc1]\n","        tokens2 = [token.text for token in doc2]\n","\n","        # Get lemmatized tokens\n","        lemmas1 = [token.lemma_ for token in doc1]\n","        lemmas2 = [token.lemma_ for token in doc2]\n","\n","        # Calculate METEOR score on raw tokens\n","        try:\n","            meteor = meteor_score([tokens1], tokens2)\n","        except Exception as e:\n","            print(f\"Error calculating METEOR: {e}\")\n","            meteor = np.nan\n","\n","        # Calculate METEOR score on lemmatized tokens\n","        try:\n","            meteor_lemma = meteor_score([lemmas1], lemmas2)\n","        except Exception as e:\n","            print(f\"Error calculating lemma METEOR: {e}\")\n","            meteor_lemma = np.nan\n","\n","        results.append({\n","            'tokens_sent1': tokens1,\n","            'tokens_sent2': tokens2,\n","            'lemmas_sent1': lemmas1,\n","            'lemmas_sent2': lemmas2,\n","            'token_count_sent1': len(tokens1),\n","            'token_count_sent2': len(tokens2),\n","            'meteor_score': meteor,\n","            'meteor_score_lemma': meteor_lemma\n","        })\n","\n","    return pd.DataFrame(results)\n","\n","# Main function to process the file\n","# Main function to process the file\n","def process_excel_file(file_path, batch_size=1000):\n","    print(f\"Processing file: {file_path}\")\n","\n","    try:\n","        # Read the file directly\n","        df = pd.read_excel(file_path)\n","        print(f\"Data loaded: {df.shape}\")\n","\n","        # Check column names and ensure they exist\n","        columns = df.columns.tolist()\n","        print(f\"Original columns: {columns}\")\n","\n","        # Find the original and paraphrase columns\n","        original_cols = [col for col in columns if 'original' in col.lower()]\n","        paraphrase_cols = [col for col in columns if 'parafraza' in col.lower()]\n","\n","        if not original_cols or not paraphrase_cols:\n","            raise ValueError(f\"Could not find original/paraphrase columns. Available columns: {columns}\")\n","\n","        # Process in batches with ThreadPoolExecutor\n","        results = []\n","        total_batches = (len(df) + batch_size - 1) // batch_size\n","\n","        with ThreadPoolExecutor(max_workers=4) as executor:\n","            futures = []\n","            for i in range(0, len(df), batch_size):\n","                batch_df = df.iloc[i:i+batch_size]\n","                futures.append(executor.submit(process_batch, batch_df))\n","\n","            # Collect results as they complete\n","            for i, future in enumerate(tqdm(futures, desc=\"Processing batches\")):\n","                batch_result = future.result()\n","                results.append(batch_result)\n","\n","                # Clear CUDA cache periodically\n","                if torch.cuda.is_available() and i % 10 == 0:\n","                    torch.cuda.empty_cache()\n","                    gc.collect()\n","\n","        # Combine results\n","        if not results:\n","            raise ValueError(\"No results were generated during processing\")\n","\n","        results_df = pd.concat(results, ignore_index=True)\n","\n","        # Add original data to results\n","        final_df = pd.concat([df, results_df], axis=1)\n","\n","        return final_df\n","\n","    except Exception as e:\n","        print(f\"Error in process_excel_file: {e}\")\n","        import traceback\n","        traceback.print_exc()\n","        raise"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F08j2p1P-kJd","executionInfo":{"status":"ok","timestamp":1741179938342,"user_tz":-60,"elapsed":951,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"2fe29415-85d8-4977-dd13-91865ff546e1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw to /root/nltk_data...\n","[nltk_data]   Package omw is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Loaded Slovene language model\n","SpaCy is using GPU\n"]}]},{"cell_type":"code","source":["# Example usage\n","if __name__ == \"__main__\":\n","    # Define the path to your Excel file in Google Drive\n","    file_path = '/content/drive/MyDrive/Colab Notebooks/paws_nepodvojene_filtrirane_parafraze.xlsx'\n","\n","    # Process the file\n","    result_df = process_excel_file(file_path, batch_size=1000)\n","\n","    # Save results to Google Drive\n","    output_path = '/content/drive/MyDrive/Colab Notebooks/paws_results_with_meteor.xlsx'\n","    result_df.to_excel(output_path, index=False)\n","    print(f\"Results saved to {output_path}\")\n","\n","    # Generate basic statistics\n","    print(\"\\nStatistics:\")\n","    print(f\"Average METEOR score: {result_df['meteor_score'].mean():.4f}\")\n","    print(f\"Min METEOR score: {result_df['meteor_score'].min():.4f}\")\n","    print(f\"Max METEOR score: {result_df['meteor_score'].max():.4f}\")\n","\n","    # Visualize distribution of METEOR scores\n","    try:\n","        import matplotlib.pyplot as plt\n","        plt.figure(figsize=(10, 6))\n","        plt.hist(result_df['meteor_score'].dropna(), bins=20)\n","        plt.title('Distribution of METEOR Scores')\n","        plt.xlabel('METEOR Score')\n","        plt.ylabel('Frequency')\n","        plt.savefig('/content/drive/MyDrive/Colab Notebooks/paws_meteor_distribution.png')\n","        print(\"Visualization saved to Google Drive\")\n","    except Exception as e:\n","        print(f\"Error creating visualization: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["d5ea5c60ffb146ee92a8f7f797e98d84","88925edbe6d64d338c70837a04033dd7","d06d823ef62b4c0eb50e9580b7bb7f16","538e93d0af774b45a2084de734c592df","5f584a40ff9f40299d635aaa8e830710","7a4bc236de604c8b8e506c086b53a6cf","27a06956a84c4a9bb1233751ec4e09af","042d3bbbec634a1b92f473c63d5f78fe","258cbce6fecb45db852489edd9ba7cae","f9d274a1776e4b248df32b6273673c06","2b33a83cd24a4b3688062bd27cb05771"]},"id":"2dKgK0lBQ7lJ","executionInfo":{"status":"ok","timestamp":1741180194821,"user_tz":-60,"elapsed":252649,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"26341442-3835-4ce9-830d-6d5a9a61a204"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing file: /content/drive/MyDrive/Colab Notebooks/paws_nepodvojene_filtrirane_parafraze.xlsx\n","Data loaded: (29493, 3)\n","Original columns: ['ustreznost', 'original', 'parafraza']\n","Using columns: 'original' and 'parafraza'\n","Using columns: 'original' and 'parafraza'\n","Using columns: 'original' and 'parafraza'\n","Using columns: 'original' and 'parafraza'\n"]},{"output_type":"display_data","data":{"text/plain":["Processing batches:   0%|          | 0/30 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5ea5c60ffb146ee92a8f7f797e98d84"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Using columns: 'original' and 'parafraza'\n","Using columns: 'original' and 'parafraza'\n","Using columns: 'original' and 'parafraza'\n","Using columns: 'original' and 'parafraza'\n","Using columns: 'original' and 'parafraza'\n","Using columns: 'original' and 'parafraza'\n","Using columns: 'original' and 'parafraza'\n","Using columns: 'original' and 'parafraza'\n","Using columns: 'original' and 'parafraza'\n","Using columns: 'original' and 'parafraza'\n","Using columns: 'original' and 'parafraza'\n","Using columns: 'original' and 'parafraza'\n","Using columns: 'original' and 'parafraza'\n","Using columns: 'original' and 'parafraza'\n","Using columns: 'original' and 'parafraza'\n","Using columns: 'original' and 'parafraza'\n","Using columns: 'original' and 'parafraza'\n","Using columns: 'original' and 'parafraza'\n","Using columns: 'original' and 'parafraza'\n","Using columns: 'original' and 'parafraza'\n","Using columns: 'original' and 'parafraza'\n","Using columns: 'original' and 'parafraza'\n","Using columns: 'original' and 'parafraza'\n","Using columns: 'original' and 'parafraza'\n","Using columns: 'original' and 'parafraza'\n","Using columns: 'original' and 'parafraza'\n","Results saved to /content/drive/MyDrive/Colab Notebooks/paws_results_with_meteor.xlsx\n","\n","Statistics:\n","Average METEOR score: 0.7962\n","Min METEOR score: 0.0000\n","Max METEOR score: 1.0000\n","Visualization saved to Google Drive\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x600 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["#### Evaluating metric on the clean files"],"metadata":{"id":"ex6jQ6-9K5lh"}},{"cell_type":"code","source":[],"metadata":{"id":"fuRTal_bLBIH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Paraphrase evaluation pipeline - first try"],"metadata":{"id":"rqxIWhx9KjHf"}},{"cell_type":"markdown","source":["#### Input → Preprocessing → Embedding Metrics → Linguistic Metrics → Ensemble Scoring → Visualization/Analysis"],"metadata":{"id":"aFfJZr6ggP9T"}},{"cell_type":"markdown","source":["#### Preprocessing with cleaning the metadata of the sentence (only needed for MSR dataset)"],"metadata":{"id":"F4zPCMFybEjr"}},{"cell_type":"code","source":["import pandas as pd\n","import re\n","\n","# Define the base directory and input file\n","base_dir = \"/content/drive/MyDrive/Colab Notebooks/preprocessed_datasets\"\n","dataset = \"predprocesiranje_msr_paired\"\n","input_file = f\"{base_dir}/{dataset}.xlsx\"\n","output_file = f\"{base_dir}/{dataset}_cleaned.xlsx\"\n","\n","# Load the Excel file\n","df = pd.read_excel(input_file)\n","\n","# Function to clean metadata from a cell\n","def clean_metadata(cell):\n","    if isinstance(cell, str):\n","        # Remove everything after the first occurrence of '. ' or '.\" '\n","        cleaned_cell = re.sub(r'\\. +.*|\\. *\\t.*|\\.\\\" +.*', '.', cell)  # Keep the period and remove everything after\n","        return cleaned_cell.strip()  # Remove any leading/trailing whitespace\n","    return cell\n","\n","# Apply the cleaning function to each cell in the DataFrame\n","df_cleaned = df.applymap(clean_metadata)\n","\n","# Save the cleaned DataFrame to a new Excel file\n","df_cleaned.to_excel(output_file, index=False)\n","\n","print(f\"Cleaned data saved to {output_file}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LQ7RjARvbJNm","executionInfo":{"status":"ok","timestamp":1742211686266,"user_tz":-60,"elapsed":1486,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"4bbb3b3c-5d57-47f6-f089-193d2ad70540"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-50-c59483a51c40>:22: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n","  df_cleaned = df.applymap(clean_metadata)\n"]},{"output_type":"stream","name":"stdout","text":["Cleaned data saved to /content/drive/MyDrive/Colab Notebooks/preprocessed_datasets/predprocesiranje_msr_paired_cleaned.xlsx\n"]}]},{"cell_type":"markdown","source":["#### Apache Spark Pipeline - try"],"metadata":{"id":"XQaBTuD2gYuV"}},{"cell_type":"code","source":["\"\"\"\n","Apache Spark Integration for Paraphrase Analysis Pipeline\n","This module enhances the existing pipeline with distributed processing capabilities.\n","\"\"\"\n","\n","import os\n","import time\n","import pandas as pd\n","import numpy as np\n","from pyspark.sql import SparkSession\n","from pyspark.sql.types import *\n","from pyspark.sql.functions import col, udf, pandas_udf, lit\n","from pyspark import SparkFiles\n","import torch\n","from typing import Iterator, Tuple, List\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","\n","# Visualization functions included directly in the main module\n","def visualize_results(df, output_dir='.'):\n","    \"\"\"\n","    Create visualizations for the paraphrase analysis results.\n","\n","    Args:\n","        df: Pandas DataFrame with paraphrase analysis results\n","        output_dir: Directory to save the visualizations\n","    \"\"\"\n","    # Create directory if it doesn't exist\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    # Create figure with subplots\n","    metrics_to_plot = []\n","\n","    # Check which metrics are available\n","    for metric in ['labse_similarity', 'laser_similarity', 'meteor_score',\n","                   'length_ratio', 'jaccard_similarity', 'ensemble_score']:\n","        if metric in df.columns:\n","            metrics_to_plot.append(metric)\n","\n","    if not metrics_to_plot:\n","        print(\"No metrics available for visualization\")\n","        return\n","\n","    # Calculate subplot grid dimensions\n","    n_metrics = len(metrics_to_plot)\n","    n_cols = min(3, n_metrics)\n","    n_rows = (n_metrics + n_cols - 1) // n_cols\n","\n","    # Create figure\n","    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 4*n_rows))\n","\n","    # Handle case with single subplot\n","    if n_metrics == 1:\n","        axes = np.array([axes])\n","\n","    # Flatten axes array for easy iteration\n","    if n_metrics > 1:\n","        axes = axes.flatten()\n","\n","    # Create histograms\n","    for i, metric in enumerate(metrics_to_plot):\n","        sns.histplot(df[metric], kde=True, ax=axes[i])\n","        axes[i].set_title(f'Distribution of {metric}')\n","        axes[i].axvline(df[metric].mean(), color='r', linestyle='--')\n","\n","    # Hide unused subplots\n","    for i in range(n_metrics, len(axes)):\n","        axes[i].set_visible(False)\n","\n","    plt.tight_layout()\n","    plt.savefig(os.path.join(output_dir, 'metric_distributions.png'))\n","    plt.close()\n","\n","    # Correlation matrix (if multiple metrics available)\n","    if len(metrics_to_plot) > 1:\n","        plt.figure(figsize=(10, 8))\n","        correlation = df[metrics_to_plot].corr()\n","        sns.heatmap(correlation, annot=True, cmap='coolwarm')\n","        plt.title('Correlation Matrix of Metrics')\n","        plt.tight_layout()\n","        plt.savefig(os.path.join(output_dir, 'correlation_matrix.png'))\n","        plt.close()\n","\n","    # Create a scatter plot of two main metrics (if available)\n","    main_metrics = []\n","    for metric in ['labse_similarity', 'laser_similarity']:\n","        if metric in metrics_to_plot:\n","            main_metrics.append(metric)\n","\n","    if len(main_metrics) >= 2:\n","        plt.figure(figsize=(10, 8))\n","        scatter = plt.scatter(\n","            df[main_metrics[0]],\n","            df[main_metrics[1]],\n","            c=df['ensemble_score'] if 'ensemble_score' in df.columns else None,\n","            cmap='viridis',\n","            alpha=0.7\n","        )\n","        plt.colorbar(scatter, label='Ensemble Score')\n","        plt.xlabel(main_metrics[0])\n","        plt.ylabel(main_metrics[1])\n","        plt.title(f'Scatter Plot of {main_metrics[0]} vs {main_metrics[1]}')\n","        plt.tight_layout()\n","        plt.savefig(os.path.join(output_dir, 'metrics_scatter.png'))\n","        plt.close()\n","\n","    print(f\"Basic visualizations saved to {output_dir}\")\n","\n","\n","def visualize_grammatical_metrics(df, output_dir='.'):\n","    \"\"\"\n","    Create visualizations specifically for grammatical metrics.\n","\n","    Args:\n","        df: Pandas DataFrame with grammatical metrics\n","        output_dir: Directory to save the visualizations\n","    \"\"\"\n","    # Create directory if it doesn't exist\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    # 1. METEOR before and after lemmatization comparison\n","    if 'raw_meteor_score' in df.columns and 'lemma_meteor_score' in df.columns:\n","        plt.figure(figsize=(10, 8))\n","        plt.scatter(df['raw_meteor_score'], df['lemma_meteor_score'], alpha=0.5)\n","        plt.plot([0, 1], [0, 1], 'r--')  # Diagonal line\n","        plt.xlabel('Raw METEOR Score')\n","        plt.ylabel('Lemmatized METEOR Score')\n","        plt.title('METEOR Scores Before and After Lemmatization')\n","        plt.grid(True, alpha=0.3)\n","        plt.savefig(os.path.join(output_dir, 'meteor_comparison.png'))\n","        plt.close()\n","\n","        # Histogram of METEOR differences\n","        if 'meteor_difference' in df.columns:\n","            plt.figure(figsize=(10, 6))\n","            sns.histplot(df['meteor_difference'], kde=True)\n","            plt.axvline(x=0, color='r', linestyle='--')\n","            plt.xlabel('METEOR Difference (Lemmatized - Raw)')\n","            plt.ylabel('Count')\n","            plt.title('Distribution of METEOR Differences')\n","            plt.grid(True, alpha=0.3)\n","            plt.savefig(os.path.join(output_dir, 'meteor_difference.png'))\n","            plt.close()\n","\n","    # 2. Morphological similarity distribution\n","    if 'morph_similarity' in df.columns:\n","        plt.figure(figsize=(10, 6))\n","        sns.histplot(df['morph_similarity'], kde=True, bins=20)\n","        plt.xlabel('Morphological Similarity')\n","        plt.ylabel('Count')\n","        plt.title('Distribution of Morphological Similarity')\n","        plt.grid(True, alpha=0.3)\n","        plt.savefig(os.path.join(output_dir, 'morph_similarity.png'))\n","        plt.close()\n","\n","    # 3. Grammar mismatch analysis\n","    if 'grammar_mismatch' in df.columns and 'morph_grammar_mismatch' in df.columns:\n","        # Count of grammar mismatch types\n","        mismatch_counts = {\n","            'Both': sum(df['grammar_mismatch'] & df['morph_grammar_mismatch']),\n","            'METEOR Only': sum(df['grammar_mismatch'] & ~df['morph_grammar_mismatch']),\n","            'Morphology Only': sum(~df['grammar_mismatch'] & df['morph_grammar_mismatch']),\n","            'No Mismatch': sum(~df['grammar_mismatch'] & ~df['morph_grammar_mismatch'])\n","        }\n","\n","        plt.figure(figsize=(10, 6))\n","        plt.bar(mismatch_counts.keys(), mismatch_counts.values())\n","        plt.xlabel('Grammar Mismatch Type')\n","        plt.ylabel('Count')\n","        plt.title('Types of Grammar Mismatches Detected')\n","        plt.savefig(os.path.join(output_dir, 'grammar_mismatch_types.png'))\n","        plt.close()\n","\n","    # 4. Near-duplicates vs. Grammar mismatches\n","    if 'is_near_duplicate' in df.columns and 'potential_grammar_error' in df.columns:\n","        # Count combinations\n","        categories = {\n","            'Near Duplicate & Grammar Error': sum(df['is_near_duplicate'] & df['potential_grammar_error']),\n","            'Near Duplicate Only': sum(df['is_near_duplicate'] & ~df['potential_grammar_error']),\n","            'Grammar Error Only': sum(~df['is_near_duplicate'] & df['potential_grammar_error']),\n","            'Neither': sum(~df['is_near_duplicate'] & ~df['potential_grammar_error'])\n","        }\n","\n","        plt.figure(figsize=(10, 6))\n","        plt.bar(categories.keys(), categories.values())\n","        plt.xlabel('Category')\n","        plt.ylabel('Count')\n","        plt.title('Near Duplicates vs. Grammar Errors')\n","        plt.xticks(rotation=45, ha='right')\n","        plt.tight_layout()\n","        plt.savefig(os.path.join(output_dir, 'duplicate_vs_grammar.png'))\n","        plt.close()\n","\n","    print(f\"Grammar-specific visualizations saved to {output_dir}\")\n","\n","\n","def initialize_spark(app_name=\"ParaphraseAnalysis\", master=None):\n","    \"\"\"Initialize a Spark session with appropriate configuration for NLP tasks.\"\"\"\n","    # If no master is specified, it will use the default (local or cluster if configured)\n","    builder = SparkSession.builder.appName(app_name)\n","\n","    if master:\n","        builder = builder.master(master)\n","\n","    # Add necessary configuration for handling NLP models and data\n","    spark = (builder\n","        .config(\"spark.driver.memory\", \"16g\")  # Adjust based on your environment\n","        .config(\"spark.executor.memory\", \"16g\")\n","        .config(\"spark.driver.maxResultSize\", \"8g\")\n","        .config(\"spark.python.worker.memory\", \"8g\")\n","        .config(\"spark.kryoserializer.buffer.max\", \"1g\")\n","        .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")  # Enable Arrow for pandas operations\n","        .config(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"10000\")  # Control batch size\n","        .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n","        .getOrCreate())\n","\n","    # Broadcast the device information to all workers\n","    def get_device_info():\n","        if torch.cuda.is_available():\n","            return {\"name\": \"cuda\", \"device_name\": torch.cuda.get_device_name(0)}\n","        else:\n","            return {\"name\": \"cpu\", \"device_name\": \"CPU\"}\n","\n","    device_info = get_device_info()\n","    device_broadcast = spark.sparkContext.broadcast(device_info)\n","\n","    print(f\"Initialized Spark with {device_info['name']} device: {device_info['device_name']}\")\n","    return spark, device_broadcast\n","\n","\n","def shutdown_spark(spark):\n","    \"\"\"Properly shut down the Spark session.\"\"\"\n","    if spark:\n","        spark.stop()\n","        print(\"Spark session stopped\")\n","\n","\n","def distribute_model_files(spark, model_paths):\n","    \"\"\"Add model files to Spark for distribution to all workers.\"\"\"\n","    for path in model_paths:\n","        if os.path.exists(path):\n","            spark.sparkContext.addFile(path)\n","            print(f\"Added {path} to Spark distribution\")\n","        else:\n","            print(f\"Warning: Model file {path} not found\")\n","\n","\n","def preprocess_with_spark(spark, df, source_col1, source_col2):\n","    \"\"\"\n","    Preprocess the input dataframe using Spark for parallel processing.\n","\n","    Args:\n","        spark: SparkSession instance\n","        df: Pandas DataFrame with source columns\n","        source_col1, source_col2: Names of the text columns to normalize\n","\n","    Returns:\n","        Pandas DataFrame with additional normalized columns\n","    \"\"\"\n","    # Convert pandas DataFrame to Spark DataFrame\n","    spark_df = spark.createDataFrame(df)\n","\n","    # Define the normalization function\n","    def normalize_text(text):\n","        if not isinstance(text, str):\n","            return \"\"\n","        return text.lower().strip()\n","\n","    # Register UDF\n","    normalize_udf = udf(normalize_text, StringType())\n","\n","    # Apply normalization\n","    spark_df = spark_df.withColumn(f\"norm_{source_col1}\", normalize_udf(col(source_col1)))\n","    spark_df = spark_df.withColumn(f\"norm_{source_col2}\", normalize_udf(col(source_col2)))\n","\n","    # Convert back to pandas\n","    result_df = spark_df.toPandas()\n","    print(f\"Preprocessed {len(result_df)} rows using Spark\")\n","\n","    return result_df\n","\n","\n","def get_batch_embeddings(model_name, batch_texts, device):\n","    \"\"\"\n","    Get embeddings for a batch of texts using the specified model.\n","    This function is designed to run on a single Spark executor.\n","\n","    Args:\n","        model_name: Name of the embedding model to use ('labse' or 'sentence-transformer')\n","        batch_texts: List of text strings\n","        device: Device to run the model on (cuda/cpu)\n","\n","    Returns:\n","        numpy array of embeddings\n","    \"\"\"\n","    import torch\n","    import numpy as np\n","\n","    if model_name == 'labse':\n","        try:\n","            from transformers import AutoTokenizer, AutoModel\n","\n","            # Load models if not loaded already (will be cached for subsequent calls)\n","            if not hasattr(get_batch_embeddings, 'labse_tokenizer'):\n","                get_batch_embeddings.labse_tokenizer = AutoTokenizer.from_pretrained(\"setu4993/LaBSE\")\n","                get_batch_embeddings.labse_model = AutoModel.from_pretrained(\"setu4993/LaBSE\").to(device)\n","                print(f\"LaBSE model loaded on device: {device}\")\n","\n","            # Tokenize\n","            inputs = get_batch_embeddings.labse_tokenizer(\n","                batch_texts,\n","                return_tensors=\"pt\",\n","                padding=True,\n","                truncation=True,\n","                max_length=128\n","            ).to(device)\n","\n","            # Get embeddings\n","            with torch.no_grad():\n","                outputs = get_batch_embeddings.labse_model(**inputs)\n","                embeddings = outputs.pooler_output\n","\n","                # Normalize\n","                embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n","\n","            return embeddings.cpu().numpy()\n","\n","        except Exception as e:\n","            print(f\"Error in LaBSE embedding calculation: {e}\")\n","            # Return zero embeddings as fallback\n","            return np.zeros((len(batch_texts), 768))\n","\n","    elif model_name == 'sentence-transformer':\n","        try:\n","            from sentence_transformers import SentenceTransformer\n","\n","            # Load model if not loaded already\n","            if not hasattr(get_batch_embeddings, 'st_model'):\n","                get_batch_embeddings.st_model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')\n","                if torch.cuda.is_available():\n","                    get_batch_embeddings.st_model = get_batch_embeddings.st_model.to(device)\n","                print(f\"Sentence-Transformer model loaded on device: {device}\")\n","\n","            # Get embeddings\n","            embeddings = get_batch_embeddings.st_model.encode(\n","                batch_texts,\n","                convert_to_tensor=True,\n","                show_progress_bar=False\n","            )\n","\n","            return embeddings.cpu().numpy()\n","\n","        except Exception as e:\n","            print(f\"Error in Sentence-Transformer embedding calculation: {e}\")\n","            # Return zero embeddings as fallback\n","            return np.zeros((len(batch_texts), 768))\n","\n","    else:\n","        print(f\"Unknown model name: {model_name}\")\n","        return np.zeros((len(batch_texts), 768))\n","\n","\n","def calculate_similarities(embeddings1, embeddings2):\n","    \"\"\"Calculate cosine similarities between two sets of embeddings.\"\"\"\n","    import numpy as np\n","\n","    similarities = np.zeros(len(embeddings1))\n","    for i in range(len(embeddings1)):\n","        # Ensure embeddings are normalized\n","        emb1 = embeddings1[i].reshape(1, -1)\n","        emb2 = embeddings2[i].reshape(1, -1)\n","\n","        # Calculate cosine similarity\n","        similarities[i] = np.dot(emb1, emb2.T)[0][0] / (\n","            np.linalg.norm(emb1) * np.linalg.norm(emb2) + 1e-8)\n","\n","    return similarities\n","\n","\n","def calculate_embedding_metrics_spark(spark, df, text_col1, text_col2, device_broadcast, batch_size=32):\n","    \"\"\"\n","    Calculate embedding-based similarity metrics using Spark for distributed processing.\n","\n","    Args:\n","        spark: SparkSession instance\n","        df: Pandas DataFrame with normalized text columns\n","        text_col1, text_col2: Names of the text columns to compare\n","        device_broadcast: Broadcast variable containing device information\n","        batch_size: Size of batches to process\n","\n","    Returns:\n","        Pandas DataFrame with similarity metrics added\n","    \"\"\"\n","    # Convert pandas DataFrame to Spark DataFrame\n","    spark_df = spark.createDataFrame(df)\n","\n","    # Use broadcast variables for efficiency\n","    device_info = device_broadcast.value\n","    device = device_info[\"name\"]\n","\n","    # Define processing function for batch-wise computation using a safer approach\n","    @pandas_udf(\"double\")\n","    def calculate_labse_similarity(texts1_series, texts2_series):\n","        # Process one row at a time (safer but less efficient)\n","        texts1 = texts1_series.tolist()\n","        texts2 = texts2_series.tolist()\n","        results = []\n","\n","        # Process in small, fixed-size batches\n","        for i in range(0, len(texts1), batch_size):\n","            batch_end = min(i + batch_size, len(texts1))\n","            batch_texts1 = texts1[i:batch_end]\n","            batch_texts2 = texts2[i:batch_end]\n","\n","            try:\n","                # Get embeddings\n","                emb1 = get_batch_embeddings('labse', batch_texts1, device)\n","                emb2 = get_batch_embeddings('labse', batch_texts2, device)\n","\n","                # Calculate similarities\n","                batch_similarities = calculate_similarities(emb1, emb2)\n","                results.extend(batch_similarities)\n","            except Exception as e:\n","                print(f\"Error in batch {i}-{batch_end}: {e}\")\n","                # Fallback for errors: neutral similarity\n","                results.extend([0.5] * (batch_end - i))\n","\n","        return pd.Series(results)\n","\n","    @pandas_udf(\"double\")\n","    def calculate_st_similarity(texts1_series, texts2_series):\n","        # Process one row at a time (safer but less efficient)\n","        texts1 = texts1_series.tolist()\n","        texts2 = texts2_series.tolist()\n","        results = []\n","\n","        # Process in small, fixed-size batches\n","        for i in range(0, len(texts1), batch_size):\n","            batch_end = min(i + batch_size, len(texts1))\n","            batch_texts1 = texts1[i:batch_end]\n","            batch_texts2 = texts2[i:batch_end]\n","\n","            try:\n","                # Get embeddings\n","                emb1 = get_batch_embeddings('sentence-transformer', batch_texts1, device)\n","                emb2 = get_batch_embeddings('sentence-transformer', batch_texts2, device)\n","\n","                # Calculate similarities\n","                batch_similarities = calculate_similarities(emb1, emb2)\n","                results.extend(batch_similarities)\n","            except Exception as e:\n","                print(f\"Error in batch {i}-{batch_end}: {e}\")\n","                # Fallback for errors: neutral similarity\n","                results.extend([0.5] * (batch_end - i))\n","\n","        return pd.Series(results)\n","\n","    # Apply the functions\n","    try:\n","        print(\"Calculating LaBSE similarities...\")\n","        spark_df = spark_df.withColumn(\n","            'labse_similarity',\n","            calculate_labse_similarity(col(text_col1), col(text_col2))\n","        )\n","    except Exception as e:\n","        print(f\"Error in LaBSE calculation: {e}\")\n","        # Add fallback column\n","        spark_df = spark_df.withColumn('labse_similarity', lit(0.5))\n","\n","    try:\n","        print(\"Calculating Sentence-Transformer similarities...\")\n","        spark_df = spark_df.withColumn(\n","            'laser_similarity',  # We keep the same name for compatibility\n","            calculate_st_similarity(col(text_col1), col(text_col2))\n","        )\n","    except Exception as e:\n","        print(f\"Error in sentence-transformer calculation: {e}\")\n","        # Add fallback column\n","        spark_df = spark_df.withColumn('laser_similarity', lit(0.5))\n","\n","    # Convert back to pandas\n","    result_df = spark_df.toPandas()\n","    print(f\"Calculated embedding metrics for {len(result_df)} rows using Spark\")\n","\n","    return result_df\n","\n","\n","def jaccard_similarity_udf(s1, s2):\n","    \"\"\"Calculate Jaccard similarity between two strings.\"\"\"\n","    if not isinstance(s1, str):\n","        s1 = \"\"\n","    if not isinstance(s2, str):\n","        s2 = \"\"\n","\n","    words1 = set(s1.split())\n","    words2 = set(s2.split())\n","\n","    if not words1 and not words2:\n","        return 1.0\n","\n","    intersection = len(words1.intersection(words2))\n","    union = len(words1.union(words2))\n","\n","    return intersection / union if union > 0 else 0\n","\n","\n","def calculate_linguistic_metrics_spark(spark, df, text_col1, text_col2):\n","    \"\"\"\n","    Calculate linguistic metrics using Spark for distributed processing.\n","    A simplified version focusing on metrics that can be reliably computed in Spark.\n","\n","    Args:\n","        spark: SparkSession instance\n","        df: Pandas DataFrame with normalized text columns\n","        text_col1, text_col2: Names of the text columns to compare\n","\n","    Returns:\n","        Pandas DataFrame with linguistic metrics added\n","    \"\"\"\n","    # Convert pandas DataFrame to Spark DataFrame\n","    spark_df = spark.createDataFrame(df)\n","\n","    # Register UDFs\n","    jaccard_udf = udf(jaccard_similarity_udf, DoubleType())\n","\n","    # Calculate length ratio\n","    @udf(DoubleType())\n","    def length_ratio(text1, text2):\n","        if not isinstance(text1, str):\n","            text1 = \"\"\n","        if not isinstance(text2, str):\n","            text2 = \"\"\n","\n","        len1 = len(text1.split())\n","        len2 = len(text2.split())\n","\n","        return min(len1, len2) / max(len1, len2) if max(len1, len2) > 0 else 0\n","\n","    # Calculate metrics\n","    print(\"Calculating linguistic metrics with Spark...\")\n","    spark_df = spark_df.withColumn(\n","        'jaccard_similarity',\n","        jaccard_udf(col(text_col1), col(text_col2))\n","    )\n","\n","    spark_df = spark_df.withColumn(\n","        'length_ratio',\n","        length_ratio(col(text_col1), col(text_col2))\n","    )\n","\n","    # Add placeholder for METEOR score (simplified approximation)\n","    # In a full implementation, this would use a more sophisticated NLP approach\n","    spark_df = spark_df.withColumn(\n","        'meteor_score',\n","        col('jaccard_similarity') * 0.8  # Simple approximation\n","    )\n","\n","    # Convert back to pandas\n","    result_df = spark_df.toPandas()\n","    print(f\"Calculated linguistic metrics for {len(result_df)} rows using Spark\")\n","\n","    return result_df\n","\n","\n","def ensemble_scoring_spark(spark, df):\n","    \"\"\"\n","    Apply ensemble scoring using Spark.\n","\n","    Args:\n","        spark: SparkSession instance\n","        df: Pandas DataFrame with various similarity metrics\n","\n","    Returns:\n","        Pandas DataFrame with ensemble scores and classifications\n","    \"\"\"\n","    # Convert pandas DataFrame to Spark DataFrame\n","    spark_df = spark.createDataFrame(df)\n","\n","    # Available metrics (check which columns exist)\n","    available_metrics = []\n","    weights = {}\n","\n","    if 'labse_similarity' in df.columns:\n","        available_metrics.append('labse_similarity')\n","        weights['labse_similarity'] = 0.4\n","\n","    if 'laser_similarity' in df.columns:\n","        available_metrics.append('laser_similarity')\n","        weights['laser_similarity'] = 0.3\n","\n","    if 'meteor_score' in df.columns:\n","        available_metrics.append('meteor_score')\n","        weights['meteor_score'] = 0.1\n","\n","    if 'length_ratio' in df.columns:\n","        available_metrics.append('length_ratio')\n","        weights['length_ratio'] = 0.1\n","\n","    if 'jaccard_similarity' in df.columns:\n","        available_metrics.append('jaccard_similarity')\n","        weights['jaccard_similarity'] = 0.1\n","\n","    # If no metrics available, add simple fallback\n","    if not available_metrics:\n","        print(\"No metrics available for ensemble scoring, using fallback\")\n","        spark_df = spark_df.withColumn('ensemble_score', lit(0.5))\n","        spark_df = spark_df.withColumn('is_paraphrase', lit(False))\n","        return spark_df.toPandas()\n","\n","    # Normalize weights to sum to 1\n","    total_weight = sum(weights.values())\n","    normalized_weights = {k: v/total_weight for k, v in weights.items()}\n","\n","    # Calculate weighted score\n","    ensemble_expr = None\n","    for metric in available_metrics:\n","        weight = normalized_weights[metric]\n","        if ensemble_expr is None:\n","            ensemble_expr = col(metric) * weight\n","        else:\n","            ensemble_expr = ensemble_expr + (col(metric) * weight)\n","\n","    spark_df = spark_df.withColumn('ensemble_score', ensemble_expr)\n","\n","    # Classify pairs\n","    spark_df = spark_df.withColumn('is_paraphrase', col('ensemble_score') > 0.75)\n","\n","    print(f\"Using {len(available_metrics)} metrics for ensemble scoring with weights: {normalized_weights}\")\n","\n","    # Convert back to pandas\n","    result_df = spark_df.toPandas()\n","\n","    return result_df\n","\n","\n","def calculate_metrics_fallback(df, text_col1, text_col2, device):\n","    \"\"\"\n","    Fallback method for calculating metrics when Spark processing fails.\n","    This uses the original code's approach but with improved error handling.\n","\n","    Args:\n","        df: Pandas DataFrame with normalized text columns\n","        text_col1, text_col2: Names of the text columns to compare\n","        device: Torch device to use for calculations\n","\n","    Returns:\n","        Pandas DataFrame with metrics added\n","    \"\"\"\n","    import torch\n","    import numpy as np\n","    from tqdm.auto import tqdm\n","    import time\n","\n","    print(\"Using fallback calculation method...\")\n","    results = df.copy()\n","\n","    # Define safe batch size\n","    batch_size = 8  # Smaller batch size for safety\n","\n","    # Try to load models with multiple retries\n","    max_retries = 3\n","\n","    # LaBSE loading with retries\n","    for attempt in range(max_retries):\n","        try:\n","            print(f\"Loading LaBSE model (attempt {attempt+1}/{max_retries})...\")\n","            from transformers import AutoTokenizer, AutoModel\n","\n","            tokenizer = AutoTokenizer.from_pretrained(\"setu4993/LaBSE\")\n","            model = AutoModel.from_pretrained(\"setu4993/LaBSE\").to(device)\n","            print(\"LaBSE model loaded successfully\")\n","            break\n","        except Exception as e:\n","            print(f\"LaBSE loading attempt {attempt+1} failed: {e}\")\n","            if attempt == max_retries - 1:\n","                print(\"Could not load LaBSE model, will use simpler metrics\")\n","                model = None\n","                tokenizer = None\n","            time.sleep(2)  # Wait before retrying\n","\n","    # Sentence transformer loading with retries\n","    for attempt in range(max_retries):\n","        try:\n","            print(f\"Loading sentence-transformers model (attempt {attempt+1}/{max_retries})...\")\n","            from sentence_transformers import SentenceTransformer\n","            st_model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')\n","            if torch.cuda.is_available():\n","                st_model = st_model.to(device)\n","            print(\"Sentence-Transformer model loaded successfully\")\n","            break\n","        except Exception as e:\n","            print(f\"Sentence-Transformer loading attempt {attempt+1} failed: {e}\")\n","            if attempt == max_retries - 1:\n","                print(\"Could not load Sentence-Transformer model, will use simpler metrics\")\n","                st_model = None\n","            time.sleep(2)  # Wait before retrying\n","\n","    # Prepare data\n","    texts1 = df[text_col1].tolist()\n","    texts2 = df[text_col2].tolist()\n","\n","    # Initialize results containers\n","    labse_scores = np.zeros(len(df))\n","    st_scores = np.zeros(len(df))\n","\n","    # LaBSE scoring function with better error handling\n","    def get_labse_similarity_safe(batch_texts1, batch_texts2):\n","        try:\n","            if tokenizer is None or model is None:\n","                return np.array([0.5] * len(batch_texts1))\n","\n","            # Tokenize\n","            inputs1 = tokenizer(batch_texts1, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n","            inputs2 = tokenizer(batch_texts2, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n","\n","            # Get embeddings\n","            with torch.no_grad():\n","                embeddings1 = model(**inputs1).pooler_output\n","                embeddings2 = model(**inputs2).pooler_output\n","\n","                # Normalize\n","                embeddings1 = torch.nn.functional.normalize(embeddings1, p=2, dim=1)\n","                embeddings2 = torch.nn.functional.normalize(embeddings2, p=2, dim=1)\n","\n","                # Calculate cosine similarity\n","                similarities = torch.bmm(\n","                    embeddings1.unsqueeze(1),\n","                    embeddings2.unsqueeze(2)\n","                ).squeeze().cpu().numpy()\n","\n","            return similarities\n","        except Exception as e:\n","            print(f\"Error in LaBSE similarity calculation: {e}\")\n","            return np.array([0.5] * len(batch_texts1))  # Fallback to neutral score\n","\n","    # Sentence-transformers scoring with better error handling\n","    def get_st_similarity_safe(batch_texts1, batch_texts2):\n","        try:\n","            if st_model is None:\n","                return np.array([0.5] * len(batch_texts1))\n","\n","            # Get embeddings\n","            with torch.no_grad():\n","                embeddings1 = st_model.encode(batch_texts1, convert_to_tensor=True)\n","                embeddings2 = st_model.encode(batch_texts2, convert_to_tensor=True)\n","\n","                # Calculate cosine similarities\n","                similarities = []\n","                for i in range(len(batch_texts1)):\n","                    try:\n","                        emb1 = embeddings1[i].unsqueeze(0)\n","                        emb2 = embeddings2[i].unsqueeze(0)\n","                        sim = torch.nn.functional.cosine_similarity(emb1, emb2).item()\n","                        similarities.append(sim)\n","                    except Exception as e:\n","                        print(f\"Error calculating similarity for item {i}: {e}\")\n","                        similarities.append(0.5)  # Fallback\n","\n","            return np.array(similarities)\n","        except Exception as e:\n","            print(f\"Error in Sentence-Transformer similarity calculation: {e}\")\n","            return np.array([0.5] * len(batch_texts1))  # Fallback to neutral score\n","\n","    # Jaccard similarity as a fallback\n","    def jaccard_similarity(text1, text2):\n","        if not isinstance(text1, str):\n","            text1 = \"\"\n","        if not isinstance(text2, str):\n","            text2 = \"\"\n","\n","        words1 = set(text1.lower().split())\n","        words2 = set(text2.lower().split())\n","\n","        if not words1 and not words2:\n","            return 1.0\n","\n","        intersection = len(words1.intersection(words2))\n","        union = len(words1.union(words2))\n","\n","        return intersection / union if union > 0 else 0\n","\n","    # Length ratio\n","    def calc_length_ratio(text1, text2):\n","        if not isinstance(text1, str):\n","            text1 = \"\"\n","        if not isinstance(text2, str):\n","            text2 = \"\"\n","\n","        len1 = len(text1.split())\n","        len2 = len(text2.split())\n","\n","        return min(len1, len2) / max(len1, len2) if max(len1, len2) > 0 else 0\n","\n","    # Process in batches with progress bar\n","    for i in tqdm(range(0, len(df), batch_size), desc=\"Calculating metrics (fallback method)\"):\n","        end_idx = min(i + batch_size, len(df))\n","        batch_texts1 = texts1[i:end_idx]\n","        batch_texts2 = texts2[i:end_idx]\n","\n","        # Calculate and store similarities\n","        labse_scores[i:end_idx] = get_labse_similarity_safe(batch_texts1, batch_texts2)\n","        st_scores[i:end_idx] = get_st_similarity_safe(batch_texts1, batch_texts2)\n","\n","    # Add scores to dataframe\n","    results['labse_similarity'] = labse_scores\n","    results['laser_similarity'] = st_scores  # We use sentence-transformers instead of LASER\n","\n","    # Calculate Jaccard similarity for each pair\n","    print(\"Calculating Jaccard similarity...\")\n","    results['jaccard_similarity'] = [\n","        jaccard_similarity(t1, t2) for t1, t2 in zip(texts1, texts2)\n","    ]\n","\n","    # Calculate length ratio\n","    print(\"Calculating length ratio...\")\n","    results['length_ratio'] = [\n","        calc_length_ratio(t1, t2) for t1, t2 in zip(texts1, texts2)\n","    ]\n","\n","    # Add placeholder for METEOR (approximated)\n","    results['meteor_score'] = results['jaccard_similarity'] * 0.8\n","\n","    return results\n","\n","\n","def run_paraphrase_pipeline_spark(input_file, text_col1, text_col2, output_file, spark_master=None):\n","    \"\"\"\n","    Run the paraphrase analysis pipeline using Spark for distributed processing.\n","    Falls back to non-Spark processing if Spark fails.\n","\n","    Args:\n","        input_file: Path to the input Excel file\n","        text_col1, text_col2: Names of the text columns to compare\n","        output_file: Path to save the output CSV\n","        spark_master: Optional Spark master URL (e.g., 'local[*]', 'spark://host:port')\n","\n","    Returns:\n","        Pandas DataFrame with analysis results\n","    \"\"\"\n","    start_time = time.time()\n","    print(f\"Starting Spark-powered paraphrase analysis pipeline at {time.strftime('%H:%M:%S')}\")\n","\n","    spark = None\n","\n","    # Flag to track if we're using Spark or fallback\n","    using_spark = True\n","    device = None\n","\n","    try:\n","        # Initialize Spark\n","        spark, device_broadcast = initialize_spark(\n","            app_name=\"ParaphraseAnalysis\",\n","            master=spark_master\n","        )\n","\n","        # Get device from broadcast\n","        device_info = device_broadcast.value\n","        device = torch.device(device_info[\"name\"])\n","\n","        # Load data\n","        print(f\"Loading data from {input_file}\")\n","        df = pd.read_excel(input_file)\n","        print(f\"Loaded {len(df)} sentence pairs\")\n","\n","        # Preprocessing with Spark\n","        try:\n","            print(\"Preprocessing data with Spark...\")\n","            df = preprocess_with_spark(spark, df, text_col1, text_col2)\n","        except Exception as e:\n","            print(f\"Spark preprocessing failed: {e}\")\n","            print(\"Using fallback preprocessing method...\")\n","\n","            # Fallback to non-Spark preprocessing\n","            def normalize_text(text):\n","                if not isinstance(text, str):\n","                    return \"\"\n","                return text.lower().strip()\n","\n","            df[f\"norm_{text_col1}\"] = df[text_col1].apply(normalize_text)\n","            df[f\"norm_{text_col2}\"] = df[text_col2].apply(normalize_text)\n","\n","        # Save intermediate preprocessing results\n","        intermediate_file = output_file.replace('.csv', '_preprocessed.csv')\n","        df.to_csv(intermediate_file, index=False)\n","        print(f\"Saved preprocessed data to {intermediate_file}\")\n","\n","        # Try Spark embedding metrics calculation\n","        try:\n","            print(\"Calculating embedding metrics with Spark...\")\n","            df = calculate_embedding_metrics_spark(\n","                spark,\n","                df,\n","                f\"norm_{text_col1}\",\n","                f\"norm_{text_col2}\",\n","                device_broadcast\n","            )\n","        except Exception as e:\n","            print(f\"Spark embedding calculation failed: {e}\")\n","            using_spark = False\n","\n","            # Fall back to non-Spark method\n","            print(\"Falling back to non-Spark embedding calculation...\")\n","            df = calculate_metrics_fallback(\n","                df,\n","                f\"norm_{text_col1}\",\n","                f\"norm_{text_col2}\",\n","                device\n","            )\n","\n","        # Save embedding results\n","        embedding_file = output_file.replace('.csv', '_embeddings.csv')\n","        df.to_csv(embedding_file, index=False)\n","        print(f\"Saved embedding results to {embedding_file}\")\n","\n","        # Try Spark linguistic metrics calculation if we're still using Spark\n","        if using_spark:\n","            try:\n","                print(\"Calculating linguistic metrics with Spark...\")\n","                df = calculate_linguistic_metrics_spark(\n","                    spark,\n","                    df,\n","                    f\"norm_{text_col1}\",\n","                    f\"norm_{text_col2}\"\n","                )\n","            except Exception as e:\n","                print(f\"Spark linguistic metrics calculation failed: {e}\")\n","                # We already have basic metrics from the previous step\n","                print(\"Using metrics from previous step...\")\n","                using_spark = False\n","\n","            # Save linguistic results\n","            linguistic_file = output_file.replace('.csv', '_linguistic.csv')\n","            df.to_csv(linguistic_file, index=False)\n","            print(f\"Saved linguistic analysis to {linguistic_file}\")\n","\n","        # Ensemble scoring - this is simple enough to run without Spark if needed\n","        print(\"Ensemble scoring...\")\n","\n","        if using_spark:\n","            try:\n","                df = ensemble_scoring_spark(spark, df)\n","            except Exception as e:\n","                print(f\"Spark ensemble scoring failed: {e}\")\n","                using_spark = False\n","                # Fall back to local ensemble scoring\n","                print(\"Using local ensemble scoring implementation...\")\n","                df = ensemble_scoring_modified(df)\n","        else:\n","            # Use local ensemble scoring\n","            print(\"Using local ensemble scoring implementation...\")\n","            df = ensemble_scoring_modified(df)\n","\n","        # Save final results\n","        print(f\"Saving final results to {output_file}\")\n","        df.to_csv(output_file, index=False)\n","\n","        # Visualization (optional)\n","        try:\n","            print(\"Generating visualizations...\")\n","\n","            # Create a visualizations directory if it doesn't exist\n","            viz_dir = os.path.join(os.path.dirname(output_file), \"visualizations\")\n","            os.makedirs(viz_dir, exist_ok=True)\n","\n","            # Use the functions defined in this module\n","            visualize_results(df, viz_dir)\n","\n","            # Only try grammar-specific visualizations if we have those metrics\n","            if any(col in df.columns for col in ['morph_similarity', 'grammar_mismatch', 'meteor_difference']):\n","                visualize_grammatical_metrics(df, viz_dir)\n","\n","            print(f\"Visualizations saved to {viz_dir}\")\n","        except Exception as e:\n","            print(f\"Visualization error: {e}\")\n","            print(\"Skipping visualization step. Error details:\")\n","            import traceback\n","            traceback.print_exc()\n","\n","        elapsed_time = time.time() - start_time\n","        print(f\"Pipeline completed in {elapsed_time:.2f} seconds\")\n","\n","        return df\n","\n","    except Exception as e:\n","        # Catch any unhandled exceptions\n","        elapsed_time = time.time() - start_time\n","        print(f\"Pipeline failed after {elapsed_time:.2f} seconds\")\n","        print(f\"Critical error: {e}\")\n","\n","        # Print exception traceback for debugging\n","        import traceback\n","        traceback.print_exc()\n","\n","        return None\n","\n","    finally:\n","        # Always shut down Spark\n","        if spark:\n","            shutdown_spark(spark)\n"],"metadata":{"id":"5b5cqtK0YT7B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    # Define base directory - Update this to your actual location\n","    base_dir = \"/content/drive/MyDrive/Colab Notebooks/preprocessed_datasets\"\n","\n","    # Dataset name - change this to switch between datasets\n","    dataset = \"predprocesiranje_msr_paired\"\n","    #dataset = \"paws_nepodvojene_filtrirane_parafraze\"\n","\n","    # Construct paths using f-strings\n","    input_file = f\"{base_dir}/{dataset}.xlsx\"\n","    output_file = f\"{base_dir}/paraphrase_analysis_results_{dataset.split('_')[0]}_{dataset}.csv\"\n","\n","    # Column names\n","    text_col1 = \"sentence_translation\"\n","    text_col2 = \"paraphrase_translation\"\n","\n","    # Spark configuration\n","    # Options for spark_master:\n","    # - 'local[*]': Use all available cores on local machine\n","    # - 'local[4]': Use 4 cores on local machine (more stable)\n","    # - None: Use the default Spark configuration\n","    # - 'spark://host:port': Connect to a Spark cluster\n","    spark_config = {\n","        'master': 'local[4]',  # Using 4 cores is more stable than all cores\n","        'use_fallback_early': False  # Set to True to skip Spark and use fallback methods directly\n","    }\n","\n","    # Run the pipeline with Spark\n","    results = run_paraphrase_pipeline_spark(\n","        input_file,\n","        text_col1,\n","        text_col2,\n","        output_file,\n","        spark_master=spark_config['master']\n","    )\n","\n","    print(\"Pipeline execution complete.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JedZvL6WYU5w","executionInfo":{"status":"ok","timestamp":1741951876390,"user_tz":-60,"elapsed":124868,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"90d8721a-0055-4078-9738-794f4a82a0c8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting Spark-powered paraphrase analysis pipeline at 11:29:11\n","Initialized Spark with cuda device: Tesla T4\n","Loading data from /content/drive/MyDrive/Colab Notebooks/preprocessed_datasets/predprocesiranje_msr_paired.xlsx\n","Loaded 4798 sentence pairs\n","Preprocessing data with Spark...\n","Preprocessed 4798 rows using Spark\n","Saved preprocessed data to /content/drive/MyDrive/Colab Notebooks/preprocessed_datasets/paraphrase_analysis_results_predprocesiranje_preprocessed.csv\n","Calculating embedding metrics with Spark...\n","Calculating LaBSE similarities...\n","Calculating Sentence-Transformer similarities...\n","Calculated embedding metrics for 4798 rows using Spark\n","Saved embedding results to /content/drive/MyDrive/Colab Notebooks/preprocessed_datasets/paraphrase_analysis_results_predprocesiranje_embeddings.csv\n","Calculating linguistic metrics with Spark...\n","Calculating linguistic metrics with Spark...\n","Calculated linguistic metrics for 4798 rows using Spark\n","Saved linguistic analysis to /content/drive/MyDrive/Colab Notebooks/preprocessed_datasets/paraphrase_analysis_results_predprocesiranje_linguistic.csv\n","Ensemble scoring...\n","Using 5 metrics for ensemble scoring with weights: {'labse_similarity': 0.4000000000000001, 'laser_similarity': 0.30000000000000004, 'meteor_score': 0.10000000000000002, 'length_ratio': 0.10000000000000002, 'jaccard_similarity': 0.10000000000000002}\n","Saving final results to /content/drive/MyDrive/Colab Notebooks/preprocessed_datasets/paraphrase_analysis_results_predprocesiranje.csv\n","Generating visualizations...\n","Basic visualizations saved to /content/drive/MyDrive/Colab Notebooks/preprocessed_datasets/visualizations\n","Visualizations saved to /content/drive/MyDrive/Colab Notebooks/preprocessed_datasets/visualizations\n","Pipeline completed in 123.83 seconds\n","Spark session stopped\n","Pipeline execution complete.\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Analysis utilities for the paraphrase pipeline.\n","This module provides functions to analyze and validate the results of the pipeline.\n","\"\"\"\n","\n","import os\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from matplotlib.backends.backend_pdf import PdfPages\n","\n","\n","def analyze_paraphrase_results(df, output_dir='.'):\n","    \"\"\"\n","    Generate basic statistics and visualizations from paraphrase detection results.\n","\n","    Args:\n","        df (pandas.DataFrame): DataFrame containing paraphrase analysis results\n","        output_dir (str): Directory to save visualizations\n","\n","    Returns:\n","        dict: Dictionary of statistics\n","    \"\"\"\n","    # Create output directory if it doesn't exist\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    # Basic counts\n","    total_pairs = len(df)\n","    if 'is_paraphrase' not in df.columns:\n","        print(\"Warning: 'is_paraphrase' column not found in results\")\n","        df['is_paraphrase'] = df.get('ensemble_score', pd.Series([0.5] * len(df))) > 0.75\n","\n","    paraphrase_count = df['is_paraphrase'].sum()\n","    non_paraphrase_count = total_pairs - paraphrase_count\n","    paraphrase_percentage = (paraphrase_count / total_pairs) * 100\n","\n","    print(f\"\\n===== PARAPHRASE ANALYSIS RESULTS =====\")\n","    print(f\"Total sentence pairs analyzed: {total_pairs}\")\n","    print(f\"Paraphrases detected: {paraphrase_count} ({paraphrase_percentage:.2f}%)\")\n","    print(f\"Non-paraphrases detected: {non_paraphrase_count} ({100-paraphrase_percentage:.2f}%)\")\n","\n","    # Grammar and duplicate statistics (if available)\n","    grammar_error_count = 0\n","    grammar_error_percentage = 0\n","    if 'potential_grammar_error' in df.columns:\n","        grammar_error_count = df['potential_grammar_error'].sum()\n","        grammar_error_percentage = (grammar_error_count / total_pairs) * 100\n","        print(f\"\\nPotential grammar errors: {grammar_error_count} ({grammar_error_percentage:.2f}%)\")\n","\n","    duplicate_count = 0\n","    duplicate_percentage = 0\n","    if 'is_near_duplicate' in df.columns:\n","        duplicate_count = df['is_near_duplicate'].sum()\n","        duplicate_percentage = (duplicate_count / total_pairs) * 100\n","        print(f\"Near-duplicates: {duplicate_count} ({duplicate_percentage:.2f}%)\")\n","\n","    # Score distribution statistics\n","    print(f\"\\n===== SCORE DISTRIBUTION =====\")\n","    # Include all metrics that might be in the enhanced pipeline\n","    metrics = [\n","        'labse_similarity', 'laser_similarity', 'meteor_score',\n","        'raw_meteor_score', 'lemma_meteor_score', 'meteor_difference',\n","        'morph_similarity', 'length_ratio', 'jaccard_similarity',\n","        'string_similarity', 'ensemble_score'\n","    ]\n","\n","    # Only include metrics that exist in the DataFrame\n","    available_metrics = [m for m in metrics if m in df.columns]\n","\n","    # Calculate statistics for each available metric\n","    metric_stats = {}\n","    for metric in available_metrics:\n","        avg = df[metric].mean()\n","        median = df[metric].median()"],"metadata":{"id":"eJ2co8uSgtoT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Failed try with meteor before and after lemmatization, and spark integration, and additional analysis"],"metadata":{"id":"0ZI23corEO87"}},{"cell_type":"code","source":["\"\"\"\n","Apache Spark Integration for Paraphrase Analysis Pipeline\n","This module enhances the existing pipeline with distributed processing capabilities.\n","\"\"\"\n","\n","import os\n","import time\n","import pandas as pd\n","import numpy as np\n","from pyspark.sql import SparkSession\n","from pyspark.sql.types import *\n","from pyspark.sql.functions import col, udf, pandas_udf, lit\n","from pyspark import SparkFiles\n","import torch\n","from typing import Iterator, Tuple, List\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","\n","# Visualization functions included directly in the main module\n","def visualize_results(df, output_dir='.'):\n","    \"\"\"\n","    Create visualizations for the paraphrase analysis results.\n","\n","    Args:\n","        df: Pandas DataFrame with paraphrase analysis results\n","        output_dir: Directory to save the visualizations\n","    \"\"\"\n","    # Create directory if it doesn't exist\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    # Create figure with subplots\n","    metrics_to_plot = []\n","\n","    # Check which metrics are available\n","    for metric in ['labse_similarity', 'laser_similarity', 'meteor_score',\n","                   'length_ratio', 'jaccard_similarity', 'ensemble_score']:\n","        if metric in df.columns:\n","            metrics_to_plot.append(metric)\n","\n","    if not metrics_to_plot:\n","        print(\"No metrics available for visualization\")\n","        return\n","\n","    # Calculate subplot grid dimensions\n","    n_metrics = len(metrics_to_plot)\n","    n_cols = min(3, n_metrics)\n","    n_rows = (n_metrics + n_cols - 1) // n_cols\n","\n","    # Create figure\n","    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 4*n_rows))\n","\n","    # Handle case with single subplot\n","    if n_metrics == 1:\n","        axes = np.array([axes])\n","\n","    # Flatten axes array for easy iteration\n","    if n_metrics > 1:\n","        axes = axes.flatten()\n","\n","    # Create histograms\n","    for i, metric in enumerate(metrics_to_plot):\n","        sns.histplot(df[metric], kde=True, ax=axes[i])\n","        axes[i].set_title(f'Distribution of {metric}')\n","        axes[i].axvline(df[metric].mean(), color='r', linestyle='--')\n","\n","    # Hide unused subplots\n","    for i in range(n_metrics, len(axes)):\n","        axes[i].set_visible(False)\n","\n","    plt.tight_layout()\n","    plt.savefig(os.path.join(output_dir, 'metric_distributions.png'))\n","    plt.close()\n","\n","    # Correlation matrix (if multiple metrics available)\n","    if len(metrics_to_plot) > 1:\n","        plt.figure(figsize=(10, 8))\n","        correlation = df[metrics_to_plot].corr()\n","        sns.heatmap(correlation, annot=True, cmap='coolwarm')\n","        plt.title('Correlation Matrix of Metrics')\n","        plt.tight_layout()\n","        plt.savefig(os.path.join(output_dir, 'correlation_matrix.png'))\n","        plt.close()\n","\n","    # Create a scatter plot of two main metrics (if available)\n","    main_metrics = []\n","    for metric in ['labse_similarity', 'laser_similarity']:\n","        if metric in metrics_to_plot:\n","            main_metrics.append(metric)\n","\n","    if len(main_metrics) >= 2:\n","        plt.figure(figsize=(10, 8))\n","        scatter = plt.scatter(\n","            df[main_metrics[0]],\n","            df[main_metrics[1]],\n","            c=df['ensemble_score'] if 'ensemble_score' in df.columns else None,\n","            cmap='viridis',\n","            alpha=0.7\n","        )\n","        plt.colorbar(scatter, label='Ensemble Score')\n","        plt.xlabel(main_metrics[0])\n","        plt.ylabel(main_metrics[1])\n","        plt.title(f'Scatter Plot of {main_metrics[0]} vs {main_metrics[1]}')\n","        plt.tight_layout()\n","        plt.savefig(os.path.join(output_dir, 'metrics_scatter.png'))\n","        plt.close()\n","\n","    print(f\"Basic visualizations saved to {output_dir}\")\n","\n","\n","def visualize_grammatical_metrics(df, output_dir='.'):\n","    \"\"\"\n","    Create visualizations specifically for grammatical metrics.\n","\n","    Args:\n","        df: Pandas DataFrame with grammatical metrics\n","        output_dir: Directory to save the visualizations\n","    \"\"\"\n","    # Create directory if it doesn't exist\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    # 1. METEOR before and after lemmatization comparison\n","    if 'raw_meteor_score' in df.columns and 'lemma_meteor_score' in df.columns:\n","        plt.figure(figsize=(10, 8))\n","        plt.scatter(df['raw_meteor_score'], df['lemma_meteor_score'], alpha=0.5)\n","        plt.plot([0, 1], [0, 1], 'r--')  # Diagonal line\n","        plt.xlabel('Raw METEOR Score')\n","        plt.ylabel('Lemmatized METEOR Score')\n","        plt.title('METEOR Scores Before and After Lemmatization')\n","        plt.grid(True, alpha=0.3)\n","        plt.savefig(os.path.join(output_dir, 'meteor_comparison.png'))\n","        plt.close()\n","\n","        # Histogram of METEOR differences\n","        if 'meteor_difference' in df.columns:\n","            plt.figure(figsize=(10, 6))\n","            sns.histplot(df['meteor_difference'], kde=True)\n","            plt.axvline(x=0, color='r', linestyle='--')\n","            plt.xlabel('METEOR Difference (Lemmatized - Raw)')\n","            plt.ylabel('Count')\n","            plt.title('Distribution of METEOR Differences')\n","            plt.grid(True, alpha=0.3)\n","            plt.savefig(os.path.join(output_dir, 'meteor_difference.png'))\n","            plt.close()\n","\n","    # 2. Morphological similarity distribution\n","    if 'morph_similarity' in df.columns:\n","        plt.figure(figsize=(10, 6))\n","        sns.histplot(df['morph_similarity'], kde=True, bins=20)\n","        plt.xlabel('Morphological Similarity')\n","        plt.ylabel('Count')\n","        plt.title('Distribution of Morphological Similarity')\n","        plt.grid(True, alpha=0.3)\n","        plt.savefig(os.path.join(output_dir, 'morph_similarity.png'))\n","        plt.close()\n","\n","    # 3. Grammar mismatch analysis\n","    if 'grammar_mismatch' in df.columns and 'morph_grammar_mismatch' in df.columns:\n","        # Count of grammar mismatch types\n","        mismatch_counts = {\n","            'Both': sum(df['grammar_mismatch'] & df['morph_grammar_mismatch']),\n","            'METEOR Only': sum(df['grammar_mismatch'] & ~df['morph_grammar_mismatch']),\n","            'Morphology Only': sum(~df['grammar_mismatch'] & df['morph_grammar_mismatch']),\n","            'No Mismatch': sum(~df['grammar_mismatch'] & ~df['morph_grammar_mismatch'])\n","        }\n","\n","        plt.figure(figsize=(10, 6))\n","        plt.bar(mismatch_counts.keys(), mismatch_counts.values())\n","        plt.xlabel('Grammar Mismatch Type')\n","        plt.ylabel('Count')\n","        plt.title('Types of Grammar Mismatches Detected')\n","        plt.savefig(os.path.join(output_dir, 'grammar_mismatch_types.png'))\n","        plt.close()\n","\n","    # 4. Near-duplicates vs. Grammar mismatches\n","    if 'is_near_duplicate' in df.columns and 'potential_grammar_error' in df.columns:\n","        # Count combinations\n","        categories = {\n","            'Near Duplicate & Grammar Error': sum(df['is_near_duplicate'] & df['potential_grammar_error']),\n","            'Near Duplicate Only': sum(df['is_near_duplicate'] & ~df['potential_grammar_error']),\n","            'Grammar Error Only': sum(~df['is_near_duplicate'] & df['potential_grammar_error']),\n","            'Neither': sum(~df['is_near_duplicate'] & ~df['potential_grammar_error'])\n","        }\n","\n","        plt.figure(figsize=(10, 6))\n","        plt.bar(categories.keys(), categories.values())\n","        plt.xlabel('Category')\n","        plt.ylabel('Count')\n","        plt.title('Near Duplicates vs. Grammar Errors')\n","        plt.xticks(rotation=45, ha='right')\n","        plt.tight_layout()\n","        plt.savefig(os.path.join(output_dir, 'duplicate_vs_grammar.png'))\n","        plt.close()\n","\n","    print(f\"Grammar-specific visualizations saved to {output_dir}\")\n","\n","\n","def initialize_spark(app_name=\"ParaphraseAnalysis\", master=None):\n","    \"\"\"Initialize a Spark session with appropriate configuration for NLP tasks.\"\"\"\n","    # If no master is specified, it will use the default (local or cluster if configured)\n","    builder = SparkSession.builder.appName(app_name)\n","\n","    if master:\n","        builder = builder.master(master)\n","\n","    # Add necessary configuration for handling NLP models and data\n","    spark = (builder\n","        .config(\"spark.driver.memory\", \"16g\")  # Adjust based on your environment\n","        .config(\"spark.executor.memory\", \"16g\")\n","        .config(\"spark.driver.maxResultSize\", \"8g\")\n","        .config(\"spark.python.worker.memory\", \"8g\")\n","        .config(\"spark.kryoserializer.buffer.max\", \"1g\")\n","        .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")  # Enable Arrow for pandas operations\n","        .config(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"10000\")  # Control batch size\n","        .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n","        .getOrCreate())\n","\n","    # Broadcast the device information to all workers\n","    def get_device_info():\n","        if torch.cuda.is_available():\n","            return {\"name\": \"cuda\", \"device_name\": torch.cuda.get_device_name(0)}\n","        else:\n","            return {\"name\": \"cpu\", \"device_name\": \"CPU\"}\n","\n","    device_info = get_device_info()\n","    device_broadcast = spark.sparkContext.broadcast(device_info)\n","\n","    print(f\"Initialized Spark with {device_info['name']} device: {device_info['device_name']}\")\n","    return spark, device_broadcast\n","\n","\n","def shutdown_spark(spark):\n","    \"\"\"Properly shut down the Spark session.\"\"\"\n","    if spark:\n","        spark.stop()\n","        print(\"Spark session stopped\")\n","\n","\n","def distribute_model_files(spark, model_paths):\n","    \"\"\"Add model files to Spark for distribution to all workers.\"\"\"\n","    for path in model_paths:\n","        if os.path.exists(path):\n","            spark.sparkContext.addFile(path)\n","            print(f\"Added {path} to Spark distribution\")\n","        else:\n","            print(f\"Warning: Model file {path} not found\")\n","\n","\n","def preprocess_with_spark(spark, df, source_col1, source_col2):\n","    \"\"\"\n","    Preprocess the input dataframe using Spark for parallel processing.\n","\n","    Args:\n","        spark: SparkSession instance\n","        df: Pandas DataFrame with source columns\n","        source_col1, source_col2: Names of the text columns to normalize\n","\n","    Returns:\n","        Pandas DataFrame with additional normalized columns\n","    \"\"\"\n","    # Convert pandas DataFrame to Spark DataFrame\n","    spark_df = spark.createDataFrame(df)\n","\n","    # Define the normalization function\n","    def normalize_text(text):\n","        if not isinstance(text, str):\n","            return \"\"\n","        return text.lower().strip()\n","\n","    # Register UDF\n","    normalize_udf = udf(normalize_text, StringType())\n","\n","    # Apply normalization\n","    spark_df = spark_df.withColumn(f\"norm_{source_col1}\", normalize_udf(col(source_col1)))\n","    spark_df = spark_df.withColumn(f\"norm_{source_col2}\", normalize_udf(col(source_col2)))\n","\n","    # Convert back to pandas\n","    result_df = spark_df.toPandas()\n","    print(f\"Preprocessed {len(result_df)} rows using Spark\")\n","\n","    return result_df\n","\n","\n","def get_batch_embeddings(model_name, batch_texts, device):\n","    \"\"\"\n","    Get embeddings for a batch of texts using the specified model.\n","    This function is designed to run on a single Spark executor.\n","\n","    Args:\n","        model_name: Name of the embedding model to use ('labse' or 'sentence-transformer')\n","        batch_texts: List of text strings\n","        device: Device to run the model on (cuda/cpu)\n","\n","    Returns:\n","        numpy array of embeddings\n","    \"\"\"\n","    import torch\n","    import numpy as np\n","\n","    if model_name == 'labse':\n","        try:\n","            from transformers import AutoTokenizer, AutoModel\n","\n","            # Load models if not loaded already (will be cached for subsequent calls)\n","            if not hasattr(get_batch_embeddings, 'labse_tokenizer'):\n","                get_batch_embeddings.labse_tokenizer = AutoTokenizer.from_pretrained(\"setu4993/LaBSE\")\n","                get_batch_embeddings.labse_model = AutoModel.from_pretrained(\"setu4993/LaBSE\").to(device)\n","                print(f\"LaBSE model loaded on device: {device}\")\n","\n","            # Tokenize\n","            inputs = get_batch_embeddings.labse_tokenizer(\n","                batch_texts,\n","                return_tensors=\"pt\",\n","                padding=True,\n","                truncation=True,\n","                max_length=128\n","            ).to(device)\n","\n","            # Get embeddings\n","            with torch.no_grad():\n","                outputs = get_batch_embeddings.labse_model(**inputs)\n","                embeddings = outputs.pooler_output\n","\n","                # Normalize\n","                embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n","\n","            return embeddings.cpu().numpy()\n","\n","        except Exception as e:\n","            print(f\"Error in LaBSE embedding calculation: {e}\")\n","            # Return zero embeddings as fallback\n","            return np.zeros((len(batch_texts), 768))\n","\n","    elif model_name == 'sentence-transformer':\n","        try:\n","            from sentence_transformers import SentenceTransformer\n","\n","            # Load model if not loaded already\n","            if not hasattr(get_batch_embeddings, 'st_model'):\n","                get_batch_embeddings.st_model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')\n","                if torch.cuda.is_available():\n","                    get_batch_embeddings.st_model = get_batch_embeddings.st_model.to(device)\n","                print(f\"Sentence-Transformer model loaded on device: {device}\")\n","\n","            # Get embeddings\n","            embeddings = get_batch_embeddings.st_model.encode(\n","                batch_texts,\n","                convert_to_tensor=True,\n","                show_progress_bar=False\n","            )\n","\n","            return embeddings.cpu().numpy()\n","\n","        except Exception as e:\n","            print(f\"Error in Sentence-Transformer embedding calculation: {e}\")\n","            # Return zero embeddings as fallback\n","            return np.zeros((len(batch_texts), 768))\n","\n","    else:\n","        print(f\"Unknown model name: {model_name}\")\n","        return np.zeros((len(batch_texts), 768))\n","\n","\n","def calculate_similarities(embeddings1, embeddings2):\n","    \"\"\"Calculate cosine similarities between two sets of embeddings.\"\"\"\n","    import numpy as np\n","\n","    similarities = np.zeros(len(embeddings1))\n","    for i in range(len(embeddings1)):\n","        # Ensure embeddings are normalized\n","        emb1 = embeddings1[i].reshape(1, -1)\n","        emb2 = embeddings2[i].reshape(1, -1)\n","\n","        # Calculate cosine similarity\n","        similarities[i] = np.dot(emb1, emb2.T)[0][0] / (\n","            np.linalg.norm(emb1) * np.linalg.norm(emb2) + 1e-8)\n","\n","    return similarities\n","\n","\n","def calculate_embedding_metrics_spark(spark, df, text_col1, text_col2, device_broadcast, batch_size=32):\n","    \"\"\"\n","    Calculate embedding-based similarity metrics using Spark for distributed processing.\n","\n","    Args:\n","        spark: SparkSession instance\n","        df: Pandas DataFrame with normalized text columns\n","        text_col1, text_col2: Names of the text columns to compare\n","        device_broadcast: Broadcast variable containing device information\n","        batch_size: Size of batches to process\n","\n","    Returns:\n","        Pandas DataFrame with similarity metrics added\n","    \"\"\"\n","    # Convert pandas DataFrame to Spark DataFrame\n","    spark_df = spark.createDataFrame(df)\n","\n","    # Use broadcast variables for efficiency\n","    device_info = device_broadcast.value\n","    device = device_info[\"name\"]\n","\n","    # Define processing function for batch-wise computation using a safer approach\n","    @pandas_udf(\"double\")\n","    def calculate_labse_similarity(texts1_series, texts2_series):\n","        # Process one row at a time (safer but less efficient)\n","        texts1 = texts1_series.tolist()\n","        texts2 = texts2_series.tolist()\n","        results = []\n","\n","        # Process in small, fixed-size batches\n","        for i in range(0, len(texts1), batch_size):\n","            batch_end = min(i + batch_size, len(texts1))\n","            batch_texts1 = texts1[i:batch_end]\n","            batch_texts2 = texts2[i:batch_end]\n","\n","            try:\n","                # Get embeddings\n","                emb1 = get_batch_embeddings('labse', batch_texts1, device)\n","                emb2 = get_batch_embeddings('labse', batch_texts2, device)\n","\n","                # Calculate similarities\n","                batch_similarities = calculate_similarities(emb1, emb2)\n","                results.extend(batch_similarities)\n","            except Exception as e:\n","                print(f\"Error in batch {i}-{batch_end}: {e}\")\n","                # Fallback for errors: neutral similarity\n","                results.extend([0.5] * (batch_end - i))\n","\n","        return pd.Series(results)\n","\n","    @pandas_udf(\"double\")\n","    def calculate_st_similarity(texts1_series, texts2_series):\n","        # Process one row at a time (safer but less efficient)\n","        texts1 = texts1_series.tolist()\n","        texts2 = texts2_series.tolist()\n","        results = []\n","\n","        # Process in small, fixed-size batches\n","        for i in range(0, len(texts1), batch_size):\n","            batch_end = min(i + batch_size, len(texts1))\n","            batch_texts1 = texts1[i:batch_end]\n","            batch_texts2 = texts2[i:batch_end]\n","\n","            try:\n","                # Get embeddings\n","                emb1 = get_batch_embeddings('sentence-transformer', batch_texts1, device)\n","                emb2 = get_batch_embeddings('sentence-transformer', batch_texts2, device)\n","\n","                # Calculate similarities\n","                batch_similarities = calculate_similarities(emb1, emb2)\n","                results.extend(batch_similarities)\n","            except Exception as e:\n","                print(f\"Error in batch {i}-{batch_end}: {e}\")\n","                # Fallback for errors: neutral similarity\n","                results.extend([0.5] * (batch_end - i))\n","\n","        return pd.Series(results)\n","\n","    # Apply the functions\n","    try:\n","        print(\"Calculating LaBSE similarities...\")\n","        spark_df = spark_df.withColumn(\n","            'labse_similarity',\n","            calculate_labse_similarity(col(text_col1), col(text_col2))\n","        )\n","    except Exception as e:\n","        print(f\"Error in LaBSE calculation: {e}\")\n","        # Add fallback column\n","        spark_df = spark_df.withColumn('labse_similarity', lit(0.5))\n","\n","    try:\n","        print(\"Calculating Sentence-Transformer similarities...\")\n","        spark_df = spark_df.withColumn(\n","            'laser_similarity',  # We keep the same name for compatibility\n","            calculate_st_similarity(col(text_col1), col(text_col2))\n","        )\n","    except Exception as e:\n","        print(f\"Error in sentence-transformer calculation: {e}\")\n","        # Add fallback column\n","        spark_df = spark_df.withColumn('laser_similarity', lit(0.5))\n","\n","    # Convert back to pandas\n","    result_df = spark_df.toPandas()\n","    print(f\"Calculated embedding metrics for {len(result_df)} rows using Spark\")\n","\n","    return result_df\n","\n","\n","def jaccard_similarity_udf(s1, s2):\n","    \"\"\"Calculate Jaccard similarity between two strings.\"\"\"\n","    if not isinstance(s1, str):\n","        s1 = \"\"\n","    if not isinstance(s2, str):\n","        s2 = \"\"\n","\n","    words1 = set(s1.split())\n","    words2 = set(s2.split())\n","\n","    if not words1 and not words2:\n","        return 1.0\n","\n","    intersection = len(words1.intersection(words2))\n","    union = len(words1.union(words2))\n","\n","    return intersection / union if union > 0 else 0\n","\n","\n","def calculate_linguistic_metrics_spark(spark, df, text_col1, text_col2):\n","    \"\"\"\n","    Calculate linguistic metrics using Spark for distributed processing.\n","    Modified to use ClassLA for Slovenian lemmatization.\n","\n","    Args:\n","        spark: SparkSession instance\n","        df: Pandas DataFrame with normalized text columns\n","        text_col1, text_col2: Names of the text columns to compare\n","\n","    Returns:\n","        Pandas DataFrame with linguistic metrics added\n","    \"\"\"\n","    # Convert pandas DataFrame to Spark DataFrame\n","    spark_df = spark.createDataFrame(df)\n","\n","    # Register UDFs\n","    jaccard_udf = udf(jaccard_similarity_udf, DoubleType())\n","\n","    # Calculate length ratio\n","    @udf(DoubleType())\n","    def length_ratio(text1, text2):\n","        if not isinstance(text1, str):\n","            text1 = \"\"\n","        if not isinstance(text2, str):\n","            text2 = \"\"\n","\n","        len1 = len(text1.split())\n","        len2 = len(text2.split())\n","\n","        return min(len1, len2) / max(len1, len2) if max(len1, len2) > 0 else 0\n","\n","    # Calculate metrics\n","    print(\"Calculating linguistic metrics with Spark...\")\n","    spark_df = spark_df.withColumn(\n","        'jaccard_similarity',\n","        jaccard_udf(col(text_col1), col(text_col2))\n","    )\n","\n","    spark_df = spark_df.withColumn(\n","        'length_ratio',\n","        length_ratio(col(text_col1), col(text_col2))\n","    )\n","\n","    # Add placeholder for METEOR score (simplified approximation)\n","    # In a full implementation, this would use a more sophisticated NLP approach\n","    spark_df = spark_df.withColumn(\n","        'meteor_score',\n","        col('jaccard_similarity') * 0.8  # Simple approximation\n","    )\n","\n","    # Convert back to pandas for more complex processing\n","    result_df = spark_df.toPandas()\n","    print(f\"Calculated linguistic metrics for {len(result_df)} rows using Spark\")\n","\n","    # Calculate proper METEOR scores with ClassLA for Slovenian\n","    try:\n","        # Import NLTK for METEOR calculation\n","        import nltk\n","        from nltk.translate.meteor_score import meteor_score\n","\n","        # Import ClassLA for Slovenian lemmatization\n","        import classla\n","\n","        # Download required NLTK data if not already present\n","        try:\n","            nltk.data.find('wordnet')\n","        except LookupError:\n","            nltk.download('wordnet')\n","        try:\n","            nltk.data.find('omw-1.4')\n","        except LookupError:\n","            nltk.download('omw-1.4')\n","\n","        # Initialize ClassLA for Slovenian\n","        # Download models on first run if needed\n","        try:\n","            # Check if models exist\n","            import os\n","            if not os.path.exists(os.path.expanduser('~/.classla_resources/resources/slovenian')):\n","                print(\"Downloading ClassLA models for Slovenian (first run only)...\")\n","                classla.download('sl')\n","        except Exception as e:\n","            print(f\"Warning: Could not verify ClassLA models: {e}. Will attempt to continue.\")\n","\n","        # Initialize the Slovenian pipeline with just the necessary processors\n","        print(\"Initializing ClassLA pipeline for Slovenian...\")\n","        nlp = classla.Pipeline('sl', processors='tokenize,lemma')\n","\n","        # Helper function for Slovenian lemmatization using ClassLA\n","        def lemmatize_text_classla(text):\n","            if not isinstance(text, str) or not text.strip():\n","                return \"\"\n","            try:\n","                doc = nlp(text)\n","                # Extract lemmas from the processed document\n","                lemmas = [word.lemma for sent in doc.sentences for word in sent.words]\n","                return \" \".join(lemmas)\n","            except Exception as e:\n","                print(f\"Error in ClassLA lemmatization: {e}\")\n","                return text  # Return original text as fallback\n","\n","        # First, perform lemmatization\n","        print(\"Performing Slovenian lemmatization with ClassLA...\")\n","        lemma_texts1 = []\n","        lemma_texts2 = []\n","\n","        # Process in smaller batches to avoid memory issues\n","        batch_size = 100\n","        for i in range(0, len(result_df), batch_size):\n","            end_idx = min(i + batch_size, len(result_df))\n","            print(f\"Processing lemmatization batch {i+1}-{end_idx} of {len(result_df)}\")\n","\n","            batch_lemmas1 = [lemmatize_text_classla(t) for t in result_df[text_col1][i:end_idx]]\n","            batch_lemmas2 = [lemmatize_text_classla(t) for t in result_df[text_col2][i:end_idx]]\n","\n","            lemma_texts1.extend(batch_lemmas1)\n","            lemma_texts2.extend(batch_lemmas2)\n","\n","        # Add lemmatized forms as columns\n","        result_df['lemma_text1'] = lemma_texts1\n","        result_df['lemma_text2'] = lemma_texts2\n","\n","        # Calculate multiple METEOR variants with different parameter settings\n","        print(\"Calculating multiple METEOR variants...\")\n","\n","        # Standard METEOR (current implementation)\n","        result_df['raw_meteor_score'] = [\n","            meteor_score([t1.split()], t2.split()) if isinstance(t1, str) and isinstance(t2, str) else 0.0\n","            for t1, t2 in zip(result_df[text_col1], result_df[text_col2])\n","        ]\n","\n","        # Lemmatized with standard weights\n","        result_df['lemma_meteor_score'] = [\n","            meteor_score([t1.split()], t2.split()) if t1 and t2 else 0.0\n","            for t1, t2 in zip(lemma_texts1, lemma_texts2)\n","        ]\n","\n","        # Lemmatized with fragmentation emphasis\n","        result_df['lemma_meteor_frag'] = [\n","            meteor_score([t1.split()], t2.split(), gamma=0.75) if t1 and t2 else 0.0\n","            for t1, t2 in zip(lemma_texts1, lemma_texts2)\n","        ]\n","\n","        # Lemmatized with precision emphasis\n","        result_df['lemma_meteor_prec'] = [\n","            meteor_score([t1.split()], t2.split(), alpha=0.9, beta=0.1) if t1 and t2 else 0.0\n","            for t1, t2 in zip(lemma_texts1, lemma_texts2)\n","        ]\n","\n","        # Calculate differences\n","        result_df['meteor_difference'] = result_df['lemma_meteor_score'] - result_df['raw_meteor_score']\n","        result_df['meteor_frag_difference'] = result_df['lemma_meteor_frag'] - result_df['raw_meteor_score']\n","        result_df['meteor_prec_difference'] = result_df['lemma_meteor_prec'] - result_df['raw_meteor_score']\n","\n","        # Set the main meteor_score to the standard lemmatized version\n","        result_df['meteor_score'] = result_df['lemma_meteor_score']\n","\n","        print(\"METEOR scores calculated successfully with Slovenian lemmatization\")\n","    except Exception as e:\n","        print(f\"Failed to calculate METEOR scores: {e}\")\n","        print(\"Using simplified METEOR approximation\")\n","        # Fallback to the simple approximation\n","        result_df['meteor_score'] = result_df['jaccard_similarity'] * 0.8\n","\n","    print(f\"Calculated linguistic metrics for {len(result_df)} rows\")\n","\n","    return result_df\n","\n","def ensemble_scoring_spark(spark, df):\n","    \"\"\"\n","    Apply ensemble scoring using Spark.\n","\n","    Args:\n","        spark: SparkSession instance\n","        df: Pandas DataFrame with various similarity metrics\n","\n","    Returns:\n","        Pandas DataFrame with ensemble scores and classifications\n","    \"\"\"\n","    # First, keep track of columns we need to preserve\n","    all_columns = df.columns.tolist()\n","    meteor_columns = [col for col in all_columns if 'meteor' in col.lower()]\n","    lemma_columns = [col for col in all_columns if 'lemma_text' in col]\n","    preserve_columns = meteor_columns + lemma_columns\n","\n","    print(f\"Columns to preserve: {preserve_columns}\")\n","\n","    # Store these columns before Spark conversion\n","    preserved_data = {}\n","    for col in preserve_columns:\n","        if col in df.columns:\n","            preserved_data[col] = df[col].tolist()\n","\n","    # Convert to Spark DataFrame - potentially losing special columns\n","    spark_df = spark.createDataFrame(df)\n","\n","    # Available metrics (check which columns exist)\n","    available_metrics = []\n","    weights = {}\n","\n","    if 'labse_similarity' in df.columns:\n","        available_metrics.append('labse_similarity')\n","        weights['labse_similarity'] = 0.4\n","\n","    if 'laser_similarity' in df.columns:\n","        available_metrics.append('laser_similarity')\n","        weights['laser_similarity'] = 0.3\n","\n","    if 'meteor_score' in df.columns:\n","        available_metrics.append('meteor_score')\n","        weights['meteor_score'] = 0.1\n","\n","    if 'length_ratio' in df.columns:\n","        available_metrics.append('length_ratio')\n","        weights['length_ratio'] = 0.1\n","\n","    if 'jaccard_similarity' in df.columns:\n","        available_metrics.append('jaccard_similarity')\n","        weights['jaccard_similarity'] = 0.1\n","\n","    # If no metrics available, add simple fallback\n","    if not available_metrics:\n","        print(\"No metrics available for ensemble scoring, using fallback\")\n","        spark_df = spark_df.withColumn('ensemble_score', lit(0.5))\n","        spark_df = spark_df.withColumn('is_paraphrase', lit(False))\n","        return spark_df.toPandas()\n","\n","    # Normalize weights to sum to 1\n","    total_weight = sum(weights.values())\n","    normalized_weights = {k: v/total_weight for k, v in weights.items()}\n","\n","    # Calculate weighted score\n","    ensemble_expr = None\n","    for metric in available_metrics:\n","        weight = normalized_weights[metric]\n","        if ensemble_expr is None:\n","            ensemble_expr = col(metric) * weight\n","        else:\n","            ensemble_expr = ensemble_expr + (col(metric) * weight)\n","\n","    spark_df = spark_df.withColumn('ensemble_score', ensemble_expr)\n","\n","    # Classify pairs\n","    spark_df = spark_df.withColumn('is_paraphrase', col('ensemble_score') > 0.75)\n","\n","    print(f\"Using {len(available_metrics)} metrics for ensemble scoring with weights: {normalized_weights}\")\n","\n","# Convert back to pandas\n","    result_df = spark_df.toPandas()\n","\n","    # Restore preserved columns\n","    for col, data in preserved_data.items():\n","        result_df[col] = data\n","\n","    print(f\"Final columns after ensemble scoring: {result_df.columns.tolist()}\")\n","    return result_df\n","\n","\n","def calculate_metrics_fallback(df, text_col1, text_col2, device):\n","    \"\"\"\n","    Fallback method for calculating metrics when Spark processing fails.\n","    This uses the original code's approach but with improved error handling.\n","\n","    Args:\n","        df: Pandas DataFrame with normalized text columns\n","        text_col1, text_col2: Names of the text columns to compare\n","        device: Torch device to use for calculations\n","\n","    Returns:\n","        Pandas DataFrame with metrics added\n","    \"\"\"\n","    import torch\n","    import numpy as np\n","    from tqdm.auto import tqdm\n","    import time\n","\n","    print(\"Using fallback calculation method...\")\n","    results = df.copy()\n","\n","    # Define safe batch size\n","    batch_size = 8  # Smaller batch size for safety\n","\n","    # Try to load models with multiple retries\n","    max_retries = 3\n","\n","    # LaBSE loading with retries\n","    for attempt in range(max_retries):\n","        try:\n","            print(f\"Loading LaBSE model (attempt {attempt+1}/{max_retries})...\")\n","            from transformers import AutoTokenizer, AutoModel\n","\n","            tokenizer = AutoTokenizer.from_pretrained(\"setu4993/LaBSE\")\n","            model = AutoModel.from_pretrained(\"setu4993/LaBSE\").to(device)\n","            print(\"LaBSE model loaded successfully\")\n","            break\n","        except Exception as e:\n","            print(f\"LaBSE loading attempt {attempt+1} failed: {e}\")\n","            if attempt == max_retries - 1:\n","                print(\"Could not load LaBSE model, will use simpler metrics\")\n","                model = None\n","                tokenizer = None\n","            time.sleep(2)  # Wait before retrying\n","\n","    # Sentence transformer loading with retries\n","    for attempt in range(max_retries):\n","        try:\n","            print(f\"Loading sentence-transformers model (attempt {attempt+1}/{max_retries})...\")\n","            from sentence_transformers import SentenceTransformer\n","            st_model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')\n","            if torch.cuda.is_available():\n","                st_model = st_model.to(device)\n","            print(\"Sentence-Transformer model loaded successfully\")\n","            break\n","        except Exception as e:\n","            print(f\"Sentence-Transformer loading attempt {attempt+1} failed: {e}\")\n","            if attempt == max_retries - 1:\n","                print(\"Could not load Sentence-Transformer model, will use simpler metrics\")\n","                st_model = None\n","            time.sleep(2)  # Wait before retrying\n","\n","    # Prepare data\n","    texts1 = df[text_col1].tolist()\n","    texts2 = df[text_col2].tolist()\n","\n","    # Initialize results containers\n","    labse_scores = np.zeros(len(df))\n","    st_scores = np.zeros(len(df))\n","\n","    # LaBSE scoring function with better error handling\n","    def get_labse_similarity_safe(batch_texts1, batch_texts2):\n","        try:\n","            if tokenizer is None or model is None:\n","                return np.array([0.5] * len(batch_texts1))\n","\n","            # Tokenize\n","            inputs1 = tokenizer(batch_texts1, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n","            inputs2 = tokenizer(batch_texts2, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n","\n","            # Get embeddings\n","            with torch.no_grad():\n","                embeddings1 = model(**inputs1).pooler_output\n","                embeddings2 = model(**inputs2).pooler_output\n","\n","                # Normalize\n","                embeddings1 = torch.nn.functional.normalize(embeddings1, p=2, dim=1)\n","                embeddings2 = torch.nn.functional.normalize(embeddings2, p=2, dim=1)\n","\n","                # Calculate cosine similarity\n","                similarities = torch.bmm(\n","                    embeddings1.unsqueeze(1),\n","                    embeddings2.unsqueeze(2)\n","                ).squeeze().cpu().numpy()\n","\n","            return similarities\n","        except Exception as e:\n","            print(f\"Error in LaBSE similarity calculation: {e}\")\n","            return np.array([0.5] * len(batch_texts1))  # Fallback to neutral score\n","\n","    # Sentence-transformers scoring with better error handling\n","    def get_st_similarity_safe(batch_texts1, batch_texts2):\n","        try:\n","            if st_model is None:\n","                return np.array([0.5] * len(batch_texts1))\n","\n","            # Get embeddings\n","            with torch.no_grad():\n","                embeddings1 = st_model.encode(batch_texts1, convert_to_tensor=True)\n","                embeddings2 = st_model.encode(batch_texts2, convert_to_tensor=True)\n","\n","                # Calculate cosine similarities\n","                similarities = []\n","                for i in range(len(batch_texts1)):\n","                    try:\n","                        emb1 = embeddings1[i].unsqueeze(0)\n","                        emb2 = embeddings2[i].unsqueeze(0)\n","                        sim = torch.nn.functional.cosine_similarity(emb1, emb2).item()\n","                        similarities.append(sim)\n","                    except Exception as e:\n","                        print(f\"Error calculating similarity for item {i}: {e}\")\n","                        similarities.append(0.5)  # Fallback\n","\n","            return np.array(similarities)\n","        except Exception as e:\n","            print(f\"Error in Sentence-Transformer similarity calculation: {e}\")\n","            return np.array([0.5] * len(batch_texts1))  # Fallback to neutral score\n","\n","    # Jaccard similarity as a fallback\n","    def jaccard_similarity(text1, text2):\n","        if not isinstance(text1, str):\n","            text1 = \"\"\n","        if not isinstance(text2, str):\n","            text2 = \"\"\n","\n","        words1 = set(text1.lower().split())\n","        words2 = set(text2.lower().split())\n","\n","        if not words1 and not words2:\n","            return 1.0\n","\n","        intersection = len(words1.intersection(words2))\n","        union = len(words1.union(words2))\n","\n","        return intersection / union if union > 0 else 0\n","\n","    # Length ratio\n","    def calc_length_ratio(text1, text2):\n","        if not isinstance(text1, str):\n","            text1 = \"\"\n","        if not isinstance(text2, str):\n","            text2 = \"\"\n","\n","        len1 = len(text1.split())\n","        len2 = len(text2.split())\n","\n","        return min(len1, len2) / max(len1, len2) if max(len1, len2) > 0 else 0\n","\n","    # Process in batches with progress bar\n","    for i in tqdm(range(0, len(df), batch_size), desc=\"Calculating metrics (fallback method)\"):\n","        end_idx = min(i + batch_size, len(df))\n","        batch_texts1 = texts1[i:end_idx]\n","        batch_texts2 = texts2[i:end_idx]\n","\n","        # Calculate and store similarities\n","        labse_scores[i:end_idx] = get_labse_similarity_safe(batch_texts1, batch_texts2)\n","        st_scores[i:end_idx] = get_st_similarity_safe(batch_texts1, batch_texts2)\n","\n","    # Add scores to dataframe\n","    results['labse_similarity'] = labse_scores\n","    results['laser_similarity'] = st_scores  # We use sentence-transformers instead of LASER\n","\n","    # Calculate Jaccard similarity for each pair\n","    print(\"Calculating Jaccard similarity...\")\n","    results['jaccard_similarity'] = [\n","        jaccard_similarity(t1, t2) for t1, t2 in zip(texts1, texts2)\n","    ]\n","\n","    # Calculate length ratio\n","    print(\"Calculating length ratio...\")\n","    results['length_ratio'] = [\n","        calc_length_ratio(t1, t2) for t1, t2 in zip(texts1, texts2)\n","    ]\n","\n","    # Add placeholder for METEOR (approximated)\n","    results['meteor_score'] = results['jaccard_similarity'] * 0.8\n","\n","    return results\n","\n","\n","def run_paraphrase_pipeline_spark(input_file, text_col1, text_col2, output_file, spark_master=None, clean_metadata=True):\n","    \"\"\"\n","    Run the paraphrase analysis pipeline using Spark for distributed processing.\n","\n","    Args:\n","        input_file: Path to the input file (Excel or CSV)\n","        text_col1, text_col2: Names of the text columns to compare\n","        output_file: Path to save the output CSV\n","        spark_master: Optional Spark master URL (e.g., 'local[*]', 'spark://host:port')\n","        clean_metadata: Whether to perform metadata cleaning (default: True)\n","\n","    Returns:\n","        Pandas DataFrame with analysis results\n","    \"\"\"\n","    import os\n","    start_time = time.time()\n","    print(f\"Starting Spark-powered paraphrase analysis pipeline at {time.strftime('%H:%M:%S')}\")\n","\n","    spark = None\n","\n","    # Flag to track if we're using Spark or fallback\n","    using_spark = True\n","    device = None\n","\n","    try:\n","        # Initialize Spark\n","        spark, device_broadcast = initialize_spark(\n","            app_name=\"ParaphraseAnalysis\",\n","            master=spark_master\n","        )\n","\n","        # Get device from broadcast\n","        device_info = device_broadcast.value\n","        device = torch.device(device_info[\"name\"])\n","\n","        # Load data\n","        print(f\"Loading data from {input_file}\")\n","\n","        # Check file extension to determine how to read the file\n","        file_ext = os.path.splitext(input_file)[1].lower()\n","\n","        if file_ext == '.xlsx' or file_ext == '.xls':\n","            try:\n","                # Try with openpyxl engine first (newer xlsx files)\n","                df = pd.read_excel(input_file, engine='openpyxl')\n","                print(\"Successfully read Excel file with openpyxl engine\")\n","            except Exception as e1:\n","                print(f\"Failed with openpyxl engine: {e1}\")\n","                try:\n","                    # Try with xlrd engine (older xls files)\n","                    df = pd.read_excel(input_file, engine='xlrd')\n","                    print(\"Successfully read Excel file with xlrd engine\")\n","                except Exception as e2:\n","                    print(f\"Could not read Excel file with any available engine: {e2}\")\n","                    raise ValueError(f\"Cannot read Excel file {input_file}. Try converting to CSV first.\")\n","        else:\n","            # Assume CSV for all other extensions\n","            print(f\"Reading as CSV file (extension: {file_ext})\")\n","            df = pd.read_csv(input_file)\n","            print(f\"Successfully read CSV with {len(df)} rows and columns: {df.columns.tolist()}\")\n","\n","        print(f\"Loaded {len(df)} sentence pairs\")\n","\n","        # Preprocessing with Spark\n","        try:\n","            print(\"Preprocessing data with Spark...\")\n","            df = preprocess_with_spark(spark, df, text_col1, text_col2)\n","        except Exception as e:\n","            print(f\"Spark preprocessing failed: {e}\")\n","            print(\"Using fallback preprocessing method...\")\n","\n","            # Fallback to non-Spark preprocessing\n","            def normalize_text(text):\n","                if not isinstance(text, str):\n","                    return \"\"\n","                return text.lower().strip()\n","\n","            df[f\"norm_{text_col1}\"] = df[text_col1].apply(normalize_text)\n","            df[f\"norm_{text_col2}\"] = df[text_col2].apply(normalize_text)\n","\n","        # Save intermediate preprocessing results\n","        intermediate_file = output_file.replace('.csv', '_preprocessed.csv')\n","        df.to_csv(intermediate_file, index=False)\n","        print(f\"Saved preprocessed data to {intermediate_file}\")\n","\n","        # Try Spark embedding metrics calculation\n","        try:\n","            print(\"Calculating embedding metrics with Spark...\")\n","            df = calculate_embedding_metrics_spark(\n","                spark,\n","                df,\n","                f\"norm_{text_col1}\",\n","                f\"norm_{text_col2}\",\n","                device_broadcast\n","            )\n","        except Exception as e:\n","            print(f\"Spark embedding calculation failed: {e}\")\n","            using_spark = False\n","\n","            # Fall back to non-Spark method\n","            print(\"Falling back to non-Spark embedding calculation...\")\n","            df = calculate_metrics_fallback(\n","                df,\n","                f\"norm_{text_col1}\",\n","                f\"norm_{text_col2}\",\n","                device\n","            )\n","\n","        # Save embedding results\n","        embedding_file = output_file.replace('.csv', '_embeddings.csv')\n","        df.to_csv(embedding_file, index=False)\n","        print(f\"Saved embedding results to {embedding_file}\")\n","\n","        # Try Spark linguistic metrics calculation if we're still using Spark\n","        if using_spark:\n","            try:\n","                print(\"Calculating linguistic metrics with Spark...\")\n","                df = calculate_linguistic_metrics_spark(\n","                    spark,\n","                    df,\n","                    f\"norm_{text_col1}\",\n","                    f\"norm_{text_col2}\"\n","                )\n","            except Exception as e:\n","                print(f\"Spark linguistic metrics calculation failed: {e}\")\n","                # We already have basic metrics from the previous step\n","                print(\"Using metrics from previous step...\")\n","                using_spark = False\n","\n","            # Save linguistic results\n","            linguistic_file = output_file.replace('.csv', '_linguistic.csv')\n","            df.to_csv(linguistic_file, index=False)\n","            print(f\"Saved linguistic analysis to {linguistic_file}\")\n","\n","        # Ensemble scoring - this is simple enough to run without Spark if needed\n","        print(\"Ensemble scoring...\")\n","\n","        try:\n","            df = ensemble_scoring_spark(spark, df)\n","        except Exception as e:\n","            # Modified: No fallback to ensemble_scoring_modified\n","            print(f\"Ensemble scoring failed: {e}\")\n","            print(\"WARNING: Ensemble scoring could not be completed. Results may be incomplete.\")\n","\n","        # Save final results\n","        print(f\"Saving final results to {output_file}\")\n","        df.to_csv(output_file, index=False)\n","\n","        # Visualization (optional)\n","        try:\n","            print(\"Generating visualizations...\")\n","\n","            # Create a visualizations directory if it doesn't exist\n","            viz_dir = os.path.join(os.path.dirname(output_file), \"visualizations\")\n","            os.makedirs(viz_dir, exist_ok=True)\n","\n","            # Use the functions defined in this module\n","            visualize_results(df, viz_dir)\n","\n","            # Only try grammar-specific visualizations if we have those metrics\n","            if any(col in df.columns for col in ['morph_similarity', 'grammar_mismatch', 'meteor_difference']):\n","                visualize_grammatical_metrics(df, viz_dir)\n","\n","            print(f\"Visualizations saved to {viz_dir}\")\n","        except Exception as e:\n","            print(f\"Visualization error: {e}\")\n","            print(\"Skipping visualization step. Error details:\")\n","            import traceback\n","            traceback.print_exc()\n","\n","        elapsed_time = time.time() - start_time\n","        print(f\"Pipeline completed in {elapsed_time:.2f} seconds\")\n","\n","        return df\n","\n","    except Exception as e:\n","        # Catch any unhandled exceptions\n","        elapsed_time = time.time() - start_time\n","        print(f\"Pipeline failed after {elapsed_time:.2f} seconds\")\n","        print(f\"Critical error: {e}\")\n","\n","        # Print exception traceback for debugging\n","        import traceback\n","        traceback.print_exc()\n","\n","        return None\n","\n","    finally:\n","        # Always shut down Spark\n","        if spark:\n","            shutdown_spark(spark)"],"metadata":{"id":"mpA2zOcWEZw3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    # Define base directory - Update this to your actual location\n","    base_dir = \"/content/drive/MyDrive/Colab Notebooks/preprocessed_datasets\"\n","\n","    # Dataset name - change this to switch between datasets\n","    #dataset = \"predprocesiranje_msr_paired_cleaned\"\n","    #dataset = \"paranmt_small_translated_cleaned_00\"\n","    #dataset = \"processed_quora_clean_00\"\n","    dataset =\n","\n","    # Construct paths using f-strings\n","    input_file = f\"{base_dir}/{dataset}.xlsx\"\n","    output_file = f\"{base_dir}/paraphrase_analysis_results_{dataset.split('_')[0]}_{dataset}.csv\"\n","\n","    # Column names\n","    text_col1 = \"sentence_translation\"\n","    text_col2 = \"paraphrase_translation\"\n","\n","    # Spark configuration\n","    spark_config = {\n","        'master': 'local[4]',\n","        'use_fallback_early': False\n","    }\n","\n","    # Processing flags\n","    add_metadata = True\n","    filter_dataset = True\n","\n","    # The simplest approach: Convert Excel to CSV first, then use the CSV\n","    print(f\"Converting Excel file to CSV for better compatibility...\")\n","    import pandas as pd\n","\n","    # Read Excel with explicit engine specification\n","    try:\n","        # Try with openpyxl engine (for newer .xlsx files)\n","        df = pd.read_excel(input_file, engine='openpyxl')\n","    except Exception as e1:\n","        print(f\"Failed with openpyxl engine: {e1}\")\n","        try:\n","            # Try with xlrd engine (for older .xls files)\n","            df = pd.read_excel(input_file, engine='xlrd')\n","        except Exception as e2:\n","            print(f\"Failed with xlrd engine: {e2}\")\n","            raise Exception(\"Could not read Excel file with any available engine\")\n","\n","    # Save as CSV\n","    csv_file = input_file.replace('.xlsx', '.csv')\n","    df.to_csv(csv_file, index=False)\n","    print(f\"Successfully converted Excel to CSV: {csv_file}\")\n","\n","    # Run the pipeline with the CSV file\n","    results = run_paraphrase_pipeline_spark(\n","        csv_file,  # Use the CSV file we just created\n","        text_col1,\n","        text_col2,\n","        output_file,\n","        spark_master=spark_config['master']\n","    )\n","\n","    print(\"Pipeline execution complete.\")\n","\n","    # Rest of the code remains the same...\n","    # Add metadata and filter dataset if requested\n","    if results is not None and (add_metadata or filter_dataset):\n","        try:\n","            # Import the filtering module\n","            try:\n","                from filtering_metadata import add_metadata_and_filter, export_with_metadata\n","                filtering_module_found = True\n","            except ImportError:\n","                print(\"Filtering module not found. Using local implementation.\")\n","                filtering_module_found = False\n","\n","            if not filtering_module_found:\n","                # Local implementation of filtering and metadata functions\n","                def add_metadata_and_filter(df, text_col1, text_col2, min_similarity_threshold=0.1):\n","                    import Levenshtein\n","                    import re\n","\n","                    print(f\"\\nAdding metadata and filtering dataset with {len(df)} pairs...\")\n","                    print(f\"Input columns: {df.columns.tolist()}\")  # Debug: print incoming columns\n","\n","                    # Create a true copy of the original dataframe\n","                    results = df.copy(deep=True)\n","\n","                    # Extract the normalized text columns\n","                    norm_col1 = f\"norm_{text_col1}\" if f\"norm_{text_col1}\" in df.columns else text_col1\n","                    norm_col2 = f\"norm_{text_col2}\" if f\"norm_{text_col2}\" in df.columns else text_col2\n","\n","                    # Add length metadata\n","                    results['length_s1'] = results[norm_col1].apply(lambda x: len(str(x).split()))\n","                    results['length_s2'] = results[norm_col2].apply(lambda x: len(str(x).split()))\n","\n","                    # Compute string similarity if not present\n","                    if 'string_similarity' not in results.columns:\n","                        results['string_similarity'] = [\n","                            1 - (Levenshtein.distance(str(s1), str(s2)) / max(len(str(s1)), len(str(s2)), 1))\n","                            for s1, s2 in zip(results[norm_col1], results[norm_col2])\n","                        ]\n","\n","                    # Detect identical sentences\n","                    results['is_identical'] = (results['string_similarity'] > 0.99) | (results[norm_col1] == results[norm_col2])\n","                    identical_count = results['is_identical'].sum()\n","                    print(f\"Found {identical_count} identical pairs ({identical_count/len(results)*100:.2f}%)\")\n","\n","                    # Filter out identical sentences\n","                    if filter_dataset:\n","                        before_count = len(results)\n","                        results_filtered = results[~results['is_identical']]\n","                        identical_removed = before_count - len(results_filtered)\n","                        print(f\"Removed {identical_removed} identical sentence pairs\")\n","                    else:\n","                        results_filtered = results\n","\n","                        # Debug: print columns before returning\n","                    print(f\"Columns after metadata: {results.columns.tolist()}\")\n","                    print(f\"METEOR columns: {[col for col in results.columns if 'meteor' in col.lower()]}\")\n","\n","\n","                    return {\n","                        'full_data': results,\n","                        'filtered_data': results_filtered\n","                    }\n","\n","                def export_with_metadata(result_dict, output_prefix):\n","                    # Export full dataset with metadata\n","                    full_output = f\"{output_prefix}_with_metadata.csv\"\n","                    result_dict['full_data'].to_csv(full_output, index=False)\n","                    print(f\"Full dataset with metadata saved to {full_output}\")\n","\n","                    # Export filtered dataset\n","                    filtered_output = f\"{output_prefix}_filtered.csv\"\n","                    result_dict['filtered_data'].to_csv(filtered_output, index=False)\n","                    print(f\"Filtered dataset saved to {filtered_output}\")\n","\n","            # Apply metadata and filtering\n","            print(\"\\nEnhancing dataset with metadata and filtering...\")\n","            result_dict = add_metadata_and_filter(\n","                results,\n","                text_col1=text_col1,\n","                text_col2=text_col2,\n","                min_similarity_threshold=0.1\n","            )\n","\n","            # Export the results\n","            metadata_prefix = output_file.replace('.csv', '')\n","            export_with_metadata(result_dict, metadata_prefix)\n","\n","            # Use the filtered dataset for analysis\n","            results_for_analysis = result_dict['filtered_data'] if filter_dataset else result_dict['full_data']\n","\n","        except Exception as e:\n","            print(f\"Warning: Could not add metadata or filter dataset: {e}\")\n","            import traceback\n","            traceback.print_exc()\n","            # Continue with original results\n","            results_for_analysis = results\n","    else:\n","        results_for_analysis = results\n","\n","    # Analyze the results\n","    if results_for_analysis is not None:\n","        try:\n","            # Import the analysis function\n","            try:\n","                from analysis_utils import analyze_paraphrase_results\n","                analysis_module_found = True\n","            except ImportError:\n","                print(\"Analysis module not found. Using local implementation.\")\n","                analysis_module_found = False\n","\n","            print(\"\\nAnalyzing results...\")\n","            analysis_dir = os.path.join(os.path.dirname(output_file), \"analysis\")\n","            os.makedirs(analysis_dir, exist_ok=True)\n","\n","            if analysis_module_found:\n","                stats = analyze_paraphrase_results(results_for_analysis, analysis_dir)\n","            else:\n","                # Use the visualization functions we already have\n","                visualize_results(results_for_analysis, analysis_dir)\n","                stats = {}  # Empty stats as fallback\n","\n","            print(\"Analysis complete.\")\n","\n","            # Save statistics as JSON for later reference\n","            import json\n","            try:\n","                # Convert stats to JSON-serializable format (handle numpy types)\n","                def convert_for_json(obj):\n","                    if isinstance(obj, (np.int64, np.int32, np.int16, np.int8)):\n","                        return int(obj)\n","                    elif isinstance(obj, (np.float64, np.float32, np.float16)):\n","                        return float(obj)\n","                    raise TypeError(f\"Type {type(obj)} not serializable\")\n","\n","                stats_file = os.path.join(analysis_dir, \"statistics.json\")\n","                with open(stats_file, 'w') as f:\n","                    json.dump(stats, f, indent=2, default=convert_for_json)\n","                print(f\"Statistics saved to {stats_file}\")\n","            except Exception as e:\n","                print(f\"Warning: Could not save statistics as JSON: {e}\")\n","\n","            # Compare with previous results if available\n","            original_results_file = os.path.join(base_dir, \"original_paraphrase_results.csv\")\n","            if os.path.exists(original_results_file):\n","                try:\n","                    from analysis_utils import compare_pipeline_results\n","\n","                    print(\"\\nComparing with original implementation results...\")\n","                    original_df = pd.read_csv(original_results_file)\n","\n","                    comparison_dir = os.path.join(os.path.dirname(output_file), \"comparison\")\n","                    os.makedirs(comparison_dir, exist_ok=True)\n","\n","                    comparison = compare_pipeline_results(original_df, results_for_analysis, comparison_dir)\n","                    print(\"Comparison complete.\")\n","                except Exception as e:\n","                    print(f\"Warning: Could not compare with original results: {e}\")\n","                    import traceback\n","                    traceback.print_exc()\n","        except Exception as e:\n","            print(f\"Warning: Could not analyze results: {e}\")\n","            import traceback\n","            traceback.print_exc()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jtcBAEuC57P0","executionInfo":{"status":"ok","timestamp":1742810937708,"user_tz":-60,"elapsed":125897,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"33084f5a-a51f-4f85-9d69-775b1af256b1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Converting Excel file to CSV for better compatibility...\n","Successfully converted Excel to CSV: /content/drive/MyDrive/Colab Notebooks/preprocessed_datasets/predprocesiranje_msr_paired_cleaned.csv\n","Starting Spark-powered paraphrase analysis pipeline at 10:06:56\n","Initialized Spark with cuda device: Tesla T4\n","Loading data from /content/drive/MyDrive/Colab Notebooks/preprocessed_datasets/predprocesiranje_msr_paired_cleaned.csv\n","Reading as CSV file (extension: .csv)\n","Successfully read CSV with 4798 rows and columns: ['sentence_translation', 'paraphrase_translation']\n","Loaded 4798 sentence pairs\n","Preprocessing data with Spark...\n","Preprocessed 4798 rows using Spark\n","Saved preprocessed data to /content/drive/MyDrive/Colab Notebooks/preprocessed_datasets/paraphrase_analysis_results_predprocesiranje_predprocesiranje_msr_paired_cleaned_preprocessed.csv\n","Calculating embedding metrics with Spark...\n","Calculating LaBSE similarities...\n","Calculating Sentence-Transformer similarities...\n","Calculated embedding metrics for 4798 rows using Spark\n","Saved embedding results to /content/drive/MyDrive/Colab Notebooks/preprocessed_datasets/paraphrase_analysis_results_predprocesiranje_predprocesiranje_msr_paired_cleaned_embeddings.csv\n","Calculating linguistic metrics with Spark...\n","Calculating linguistic metrics with Spark...\n","Calculated linguistic metrics for 4798 rows using Spark\n","Failed to calculate METEOR scores: No module named 'classla'\n","Using simplified METEOR approximation\n","Calculated linguistic metrics for 4798 rows\n","Saved linguistic analysis to /content/drive/MyDrive/Colab Notebooks/preprocessed_datasets/paraphrase_analysis_results_predprocesiranje_predprocesiranje_msr_paired_cleaned_linguistic.csv\n","Ensemble scoring...\n","Columns to preserve: ['meteor_score']\n","Ensemble scoring failed: 'str' object is not callable\n","WARNING: Ensemble scoring could not be completed. Results may be incomplete.\n","Saving final results to /content/drive/MyDrive/Colab Notebooks/preprocessed_datasets/paraphrase_analysis_results_predprocesiranje_predprocesiranje_msr_paired_cleaned.csv\n","Generating visualizations...\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-2-2b4697eacaac>:97: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n","  scatter = plt.scatter(\n"]},{"output_type":"stream","name":"stdout","text":["Basic visualizations saved to /content/drive/MyDrive/Colab Notebooks/preprocessed_datasets/visualizations\n","Visualizations saved to /content/drive/MyDrive/Colab Notebooks/preprocessed_datasets/visualizations\n","Spark session stopped\n","Pipeline execution complete.\n"]}]},{"cell_type":"markdown","source":["#### Filtering and Metadata for Paraphrase Pipeline"],"metadata":{"id":"xmSpvXmqEaup"}},{"cell_type":"code","source":["\"\"\"\n","Filtering and metadata enhancement for the paraphrase analysis pipeline.\n","This module provides functions to filter out noisy pairs and add useful metadata.\n","\"\"\"\n","\n","import pandas as pd\n","import numpy as np\n","from tqdm.auto import tqdm\n","import Levenshtein\n","import re\n","\n","\n","def add_metadata_and_filter(df, text_col1, text_col2, min_similarity_threshold=0.1):\n","    \"\"\"\n","    Add useful metadata to the paraphrase dataset and filter out noisy pairs.\n","\n","    Args:\n","        df: DataFrame containing paraphrase analysis results\n","        text_col1, text_col2: Names of the text columns to analyze\n","        min_similarity_threshold: Minimum similarity threshold for keeping pairs\n","\n","    Returns:\n","        DataFrame with added metadata and filtered pairs\n","    \"\"\"\n","    print(f\"\\nAdding metadata and filtering dataset with {len(df)} pairs...\")\n","    results = df.copy()\n","\n","    # Extract the normalized text columns\n","    norm_col1 = f\"norm_{text_col1}\" if f\"norm_{text_col1}\" in df.columns else text_col1\n","    norm_col2 = f\"norm_{text_col2}\" if f\"norm_{text_col2}\" in df.columns else text_col2\n","\n","    # 1. Add basic length metadata\n","    print(\"Adding length metadata...\")\n","    results['length_s1'] = results[norm_col1].apply(lambda x: len(str(x).split()))\n","    results['length_s2'] = results[norm_col2].apply(lambda x: len(str(x).split()))\n","    results['length_ratio'] = results.apply(\n","        lambda x: min(x['length_s1'], x['length_s2']) / max(x['length_s1'], x['length_s2'])\n","        if max(x['length_s1'], x['length_s2']) > 0 else 1.0,\n","        axis=1\n","    )\n","    results['char_length_s1'] = results[norm_col1].apply(lambda x: len(str(x)))\n","    results['char_length_s2'] = results[norm_col2].apply(lambda x: len(str(x)))\n","\n","    # 2. Add string similarity metadata if not already present\n","    if 'string_similarity' not in results.columns:\n","        print(\"Computing string similarity...\")\n","        results['string_similarity'] = [\n","            1 - (Levenshtein.distance(str(s1), str(s2)) / max(len(str(s1)), len(str(s2)), 1))\n","            for s1, s2 in tqdm(zip(results[norm_col1], results[norm_col2]), total=len(results))\n","        ]\n","\n","    # 3. Detect identical sentences\n","    print(\"Identifying identical sentences...\")\n","    results['is_identical'] = (results['string_similarity'] > 0.99) | (results[norm_col1] == results[norm_col2])\n","    identical_count = results['is_identical'].sum()\n","    print(f\"Found {identical_count} identical pairs ({identical_count/len(results)*100:.2f}%)\")\n","\n","    # 4. Add confidence score for classification\n","    print(\"Computing classification confidence...\")\n","    if 'ensemble_score' in results.columns:\n","        # How far from the decision threshold (0.75)\n","        results['classification_confidence'] = results['ensemble_score'].apply(\n","            lambda x: abs(x - 0.75) / 0.25  # Normalize to [0,1] range\n","        ).clip(0, 1)  # Clip to ensure range [0,1]\n","\n","    # 5. Add linguistic complexity metadata\n","    print(\"Adding linguistic complexity metadata...\")\n","    # Simple readability approximation (average word length)\n","    results['avg_word_length_s1'] = results[norm_col1].apply(\n","        lambda x: np.mean([len(w) for w in str(x).split()]) if len(str(x).split()) > 0 else 0\n","    )\n","    results['avg_word_length_s2'] = results[norm_col2].apply(\n","        lambda x: np.mean([len(w) for w in str(x).split()]) if len(str(x).split()) > 0 else 0\n","    )\n","\n","    # 6. Check for malformed content\n","    print(\"Checking for malformed content...\")\n","    html_pattern = re.compile(r'<[^>]+>')\n","    results['has_html_s1'] = results[text_col1].apply(\n","        lambda x: bool(html_pattern.search(str(x)))\n","    )\n","    results['has_html_s2'] = results[text_col2].apply(\n","        lambda x: bool(html_pattern.search(str(x)))\n","    )\n","\n","    # Add potential encoding issues flag\n","    def has_encoding_issues(text):\n","        # Check for common encoding issue patterns\n","        strange_chars = sum(1 for c in str(text) if ord(c) > 127 and c not in 'čšžćđČŠŽĆĐ')\n","        return strange_chars > len(str(text)) * 0.1  # More than 10% strange characters\n","\n","    results['encoding_issues_s1'] = results[text_col1].apply(has_encoding_issues)\n","    results['encoding_issues_s2'] = results[text_col2].apply(has_encoding_issues)\n","\n","    # 7. Create a quality score combining multiple factors\n","    print(\"Computing overall quality score...\")\n","\n","    # Initialize quality with classification confidence if available\n","    if 'classification_confidence' in results.columns:\n","        results['quality_score'] = results['classification_confidence']\n","    else:\n","        # Start with middle value\n","        results['quality_score'] = 0.5\n","\n","    # Penalize for issues\n","    if 'has_html_s1' in results.columns:\n","        results.loc[results['has_html_s1'] | results['has_html_s2'], 'quality_score'] *= 0.7\n","\n","    if 'encoding_issues_s1' in results.columns:\n","        results.loc[results['encoding_issues_s1'] | results['encoding_issues_s2'], 'quality_score'] *= 0.7\n","\n","    # Extremely low similarity is suspicious\n","    min_similarity = results[['labse_similarity', 'laser_similarity', 'string_similarity']].min(axis=1)\n","    results.loc[min_similarity < min_similarity_threshold, 'quality_score'] *= 0.5\n","\n","    # 8. Filter out noisy pairs\n","    print(\"\\nFiltering dataset...\")\n","    # Filter out identical sentences\n","    before_count = len(results)\n","    results_filtered = results[~results['is_identical']]\n","    identical_removed = before_count - len(results_filtered)\n","    print(f\"Removed {identical_removed} identical sentence pairs\")\n","\n","    # Filter out malformed content\n","    before_count = len(results_filtered)\n","    results_filtered = results_filtered[\n","        ~(results_filtered['has_html_s1'] | results_filtered['has_html_s2'] |\n","          results_filtered['encoding_issues_s1'] | results_filtered['encoding_issues_s2'])\n","    ]\n","    malformed_removed = before_count - len(results_filtered)\n","    print(f\"Removed {malformed_removed} pairs with malformed content\")\n","\n","    # Filter out pairs with extremely low similarity (likely errors)\n","    before_count = len(results_filtered)\n","    results_filtered = results_filtered[\n","        results_filtered[['labse_similarity', 'laser_similarity']].min(axis=1) >= min_similarity_threshold\n","    ]\n","    low_similarity_removed = before_count - len(results_filtered)\n","    print(f\"Removed {low_similarity_removed} pairs with extremely low similarity\")\n","\n","    # 9. Final stats\n","    filtered_total = identical_removed + malformed_removed + low_similarity_removed\n","    filtered_percentage = (filtered_total / len(df)) * 100\n","\n","    print(f\"\\nFiltering complete:\")\n","    print(f\"Started with {len(df)} pairs\")\n","    print(f\"Filtered out {filtered_total} pairs ({filtered_percentage:.2f}%)\")\n","    print(f\"Final dataset has {len(results_filtered)} pairs\")\n","\n","    # Return both the full dataset with metadata and the filtered dataset\n","    return {\n","        'full_data': results,\n","        'filtered_data': results_filtered\n","    }\n","\n","\n","def export_with_metadata(result_dict, output_prefix):\n","    \"\"\"\n","    Export both the full and filtered datasets with metadata.\n","\n","    Args:\n","        result_dict: Dictionary with 'full_data' and 'filtered_data' keys\n","        output_prefix: Prefix for output filenames\n","    \"\"\"\n","    # Export full dataset with metadata\n","    full_output = f\"{output_prefix}_with_metadata.csv\"\n","    result_dict['full_data'].to_csv(full_output, index=False)\n","    print(f\"Full dataset with metadata saved to {full_output}\")\n","\n","    # Export filtered dataset\n","    filtered_output = f\"{output_prefix}_filtered.csv\"\n","    result_dict['filtered_data'].to_csv(filtered_output, index=False)\n","    print(f\"Filtered dataset saved to {filtered_output}\")\n","\n","    # Export metadata summary\n","    summary_df = pd.DataFrame({\n","        'Metric': ['Total pairs', 'Filtered pairs', 'Remaining pairs',\n","                  'Identical pairs', 'Pairs with HTML', 'Pairs with encoding issues',\n","                  'Pairs with very low similarity'],\n","        'Count': [\n","            len(result_dict['full_data']),\n","            len(result_dict['full_data']) - len(result_dict['filtered_data']),\n","            len(result_dict['filtered_data']),\n","            result_dict['full_data']['is_identical'].sum(),\n","            (result_dict['full_data']['has_html_s1'] | result_dict['full_data']['has_html_s2']).sum(),\n","            (result_dict['full_data']['encoding_issues_s1'] | result_dict['full_data']['encoding_issues_s2']).sum(),\n","            (result_dict['full_data'][['labse_similarity', 'laser_similarity']].min(axis=1) < 0.1).sum()\n","        ],\n","        'Percentage': [\n","            100.0,\n","            (len(result_dict['full_data']) - len(result_dict['filtered_data'])) / len(result_dict['full_data']) * 100,\n","            len(result_dict['filtered_data']) / len(result_dict['full_data']) * 100,\n","            result_dict['full_data']['is_identical'].sum() / len(result_dict['full_data']) * 100,\n","            (result_dict['full_data']['has_html_s1'] | result_dict['full_data']['has_html_s2']).sum() / len(result_dict['full_data']) * 100,\n","            (result_dict['full_data']['encoding_issues_s1'] | result_dict['full_data']['encoding_issues_s2']).sum() / len(result_dict['full_data']) * 100,\n","            (result_dict['full_data'][['labse_similarity', 'laser_similarity']].min(axis=1) < 0.1).sum() / len(result_dict['full_data']) * 100\n","        ]\n","    })\n","\n","    summary_output = f\"{output_prefix}_filtering_summary.csv\"\n","    summary_df.to_csv(summary_output, index=False)\n","    print(f\"Filtering summary saved to {summary_output}\")\n"],"metadata":{"id":"S8gWJEmKEzoI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Sample usage\n","if __name__ == \"__main__\":\n","    # Path to your paraphrase analysis results\n","    input_file = \"paraphrase_analysis_results.csv\"\n","\n","    # Load the data\n","    df = pd.read_csv(input_file)\n","\n","    # Add metadata and filter\n","    result_dict = add_metadata_and_filter(\n","        df,\n","        text_col1=\"sentence_translation\",\n","        text_col2=\"paraphrase_translation\",\n","        min_similarity_threshold=0.1\n","    )\n","\n","    # Export the results\n","    export_with_metadata(result_dict, \"paraphrase_dataset\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"VawFOAc3GHWR","executionInfo":{"status":"error","timestamp":1742199389427,"user_tz":-60,"elapsed":137,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"a51e1324-bf36-4bc3-cfee-aa1f0c499e0c"},"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'paraphrase_analysis_results.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-5777fb2a3b15>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Load the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Add metadata and filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'paraphrase_analysis_results.csv'"]}]},{"cell_type":"markdown","source":["#### is_paraphrase column added based on the metrics' weights"],"metadata":{"id":"FBvSHFhkNC13"}},{"cell_type":"code","source":["import pandas as pd\n","\n","if __name__ == \"__main__\":\n","    # Define base directory - Update this to your actual location\n","    base_dir = \"/content/drive/MyDrive/Colab Notebooks/preprocessed_datasets\"\n","\n","    # Dataset name - change this to switch between datasets\n","    #dataset = \"predprocesiranje_msr_paired_cleaned\"\n","    #dataset = \"paranmt_small_translated_cleaned_00\"\n","    #dataset = \"processed_quora_clean_00\"\n","    dataset = \"paws_nepodvojene_filtrirane_parafraze_00\"\n","\n","    input_file = f\"{base_dir}/paraphrase_analysis_results_{dataset.split('_')[0]}_{dataset}_with_metadata.csv\"\n","    output_file = input_file\n","\n","    df = pd.read_csv(input_file, sep='\\t')  # Added tab separator based on your data\n","    #, sep='\\t'\n","\n","    # Print column names to verify\n","    print(\"Columns in the dataset:\", df.columns)\n","\n","    # Define thresholds for determining good paraphrases\n","    thresholds = {\n","        'labse_similarity': 0.7,\n","        'laser_similarity': 0.7,\n","        'jaccard_similarity': 0.2,\n","        'meteor_score': 0.4,\n","        'length_ratio': (0.8, 1.2),\n","        'string_similarity': 0.4,\n","        'is_identical': False\n","    }\n","\n","    '''\n","    # Function to determine if a row is a good paraphrase\n","    def is_good_paraphrase(row):\n","        if (row['labse_similarity'] >= thresholds['labse_similarity'] and\n","            row['laser_similarity'] >= thresholds['laser_similarity'] and\n","            row['jaccard_similarity'] >= thresholds['jaccard_similarity'] and\n","            row['meteor_score'] >= thresholds['meteor_score'] and\n","            thresholds['length_ratio'][0] <= row['length_ratio'] <= thresholds['length_ratio'][1] and\n","            row['string_similarity'] >= thresholds['string_similarity'] and\n","            row['is_identical'] == thresholds['is_identical']):\n","            return True\n","        return False\n","    '''\n","\n","    def is_good_paraphrase_majority(row):\n","        conditions = [\n","            row['labse_similarity'] >= thresholds['labse_similarity'],\n","            row['laser_similarity'] >= thresholds['laser_similarity'],\n","            row['jaccard_similarity'] >= thresholds['jaccard_similarity'],\n","            row['meteor_score'] >= thresholds['meteor_score'],\n","            thresholds['length_ratio'][0] <= row['length_ratio'] <= thresholds['length_ratio'][1],\n","            row['string_similarity'] >= thresholds['string_similarity'],\n","            row['is_identical'] == thresholds['is_identical']\n","        ]\n","\n","        # Classify as paraphrase if majority of conditions are met\n","        return sum(conditions) >= 4  # 4 out of 7 conditions\n","\n","    # Apply the function to create the is_paraphrase column\n","    df['is_paraphrase'] = df.apply(is_good_paraphrase_majority, axis=1)\n","\n","    # Count the number of paraphrases\n","    total_pairs = len(df)\n","    paraphrase_count = df['is_paraphrase'].sum()\n","    paraphrase_percentage = (paraphrase_count / total_pairs) * 100\n","\n","    print(f\"\\nParaphrase Analysis Results:\")\n","    print(f\"Total sentence pairs: {total_pairs}\")\n","    print(f\"Identified paraphrases: {paraphrase_count} ({paraphrase_percentage:.2f}%)\")\n","    print(f\"Non-paraphrases: {total_pairs - paraphrase_count} ({100 - paraphrase_percentage:.2f}%)\")\n","\n","    # Overwrite the original file with the updated dataset\n","    df.to_csv(output_file, sep='\\t', index=False)\n","\n","    print(f\"\\nUpdated dataset saved to {output_file}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OgOJn2JnNL2g","executionInfo":{"status":"ok","timestamp":1742555556447,"user_tz":-60,"elapsed":2939,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"543e6edd-39f7-4858-8c03-c0f437ea2417"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Columns in the dataset: Index(['sentence_translation', 'paraphrase_translation',\n","       'norm_sentence_translation', 'norm_paraphrase_translation',\n","       'labse_similarity', 'laser_similarity', 'jaccard_similarity',\n","       'length_ratio', 'meteor_score', 'length_s1', 'length_s2',\n","       'string_similarity', 'is_identical'],\n","      dtype='object')\n","\n","Paraphrase Analysis Results:\n","Total sentence pairs: 29493\n","Identified paraphrases: 26796 (90.86%)\n","Non-paraphrases: 2697 (9.14%)\n","\n","Updated dataset saved to /content/drive/MyDrive/Colab Notebooks/preprocessed_datasets/paraphrase_analysis_results_paws_paws_nepodvojene_filtrirane_parafraze_00_with_metadata.csv\n"]}]},{"cell_type":"markdown","source":["# Final File"],"metadata":{"id":"r_UkNlkUD3NK"}},{"cell_type":"markdown","source":["#### README.md"],"metadata":{"id":"A-OSOdPAD7a9"}},{"cell_type":"code","source":["# readme file"],"metadata":{"id":"huPydCYq_Hn5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Pipeline with metrics (only one meteor calculation), visualizations, and spark integration"],"metadata":{"id":"-kyeulRnpPUQ"}},{"cell_type":"code","source":["\"\"\"\n","Apache Spark Integration for Paraphrase Analysis Pipeline\n","This module enhances the existing pipeline with distributed processing capabilities.\n","\"\"\"\n","\n","import os\n","import time\n","import pandas as pd\n","import numpy as np\n","from pyspark.sql import SparkSession\n","from pyspark.sql.types import *\n","from pyspark.sql.functions import col, udf, pandas_udf, lit\n","from pyspark import SparkFiles\n","import torch\n","from typing import Iterator, Tuple, List\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Define thresholds for paraphrase detection\n","PARAPHRASE_THRESHOLDS = {\n","    'labse_similarity': 0.5,\n","    'laser_similarity': 0.5,\n","    'jaccard_similarity': 0.2,\n","    'meteor_score': 0.3,\n","    'length_ratio': (0.6, 1.4),\n","    'string_similarity': 0.2,\n","    'is_identical': False\n","}\n","\n","# Visualization functions included directly in the main module\n","def visualize_results(df, output_dir='.', dataset_name=None):\n","    \"\"\"\n","    Create visualizations for the paraphrase analysis results.\n","\n","    Args:\n","        df: Pandas DataFrame with paraphrase analysis results\n","        output_dir: Directory to save the visualizations\n","        dataset_name: Name of the dataset to include in visualization titles\n","    \"\"\"\n","    # Create directory if it doesn't exist\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    # Set dataset prefix for titles\n","    dataset_prefix = f\"{dataset_name} - \" if dataset_name else \"\"\n","    # Set filename prefix for saved files\n","    file_prefix = f\"{dataset_name}_\" if dataset_name else \"\"\n","\n","    # Create figure with subplots\n","    metrics_to_plot = []\n","\n","    # Check which metrics are available\n","    for metric in ['labse_similarity', 'laser_similarity', 'meteor_score',\n","                   'length_ratio', 'jaccard_similarity', 'ensemble_score']:\n","        if metric in df.columns and not df[metric].isna().all():\n","            metrics_to_plot.append(metric)\n","\n","    if not metrics_to_plot:\n","        print(\"No metrics available for visualization\")\n","        return\n","\n","    # Calculate subplot grid dimensions\n","    n_metrics = len(metrics_to_plot)\n","    n_cols = min(3, n_metrics)\n","    n_rows = (n_metrics + n_cols - 1) // n_cols\n","\n","    # Create figure\n","    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 4*n_rows))\n","\n","    # Handle case with single subplot\n","    if n_metrics == 1:\n","        axes = np.array([axes])\n","\n","    # Flatten axes array for easy iteration\n","    if n_metrics > 1:\n","        axes = axes.flatten()\n","\n","    # Create histograms\n","    for i, metric in enumerate(metrics_to_plot):\n","        sns.histplot(df[metric], kde=True, ax=axes[i])\n","        axes[i].set_title(f'{dataset_prefix}Distribution of {metric}')\n","        axes[i].axvline(df[metric].mean(), color='r', linestyle='--')\n","\n","        # Add threshold line if applicable\n","        if metric in PARAPHRASE_THRESHOLDS and not isinstance(PARAPHRASE_THRESHOLDS[metric], tuple):\n","            axes[i].axvline(PARAPHRASE_THRESHOLDS[metric], color='g', linestyle='-.')\n","            axes[i].text(PARAPHRASE_THRESHOLDS[metric], 0, f'Threshold: {PARAPHRASE_THRESHOLDS[metric]}',\n","                       rotation=90, verticalalignment='bottom')\n","\n","    # Hide unused subplots\n","    for i in range(n_metrics, len(axes) if hasattr(axes, '__len__') else 0):\n","        axes[i].set_visible(False)\n","\n","    plt.tight_layout()\n","    plt.savefig(os.path.join(output_dir, f'{file_prefix}metric_distributions.png'))\n","    plt.close()\n","\n","    # Correlation matrix (if multiple metrics available)\n","    if len(metrics_to_plot) > 1:\n","        plt.figure(figsize=(10, 8))\n","        correlation = df[metrics_to_plot].corr()\n","        sns.heatmap(correlation, annot=True, cmap='coolwarm')\n","        plt.title(f'{dataset_prefix}Correlation Matrix of Metrics')\n","        plt.tight_layout()\n","        plt.savefig(os.path.join(output_dir, f'{file_prefix}correlation_matrix.png'))\n","        plt.close()\n","\n","    # Create a scatter plot of two main metrics (if available)\n","    main_metrics = []\n","    for metric in ['labse_similarity', 'laser_similarity']:\n","        if metric in metrics_to_plot:\n","            main_metrics.append(metric)\n","\n","    if len(main_metrics) >= 2:\n","        plt.figure(figsize=(10, 8))\n","\n","        # Check if ensemble_score is available\n","        if 'ensemble_score' in df.columns and not df['ensemble_score'].isna().all():\n","            scatter = plt.scatter(\n","                df[main_metrics[0]],\n","                df[main_metrics[1]],\n","                c=df['ensemble_score'],\n","                cmap='viridis',\n","                alpha=0.7\n","            )\n","            plt.colorbar(scatter, label='Ensemble Score')\n","        else:\n","            # Simple scatter plot without color mapping\n","            plt.scatter(\n","                df[main_metrics[0]],\n","                df[main_metrics[1]],\n","                alpha=0.7\n","            )\n","\n","        # Add threshold lines\n","        if main_metrics[0] in PARAPHRASE_THRESHOLDS and not isinstance(PARAPHRASE_THRESHOLDS[main_metrics[0]], tuple):\n","            plt.axvline(PARAPHRASE_THRESHOLDS[main_metrics[0]], color='g', linestyle='-.')\n","        if main_metrics[1] in PARAPHRASE_THRESHOLDS and not isinstance(PARAPHRASE_THRESHOLDS[main_metrics[1]], tuple):\n","            plt.axhline(PARAPHRASE_THRESHOLDS[main_metrics[1]], color='g', linestyle='-.')\n","\n","        plt.xlabel(main_metrics[0])\n","        plt.ylabel(main_metrics[1])\n","        plt.title(f'{dataset_prefix}Scatter Plot of {main_metrics[0]} vs {main_metrics[1]}')\n","        plt.tight_layout()\n","        plt.savefig(os.path.join(output_dir, f'{file_prefix}metrics_scatter.png'))\n","        plt.close()\n","\n","    print(f\"Basic visualizations saved to {output_dir}\")\n","\n","\n","def initialize_spark(app_name=\"ParaphraseAnalysis\", master=None):\n","    \"\"\"Initialize a Spark session with appropriate configuration for NLP tasks.\"\"\"\n","    # If no master is specified, it will use the default (local or cluster if configured)\n","    builder = SparkSession.builder.appName(app_name)\n","\n","    if master:\n","        builder = builder.master(master)\n","\n","    # Add necessary configuration for handling NLP models and data\n","    spark = (builder\n","        .config(\"spark.driver.memory\", \"16g\")  # Adjust based on your environment\n","        .config(\"spark.executor.memory\", \"16g\")\n","        .config(\"spark.driver.maxResultSize\", \"8g\")\n","        .config(\"spark.python.worker.memory\", \"8g\")\n","        .config(\"spark.kryoserializer.buffer.max\", \"1g\")\n","        .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")  # Enable Arrow for pandas operations\n","        .config(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"10000\")  # Control batch size\n","        .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n","        .getOrCreate())\n","\n","    # Broadcast the device information to all workers\n","    def get_device_info():\n","        if torch.cuda.is_available():\n","            return {\"name\": \"cuda\", \"device_name\": torch.cuda.get_device_name(0)}\n","        else:\n","            return {\"name\": \"cpu\", \"device_name\": \"CPU\"}\n","\n","    device_info = get_device_info()\n","    device_broadcast = spark.sparkContext.broadcast(device_info)\n","\n","    print(f\"Initialized Spark with {device_info['name']} device: {device_info['device_name']}\")\n","    return spark, device_broadcast\n","\n","\n","def shutdown_spark(spark):\n","    \"\"\"Properly shut down the Spark session.\"\"\"\n","    if spark:\n","        spark.stop()\n","        print(\"Spark session stopped\")\n","\n","\n","def distribute_model_files(spark, model_paths):\n","    \"\"\"Add model files to Spark for distribution to all workers.\"\"\"\n","    for path in model_paths:\n","        if os.path.exists(path):\n","            spark.sparkContext.addFile(path)\n","            print(f\"Added {path} to Spark distribution\")\n","        else:\n","            print(f\"Warning: Model file {path} not found\")\n","\n","\n","def preprocess_with_spark(spark, df, source_col1, source_col2):\n","    \"\"\"\n","    Preprocess the input dataframe using Spark for parallel processing.\n","\n","    Args:\n","        spark: SparkSession instance\n","        df: Pandas DataFrame with source columns\n","        source_col1, source_col2: Names of the text columns to normalize\n","\n","    Returns:\n","        Pandas DataFrame with additional normalized columns\n","    \"\"\"\n","    # Convert pandas DataFrame to Spark DataFrame\n","    spark_df = spark.createDataFrame(df)\n","\n","    # Define the normalization function\n","    def normalize_text(text):\n","        if not isinstance(text, str):\n","            return \"\"\n","        return text.lower().strip()\n","\n","    # Register UDF\n","    normalize_udf = udf(normalize_text, StringType())\n","\n","    # Apply normalization\n","    spark_df = spark_df.withColumn(f\"norm_{source_col1}\", normalize_udf(col(source_col1)))\n","    spark_df = spark_df.withColumn(f\"norm_{source_col2}\", normalize_udf(col(source_col2)))\n","\n","    # Convert back to pandas\n","    result_df = spark_df.toPandas()\n","    print(f\"Preprocessed {len(result_df)} rows using Spark\")\n","\n","    return result_df\n","\n","\n","def get_batch_embeddings(model_name, batch_texts, device):\n","    \"\"\"\n","    Get embeddings for a batch of texts using the specified model.\n","    This function is designed to run on a single Spark executor.\n","\n","    Args:\n","        model_name: Name of the embedding model to use ('labse' or 'sentence-transformer')\n","        batch_texts: List of text strings\n","        device: Device to run the model on (cuda/cpu)\n","\n","    Returns:\n","        numpy array of embeddings\n","    \"\"\"\n","    import torch\n","    import numpy as np\n","\n","    if model_name == 'labse':\n","        try:\n","            from transformers import AutoTokenizer, AutoModel\n","\n","            # Load models if not loaded already (will be cached for subsequent calls)\n","            if not hasattr(get_batch_embeddings, 'labse_tokenizer'):\n","                get_batch_embeddings.labse_tokenizer = AutoTokenizer.from_pretrained(\"setu4993/LaBSE\")\n","                get_batch_embeddings.labse_model = AutoModel.from_pretrained(\"setu4993/LaBSE\").to(device)\n","                print(f\"LaBSE model loaded on device: {device}\")\n","\n","            # Tokenize\n","            inputs = get_batch_embeddings.labse_tokenizer(\n","                batch_texts,\n","                return_tensors=\"pt\",\n","                padding=True,\n","                truncation=True,\n","                max_length=128\n","            ).to(device)\n","\n","            # Get embeddings\n","            with torch.no_grad():\n","                outputs = get_batch_embeddings.labse_model(**inputs)\n","                embeddings = outputs.pooler_output\n","\n","                # Normalize\n","                embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n","\n","            return embeddings.cpu().numpy()\n","\n","        except Exception as e:\n","            print(f\"Error in LaBSE embedding calculation: {e}\")\n","            # Return zero embeddings as fallback\n","            return np.zeros((len(batch_texts), 768))\n","\n","    elif model_name == 'sentence-transformer':\n","        try:\n","            from sentence_transformers import SentenceTransformer\n","\n","            # Load model if not loaded already\n","            if not hasattr(get_batch_embeddings, 'st_model'):\n","                get_batch_embeddings.st_model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')\n","                if torch.cuda.is_available():\n","                    get_batch_embeddings.st_model = get_batch_embeddings.st_model.to(device)\n","                print(f\"Sentence-Transformer model loaded on device: {device}\")\n","\n","            # Get embeddings\n","            embeddings = get_batch_embeddings.st_model.encode(\n","                batch_texts,\n","                convert_to_tensor=True,\n","                show_progress_bar=False\n","            )\n","\n","            return embeddings.cpu().numpy()\n","\n","        except Exception as e:\n","            print(f\"Error in Sentence-Transformer embedding calculation: {e}\")\n","            # Return zero embeddings as fallback\n","            return np.zeros((len(batch_texts), 768))\n","\n","    else:\n","        print(f\"Unknown model name: {model_name}\")\n","        return np.zeros((len(batch_texts), 768))\n","\n","\n","def calculate_similarities(embeddings1, embeddings2):\n","    \"\"\"Calculate cosine similarities between two sets of embeddings.\"\"\"\n","    import numpy as np\n","\n","    similarities = np.zeros(len(embeddings1))\n","    for i in range(len(embeddings1)):\n","        # Ensure embeddings are normalized\n","        emb1 = embeddings1[i].reshape(1, -1)\n","        emb2 = embeddings2[i].reshape(1, -1)\n","\n","        # Calculate cosine similarity\n","        similarities[i] = np.dot(emb1, emb2.T)[0][0] / (\n","            np.linalg.norm(emb1) * np.linalg.norm(emb2) + 1e-8)\n","\n","    return similarities\n","\n","\n","def calculate_embedding_metrics_spark(spark, df, text_col1, text_col2, device_broadcast, batch_size=32):\n","    \"\"\"\n","    Calculate embedding-based similarity metrics using Spark for distributed processing.\n","\n","    Args:\n","        spark: SparkSession instance\n","        df: Pandas DataFrame with normalized text columns\n","        text_col1, text_col2: Names of the text columns to compare\n","        device_broadcast: Broadcast variable containing device information\n","        batch_size: Size of batches to process\n","\n","    Returns:\n","        Pandas DataFrame with similarity metrics added\n","    \"\"\"\n","    # Convert pandas DataFrame to Spark DataFrame\n","    spark_df = spark.createDataFrame(df)\n","\n","    # Use broadcast variables for efficiency\n","    device_info = device_broadcast.value\n","    device = device_info[\"name\"]\n","\n","    # Define processing function for batch-wise computation using a safer approach\n","    @pandas_udf(\"double\")\n","    def calculate_labse_similarity(texts1_series, texts2_series):\n","        # Process one row at a time (safer but less efficient)\n","        texts1 = texts1_series.tolist()\n","        texts2 = texts2_series.tolist()\n","        results = []\n","\n","        # Process in small, fixed-size batches\n","        for i in range(0, len(texts1), batch_size):\n","            batch_end = min(i + batch_size, len(texts1))\n","            batch_texts1 = texts1[i:batch_end]\n","            batch_texts2 = texts2[i:batch_end]\n","\n","            try:\n","                # Get embeddings\n","                emb1 = get_batch_embeddings('labse', batch_texts1, device)\n","                emb2 = get_batch_embeddings('labse', batch_texts2, device)\n","\n","                # Calculate similarities\n","                batch_similarities = calculate_similarities(emb1, emb2)\n","                results.extend(batch_similarities)\n","            except Exception as e:\n","                print(f\"Error in batch {i}-{batch_end}: {e}\")\n","                # Fallback for errors: neutral similarity\n","                results.extend([0.5] * (batch_end - i))\n","\n","        return pd.Series(results)\n","\n","    @pandas_udf(\"double\")\n","    def calculate_st_similarity(texts1_series, texts2_series):\n","        # Process one row at a time (safer but less efficient)\n","        texts1 = texts1_series.tolist()\n","        texts2 = texts2_series.tolist()\n","        results = []\n","\n","        # Process in small, fixed-size batches\n","        for i in range(0, len(texts1), batch_size):\n","            batch_end = min(i + batch_size, len(texts1))\n","            batch_texts1 = texts1[i:batch_end]\n","            batch_texts2 = texts2[i:batch_end]\n","\n","            try:\n","                # Get embeddings\n","                emb1 = get_batch_embeddings('sentence-transformer', batch_texts1, device)\n","                emb2 = get_batch_embeddings('sentence-transformer', batch_texts2, device)\n","\n","                # Calculate similarities\n","                batch_similarities = calculate_similarities(emb1, emb2)\n","                results.extend(batch_similarities)\n","            except Exception as e:\n","                print(f\"Error in batch {i}-{batch_end}: {e}\")\n","                # Fallback for errors: neutral similarity\n","                results.extend([0.5] * (batch_end - i))\n","\n","        return pd.Series(results)\n","\n","    # Apply the functions\n","    try:\n","        print(\"Calculating LaBSE similarities...\")\n","        spark_df = spark_df.withColumn(\n","            'labse_similarity',\n","            calculate_labse_similarity(col(text_col1), col(text_col2))\n","        )\n","    except Exception as e:\n","        print(f\"Error in LaBSE calculation: {e}\")\n","        # Add fallback column\n","        spark_df = spark_df.withColumn('labse_similarity', lit(0.5))\n","\n","    try:\n","        print(\"Calculating Sentence-Transformer similarities...\")\n","        spark_df = spark_df.withColumn(\n","            'laser_similarity',  # We keep the same name for compatibility\n","            calculate_st_similarity(col(text_col1), col(text_col2))\n","        )\n","    except Exception as e:\n","        print(f\"Error in sentence-transformer calculation: {e}\")\n","        # Add fallback column\n","        spark_df = spark_df.withColumn('laser_similarity', lit(0.5))\n","\n","    # Convert back to pandas\n","    result_df = spark_df.toPandas()\n","    print(f\"Calculated embedding metrics for {len(result_df)} rows using Spark\")\n","\n","    return result_df\n","\n","\n","def jaccard_similarity_udf(s1, s2):\n","    \"\"\"Calculate Jaccard similarity between two strings.\"\"\"\n","    if not isinstance(s1, str):\n","        s1 = \"\"\n","    if not isinstance(s2, str):\n","        s2 = \"\"\n","\n","    words1 = set(s1.split())\n","    words2 = set(s2.split())\n","\n","    if not words1 and not words2:\n","        return 1.0\n","\n","    intersection = len(words1.intersection(words2))\n","    union = len(words1.union(words2))\n","\n","    return intersection / union if union > 0 else 0\n","\n","\n","def calculate_linguistic_metrics_spark(spark, df, text_col1, text_col2):\n","    \"\"\"\n","    Calculate linguistic metrics using Spark for distributed processing.\n","    Simplified version without ClassLA dependencies.\n","\n","    Args:\n","        spark: SparkSession instance\n","        df: Pandas DataFrame with normalized text columns\n","        text_col1, text_col2: Names of the text columns to compare\n","\n","    Returns:\n","        Pandas DataFrame with linguistic metrics added\n","    \"\"\"\n","    # Convert pandas DataFrame to Spark DataFrame\n","    spark_df = spark.createDataFrame(df)\n","\n","    # Register UDFs\n","    jaccard_udf = udf(jaccard_similarity_udf, DoubleType())\n","\n","    # Calculate length ratio\n","    @udf(DoubleType())\n","    def length_ratio(text1, text2):\n","        if not isinstance(text1, str):\n","            text1 = \"\"\n","        if not isinstance(text2, str):\n","            text2 = \"\"\n","\n","        len1 = len(text1.split())\n","        len2 = len(text2.split())\n","\n","        return min(len1, len2) / max(len1, len2) if max(len1, len2) > 0 else 0\n","\n","    # Calculate metrics\n","    print(\"Calculating linguistic metrics with Spark...\")\n","    spark_df = spark_df.withColumn(\n","        'jaccard_similarity',\n","        jaccard_udf(col(text_col1), col(text_col2))\n","    )\n","\n","    spark_df = spark_df.withColumn(\n","        'length_ratio',\n","        length_ratio(col(text_col1), col(text_col2))\n","    )\n","\n","    # Add simple METEOR score approximation\n","    spark_df = spark_df.withColumn(\n","        'meteor_score',\n","        col('jaccard_similarity') * 0.8  # Simple approximation\n","    )\n","\n","    # Convert back to pandas\n","    result_df = spark_df.toPandas()\n","    print(f\"Calculated linguistic metrics for {len(result_df)} rows using Spark\")\n","\n","    return result_df\n","\n","\n","def ensemble_scoring_spark(spark, df):\n","    \"\"\"\n","    Apply ensemble scoring using Spark.\n","\n","    Args:\n","        spark: SparkSession instance\n","        df: Pandas DataFrame with various similarity metrics\n","\n","    Returns:\n","        Pandas DataFrame with ensemble scores and classifications\n","    \"\"\"\n","    # Create a true copy of the original dataframe to preserve all columns\n","    preserved_data = df.copy()\n","\n","    # Convert to Spark DataFrame\n","    spark_df = spark.createDataFrame(df)\n","\n","    # Available metrics (check which columns exist)\n","    available_metrics = []\n","    weights = {}\n","\n","    if 'labse_similarity' in df.columns:\n","        available_metrics.append('labse_similarity')\n","        weights['labse_similarity'] = 0.4\n","\n","    if 'laser_similarity' in df.columns:\n","        available_metrics.append('laser_similarity')\n","        weights['laser_similarity'] = 0.3\n","\n","    if 'meteor_score' in df.columns:\n","        available_metrics.append('meteor_score')\n","        weights['meteor_score'] = 0.1\n","\n","    if 'length_ratio' in df.columns:\n","        available_metrics.append('length_ratio')\n","        weights['length_ratio'] = 0.1\n","\n","    if 'jaccard_similarity' in df.columns:\n","        available_metrics.append('jaccard_similarity')\n","        weights['jaccard_similarity'] = 0.1\n","\n","    # If no metrics available, add simple fallback\n","    if not available_metrics:\n","        print(\"No metrics available for ensemble scoring, using fallback\")\n","        spark_df = spark_df.withColumn('ensemble_score', lit(0.5))\n","        spark_df = spark_df.withColumn('is_paraphrase', lit(False))\n","        result_df = spark_df.toPandas()\n","\n","        # Make sure we return all original columns\n","        for col in preserved_data.columns:\n","            if col not in result_df.columns:\n","                result_df[col] = preserved_data[col]\n","\n","        return result_df\n","\n","    # Normalize weights to sum to 1\n","    total_weight = sum(weights.values())\n","    normalized_weights = {k: v/total_weight for k, v in weights.items()}\n","\n","    # Calculate weighted score\n","    ensemble_expr = None\n","    for metric in available_metrics:\n","        weight = normalized_weights[metric]\n","        if ensemble_expr is None:\n","            ensemble_expr = col(metric) * weight\n","        else:\n","            ensemble_expr = ensemble_expr + (col(metric) * weight)\n","\n","    # Add ensemble score\n","    spark_df = spark_df.withColumn('ensemble_score', ensemble_expr)\n","\n","    # Classify pairs based on individual thresholds\n","    # A pair is a paraphrase if it meets all the thresholds for available metrics\n","    condition = None\n","\n","    # Apply threshold checking for each metric\n","    for metric in available_metrics:\n","        if metric in PARAPHRASE_THRESHOLDS:\n","            threshold = PARAPHRASE_THRESHOLDS[metric]\n","\n","            if isinstance(threshold, tuple):\n","                # For metrics like length_ratio where we have a range\n","                if condition is None:\n","                    condition = (col(metric) >= threshold[0]) & (col(metric) <= threshold[1])\n","                else:\n","                    condition = condition & (col(metric) >= threshold[0]) & (col(metric) <= threshold[1])\n","            else:\n","                # For metrics where higher is better\n","                if condition is None:\n","                    condition = col(metric) >= threshold\n","                else:\n","                    condition = condition & (col(metric) >= threshold)\n","\n","    # If we have any conditions, apply them\n","    if condition is not None:\n","        spark_df = spark_df.withColumn('is_paraphrase', condition)\n","    else:\n","        # Fallback to ensemble score if we don't have specific thresholds\n","        spark_df = spark_df.withColumn('is_paraphrase', col('ensemble_score') > 0.75)\n","\n","    print(f\"Using {len(available_metrics)} metrics for ensemble scoring with weights: {normalized_weights}\")\n","\n","    # Convert back to pandas\n","    result_df = spark_df.toPandas()\n","\n","    # Make sure we return all original columns\n","    for col in preserved_data.columns:\n","        if col not in result_df.columns:\n","            result_df[col] = preserved_data[col]\n","\n","    print(f\"Final columns after ensemble scoring: {result_df.columns.tolist()}\")\n","    return result_df\n","\n","\n","def calculate_metrics_fallback(df, text_col1, text_col2, device):\n","    \"\"\"\n","    Fallback method for calculating metrics when Spark processing fails.\n","    This uses the original code's approach but with improved error handling.\n","\n","    Args:\n","        df: Pandas DataFrame with normalized text columns\n","        text_col1, text_col2: Names of the text columns to compare\n","        device: Torch device to use for calculations\n","\n","    Returns:\n","        Pandas DataFrame with metrics added\n","    \"\"\"\n","    import torch\n","    import numpy as np\n","    from tqdm.auto import tqdm\n","    import time\n","\n","    print(\"Using fallback calculation method...\")\n","    results = df.copy()\n","\n","    # Define safe batch size\n","    batch_size = 8  # Smaller batch size for safety\n","\n","    # Try to load models with multiple retries\n","    max_retries = 3\n","\n","    # LaBSE loading with retries\n","    for attempt in range(max_retries):\n","        try:\n","            print(f\"Loading LaBSE model (attempt {attempt+1}/{max_retries})...\")\n","            from transformers import AutoTokenizer, AutoModel\n","\n","            tokenizer = AutoTokenizer.from_pretrained(\"setu4993/LaBSE\")\n","            model = AutoModel.from_pretrained(\"setu4993/LaBSE\").to(device)\n","            print(\"LaBSE model loaded successfully\")\n","            break\n","        except Exception as e:\n","            print(f\"LaBSE loading attempt {attempt+1} failed: {e}\")\n","            if attempt == max_retries - 1:\n","                print(\"Could not load LaBSE model, will use simpler metrics\")\n","                model = None\n","                tokenizer = None\n","            time.sleep(2)  # Wait before retrying\n","\n","    # Sentence transformer loading with retries\n","    for attempt in range(max_retries):\n","        try:\n","            print(f\"Loading sentence-transformers model (attempt {attempt+1}/{max_retries})...\")\n","            from sentence_transformers import SentenceTransformer\n","            st_model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')\n","            if torch.cuda.is_available():\n","                st_model = st_model.to(device)\n","            print(\"Sentence-Transformer model loaded successfully\")\n","            break\n","        except Exception as e:\n","            print(f\"Sentence-Transformer loading attempt {attempt+1} failed: {e}\")\n","            if attempt == max_retries - 1:\n","                print(\"Could not load Sentence-Transformer model, will use simpler metrics\")\n","                st_model = None\n","            time.sleep(2)  # Wait before retrying\n","\n","    # Prepare data\n","    texts1 = df[text_col1].tolist()\n","    texts2 = df[text_col2].tolist()\n","\n","    # Initialize results containers\n","    labse_scores = np.zeros(len(df))\n","    st_scores = np.zeros(len(df))\n","\n","    # LaBSE scoring function with better error handling\n","    def get_labse_similarity_safe(batch_texts1, batch_texts2):\n","        try:\n","            if tokenizer is None or model is None:\n","                return np.array([0.5] * len(batch_texts1))\n","\n","            # Tokenize\n","            inputs1 = tokenizer(batch_texts1, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n","            inputs2 = tokenizer(batch_texts2, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n","\n","            # Get embeddings\n","            with torch.no_grad():\n","                embeddings1 = model(**inputs1).pooler_output\n","                embeddings2 = model(**inputs2).pooler_output\n","\n","                # Normalize\n","                embeddings1 = torch.nn.functional.normalize(embeddings1, p=2, dim=1)\n","                embeddings2 = torch.nn.functional.normalize(embeddings2, p=2, dim=1)\n","\n","                # Calculate cosine similarity\n","                similarities = torch.bmm(\n","                    embeddings1.unsqueeze(1),\n","                    embeddings2.unsqueeze(2)\n","                ).squeeze().cpu().numpy()\n","\n","            return similarities\n","        except Exception as e:\n","            print(f\"Error in LaBSE similarity calculation: {e}\")\n","            return np.array([0.5] * len(batch_texts1))  # Fallback to neutral score\n","\n","    # Sentence-transformers scoring with better error handling\n","    def get_st_similarity_safe(batch_texts1, batch_texts2):\n","        try:\n","            if st_model is None:\n","                return np.array([0.5] * len(batch_texts1))\n","\n","            # Get embeddings\n","            with torch.no_grad():\n","                embeddings1 = st_model.encode(batch_texts1, convert_to_tensor=True)\n","                embeddings2 = st_model.encode(batch_texts2, convert_to_tensor=True)\n","\n","                # Calculate cosine similarities\n","                similarities = []\n","                for i in range(len(batch_texts1)):\n","                    try:\n","                        emb1 = embeddings1[i].unsqueeze(0)\n","                        emb2 = embeddings2[i].unsqueeze(0)\n","                        sim = torch.nn.functional.cosine_similarity(emb1, emb2).item()\n","                        similarities.append(sim)\n","                    except Exception as e:\n","                        print(f\"Error calculating similarity for item {i}: {e}\")\n","                        similarities.append(0.5)  # Fallback\n","\n","            return np.array(similarities)\n","        except Exception as e:\n","            print(f\"Error in Sentence-Transformer similarity calculation: {e}\")\n","            return np.array([0.5] * len(batch_texts1))  # Fallback to neutral score\n","\n","    # Jaccard similarity as a fallback\n","    def jaccard_similarity(text1, text2):\n","        if not isinstance(text1, str):\n","            text1 = \"\"\n","        if not isinstance(text2, str):\n","            text2 = \"\"\n","\n","        words1 = set(text1.lower().split())\n","        words2 = set(text2.lower().split())\n","\n","        if not words1 and not words2:\n","            return 1.0\n","\n","        intersection = len(words1.intersection(words2))\n","        union = len(words1.union(words2))\n","\n","        return intersection / union if union > 0 else 0\n","\n","    # Length ratio\n","    def calc_length_ratio(text1, text2):\n","        if not isinstance(text1, str):\n","            text1 = \"\"\n","        if not isinstance(text2, str):\n","            text2 = \"\"\n","\n","        len1 = len(text1.split())\n","        len2 = len(text2.split())\n","\n","        return min(len1, len2) / max(len1, len2) if max(len1, len2) > 0 else 0\n","\n","    # Process in batches with progress bar\n","    for i in tqdm(range(0, len(df), batch_size), desc=\"Calculating metrics (fallback method)\"):\n","        end_idx = min(i + batch_size, len(df))\n","        batch_texts1 = texts1[i:end_idx]\n","        batch_texts2 = texts2[i:end_idx]\n","\n","        # Calculate and store similarities\n","        labse_scores[i:end_idx] = get_labse_similarity_safe(batch_texts1, batch_texts2)\n","        st_scores[i:end_idx] = get_st_similarity_safe(batch_texts1, batch_texts2)\n","\n","    # Add scores to dataframe\n","    results['labse_similarity'] = labse_scores\n","    results['laser_similarity'] = st_scores  # We use sentence-transformers instead of LASER\n","\n","    # Calculate Jaccard similarity for each pair\n","    print(\"Calculating Jaccard similarity...\")\n","    results['jaccard_similarity'] = [\n","        jaccard_similarity(t1, t2) for t1, t2 in zip(texts1, texts2)\n","    ]\n","\n","    # Calculate length ratio\n","    print(\"Calculating length ratio...\")\n","    results['length_ratio'] = [\n","        calc_length_ratio(t1, t2) for t1, t2 in zip(texts1, texts2)\n","    ]\n","\n","    # Add simple METEOR approximation\n","    results['meteor_score'] = results['jaccard_similarity'] * 0.8\n","\n","    return results\n","\n","\n","def run_paraphrase_pipeline_spark(input_file, text_col1, text_col2, output_file, spark_master=None, clean_metadata=True, dataset_name=None):\n","    \"\"\"\n","    Run the paraphrase analysis pipeline using Spark for distributed processing.\n","    Streamlined version focusing on core metrics.\n","\n","    Args:\n","        input_file: Path to the input file (Excel or CSV)\n","        text_col1, text_col2: Names of the text columns to compare\n","        output_file: Path to save the output CSV\n","        spark_master: Optional Spark master URL (e.g., 'local[*]', 'spark://host:port')\n","        clean_metadata: Whether to perform metadata cleaning (default: True)\n","        dataset_name: Name of the dataset to include in visualization titles\n","\n","    Returns:\n","        Pandas DataFrame with analysis results\n","    \"\"\"\n","    import os\n","    start_time = time.time()\n","    print(f\"Starting Spark-powered paraphrase analysis pipeline at {time.strftime('%H:%M:%S')}\")\n","\n","    # Extract dataset name from filename if not provided\n","    if dataset_name is None:\n","        dataset_name = os.path.basename(input_file).split('.')[0]\n","\n","    print(f\"Processing dataset: {dataset_name}\")\n","\n","    spark = None\n","\n","    # Flag to track if we're using Spark or fallback\n","    using_spark = True\n","    device = None\n","\n","    try:\n","        # Initialize Spark\n","        spark, device_broadcast = initialize_spark(\n","            app_name=\"ParaphraseAnalysis\",\n","            master=spark_master\n","        )\n","\n","        # Get device from broadcast\n","        device_info = device_broadcast.value\n","        device = torch.device(device_info[\"name\"])\n","\n","        # Load data\n","        print(f\"Loading data from {input_file}\")\n","\n","        # Check file extension to determine how to read the file\n","        file_ext = os.path.splitext(input_file)[1].lower()\n","\n","        if file_ext == '.xlsx' or file_ext == '.xls':\n","            try:\n","                # Try with openpyxl engine first (newer xlsx files)\n","                df = pd.read_excel(input_file, engine='openpyxl')\n","                print(\"Successfully read Excel file with openpyxl engine\")\n","            except Exception as e1:\n","                print(f\"Failed with openpyxl engine: {e1}\")\n","                try:\n","                    # Try with xlrd engine (older xls files)\n","                    df = pd.read_excel(input_file, engine='xlrd')\n","                    print(\"Successfully read Excel file with xlrd engine\")\n","                except Exception as e2:\n","                    print(f\"Could not read Excel file with any available engine: {e2}\")\n","                    raise ValueError(f\"Cannot read Excel file {input_file}. Try converting to CSV first.\")\n","        else:\n","            # Assume CSV for all other extensions\n","            print(f\"Reading as CSV file (extension: {file_ext})\")\n","            df = pd.read_csv(input_file)\n","            print(f\"Successfully read CSV with {len(df)} rows and columns: {df.columns.tolist()}\")\n","\n","        print(f\"Loaded {len(df)} sentence pairs\")\n","\n","        # Preprocessing with Spark\n","        try:\n","            print(\"Preprocessing data with Spark...\")\n","            df = preprocess_with_spark(spark, df, text_col1, text_col2)\n","        except Exception as e:\n","            print(f\"Spark preprocessing failed: {e}\")\n","            print(\"Using fallback preprocessing method...\")\n","\n","            # Fallback to non-Spark preprocessing\n","            def normalize_text(text):\n","                if not isinstance(text, str):\n","                    return \"\"\n","                return text.lower().strip()\n","\n","            df[f\"norm_{text_col1}\"] = df[text_col1].apply(normalize_text)\n","            df[f\"norm_{text_col2}\"] = df[text_col2].apply(normalize_text)\n","\n","        # Save intermediate preprocessing results\n","        intermediate_file = output_file.replace('.csv', '_preprocessed.csv')\n","        df.to_csv(intermediate_file, index=False)\n","        print(f\"Saved preprocessed data to {intermediate_file}\")\n","\n","        # Try Spark embedding metrics calculation\n","        try:\n","            print(\"Calculating embedding metrics with Spark...\")\n","            df = calculate_embedding_metrics_spark(\n","                spark,\n","                df,\n","                f\"norm_{text_col1}\",\n","                f\"norm_{text_col2}\",\n","                device_broadcast\n","            )\n","        except Exception as e:\n","            print(f\"Spark embedding calculation failed: {e}\")\n","            using_spark = False\n","\n","            # Fall back to non-Spark method\n","            print(\"Falling back to non-Spark embedding calculation...\")\n","            df = calculate_metrics_fallback(\n","                df,\n","                f\"norm_{text_col1}\",\n","                f\"norm_{text_col2}\",\n","                device\n","            )\n","\n","        # Save embedding results\n","        embedding_file = output_file.replace('.csv', '_embeddings.csv')\n","        df.to_csv(embedding_file, index=False)\n","        print(f\"Saved embedding results to {embedding_file}\")\n","\n","        # Try Spark linguistic metrics calculation if we're still using Spark\n","        if using_spark:\n","            try:\n","                print(\"Calculating linguistic metrics with Spark...\")\n","                df = calculate_linguistic_metrics_spark(\n","                    spark,\n","                    df,\n","                    f\"norm_{text_col1}\",\n","                    f\"norm_{text_col2}\"\n","                )\n","            except Exception as e:\n","                print(f\"Spark linguistic metrics calculation failed: {e}\")\n","                # We already have basic metrics from the previous step\n","                print(\"Using metrics from previous step...\")\n","                using_spark = False\n","\n","            # Save linguistic results\n","            linguistic_file = output_file.replace('.csv', '_linguistic.csv')\n","            df.to_csv(linguistic_file, index=False)\n","            print(f\"Saved linguistic analysis to {linguistic_file}\")\n","\n","        # Ensemble scoring\n","        print(\"Ensemble scoring...\")\n","\n","        try:\n","            df = ensemble_scoring_spark(spark, df)\n","        except Exception as e:\n","            print(f\"Ensemble scoring failed: {e}\")\n","\n","            # Simple fallback for ensemble score\n","            print(\"Using fallback ensemble scoring method...\")\n","\n","            # Identify available metrics\n","            metrics = [col for col in df.columns if col in [\n","                'labse_similarity', 'laser_similarity', 'meteor_score',\n","                'length_ratio', 'jaccard_similarity'\n","            ]]\n","\n","            if metrics:\n","                # Simple weighted average with predefined weights\n","                weights = {\n","                    'labse_similarity': 0.3,\n","                    'laser_similarity': 0.3,\n","                    'meteor_score': 0.3,\n","                    'length_ratio': 0.1,\n","                    'jaccard_similarity': 0.1\n","                }\n","\n","                # Normalize weights for available metrics\n","                available_weights = {k: weights[k] for k in metrics if k in weights}\n","                total_weight = sum(available_weights.values())\n","                normalized_weights = {k: v/total_weight for k, v in available_weights.items()}\n","\n","                # Calculate ensemble score\n","                df['ensemble_score'] = 0\n","                for metric, weight in normalized_weights.items():\n","                    df['ensemble_score'] += df[metric] * weight\n","\n","                # Classify pairs\n","                condition = None\n","                for metric in metrics:\n","                    if metric in PARAPHRASE_THRESHOLDS:\n","                        threshold = PARAPHRASE_THRESHOLDS[metric]\n","\n","                        if isinstance(threshold, tuple):\n","                            # For metrics like length_ratio where we have a range\n","                            if condition is None:\n","                                condition = (df[metric] >= threshold[0]) & (df[metric] <= threshold[1])\n","                            else:\n","                                condition = condition & (df[metric] >= threshold[0]) & (df[metric] <= threshold[1])\n","                        else:\n","                            # For metrics where higher is better\n","                            if condition is None:\n","                                condition = df[metric] >= threshold\n","                            else:\n","                                condition = condition & (df[metric] >= threshold)\n","\n","                if condition is not None:\n","                    df['is_paraphrase'] = condition\n","                else:\n","                    df['is_paraphrase'] = df['ensemble_score'] > 0.75\n","\n","                print(f\"Calculated fallback ensemble score using {len(metrics)} metrics with weights: {normalized_weights}\")\n","            else:\n","                # If no metrics available, use a neutral score\n","                df['ensemble_score'] = 0.5\n","                df['is_paraphrase'] = False\n","                print(\"No metrics available for ensemble scoring, using neutral score\")\n","\n","        # Save final results\n","        print(f\"Saving final results to {output_file}\")\n","        df.to_csv(output_file, index=False)\n","\n","        # Visualization (optional)\n","        try:\n","            print(\"Generating visualizations...\")\n","\n","            # Create a visualizations directory if it doesn't exist\n","            viz_dir = os.path.join(os.path.dirname(output_file), \"visualizations\")\n","            os.makedirs(viz_dir, exist_ok=True)\n","\n","            # Use the functions defined in this module with dataset name\n","            visualize_results(df, viz_dir, dataset_name=dataset_name)\n","\n","            print(f\"Visualizations saved to {viz_dir}\")\n","        except Exception as e:\n","            print(f\"Visualization error: {e}\")\n","            print(\"Skipping visualization step. Error details:\")\n","            import traceback\n","            traceback.print_exc()\n","\n","        elapsed_time = time.time() - start_time\n","        print(f\"Pipeline completed in {elapsed_time:.2f} seconds\")\n","\n","        return df\n","\n","    except Exception as e:\n","        # Catch any unhandled exceptions\n","        elapsed_time = time.time() - start_time\n","        print(f\"Pipeline failed after {elapsed_time:.2f} seconds\")\n","        print(f\"Critical error: {e}\")\n","\n","        # Print exception traceback for debugging\n","        import traceback\n","        traceback.print_exc()\n","\n","        return None\n","\n","    finally:\n","        # Always shut down Spark\n","        if spark:\n","            shutdown_spark(spark)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1742829530085,"user_tz":-60,"elapsed":902,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"id":"ss2kVfTjrHWu"},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    # Define base directory - Update this to your actual location\n","    base_dir = \"/content/drive/MyDrive/Colab Notebooks/preprocessed_datasets\"\n","\n","    # Dataset name - change this to switch between datasets\n","    #dataset = \"predprocesiranje_msr_paired_cleaned\"\n","    #dataset = \"paranmt_small_translated_cleaned_00\"\n","    #dataset = \"processed_quora_clean_00\"\n","    dataset = \"paws_nepodvojene_filtrirane_parafraze_00\"\n","\n","    # Construct paths using f-strings\n","    input_file = f\"{base_dir}/{dataset}.xlsx\"\n","    output_file = f\"{base_dir}/paraphrase_analysis_results_{dataset.split('_')[0]}_{dataset}.csv\"\n","\n","    # Column names\n","    text_col1 = \"sentence_translation\"\n","    text_col2 = \"paraphrase_translation\"\n","\n","    # Spark configuration\n","    spark_config = {\n","        'master': 'local[4]',\n","        'use_fallback_early': False\n","    }\n","\n","    # Processing flags\n","    add_metadata = True\n","    filter_dataset = True\n","\n","    # The simplest approach: Convert Excel to CSV first, then use the CSV\n","    print(f\"Converting Excel file to CSV for better compatibility...\")\n","    import pandas as pd\n","\n","    # Read Excel with explicit engine specification\n","    try:\n","        # Try with openpyxl engine (for newer .xlsx files)\n","        df = pd.read_excel(input_file, engine='openpyxl')\n","    except Exception as e1:\n","        print(f\"Failed with openpyxl engine: {e1}\")\n","        try:\n","            # Try with xlrd engine (for older .xls files)\n","            df = pd.read_excel(input_file, engine='xlrd')\n","        except Exception as e2:\n","            print(f\"Failed with xlrd engine: {e2}\")\n","            raise Exception(\"Could not read Excel file with any available engine\")\n","\n","    # Save as CSV\n","    csv_file = input_file.replace('.xlsx', '.csv')\n","    df.to_csv(csv_file, index=False)\n","    print(f\"Successfully converted Excel to CSV: {csv_file}\")\n","\n","    # Run the pipeline with the CSV file\n","    results = run_paraphrase_pipeline_spark(\n","        csv_file,  # Use the CSV file we just created\n","        text_col1,\n","        text_col2,\n","        output_file,\n","        spark_master=spark_config['master'],\n","        dataset_name=dataset  # Add the dataset name parameter\n","    )\n","\n","    print(\"Pipeline execution complete.\")\n","\n","    # Rest of the code remains the same...\n","    # Add metadata and filter dataset if requested\n","    if results is not None and (add_metadata or filter_dataset):\n","        try:\n","            # Import the filtering module\n","            try:\n","                from filtering_metadata import add_metadata_and_filter, export_with_metadata\n","                filtering_module_found = True\n","            except ImportError:\n","                print(\"Filtering module not found. Using local implementation.\")\n","                filtering_module_found = False\n","\n","            if not filtering_module_found:\n","                # Local implementation of filtering and metadata functions\n","                def add_metadata_and_filter(df, text_col1, text_col2, min_similarity_threshold=0.1):\n","                    import Levenshtein\n","                    import re\n","\n","                    print(f\"\\nAdding metadata and filtering dataset with {len(df)} pairs...\")\n","                    print(f\"Input columns: {df.columns.tolist()}\")  # Debug: print incoming columns\n","\n","                    # Create a true copy of the original dataframe\n","                    results = df.copy(deep=True)\n","\n","                    # Extract the normalized text columns\n","                    norm_col1 = f\"norm_{text_col1}\" if f\"norm_{text_col1}\" in df.columns else text_col1\n","                    norm_col2 = f\"norm_{text_col2}\" if f\"norm_{text_col2}\" in df.columns else text_col2\n","\n","                    # Add length metadata\n","                    results['length_s1'] = results[norm_col1].apply(lambda x: len(str(x).split()))\n","                    results['length_s2'] = results[norm_col2].apply(lambda x: len(str(x).split()))\n","\n","                    # Compute string similarity if not present\n","                    if 'string_similarity' not in results.columns:\n","                        results['string_similarity'] = [\n","                            1 - (Levenshtein.distance(str(s1), str(s2)) / max(len(str(s1)), len(str(s2)), 1))\n","                            for s1, s2 in zip(results[norm_col1], results[norm_col2])\n","                        ]\n","\n","                    # Detect identical sentences\n","                    results['is_identical'] = (results['string_similarity'] > 0.99) | (results[norm_col1] == results[norm_col2])\n","                    identical_count = results['is_identical'].sum()\n","                    print(f\"Found {identical_count} identical pairs ({identical_count/len(results)*100:.2f}%)\")\n","\n","                    # Filter out identical sentences\n","                    if filter_dataset:\n","                        before_count = len(results)\n","                        results_filtered = results[~results['is_identical']]\n","                        identical_removed = before_count - len(results_filtered)\n","                        print(f\"Removed {identical_removed} identical sentence pairs\")\n","                    else:\n","                        results_filtered = results\n","\n","                    # Debug: print columns before returning\n","                    print(f\"Columns after metadata: {results.columns.tolist()}\")\n","\n","                    return {\n","                        'full_data': results,\n","                        'filtered_data': results_filtered\n","                    }\n","\n","                def export_with_metadata(result_dict, output_prefix):\n","                    # Export full dataset with metadata\n","                    full_output = f\"{output_prefix}_with_metadata.csv\"\n","                    result_dict['full_data'].to_csv(full_output, index=False)\n","                    print(f\"Full dataset with metadata saved to {full_output}\")\n","\n","                    # Export filtered dataset\n","                    filtered_output = f\"{output_prefix}_filtered.csv\"\n","                    result_dict['filtered_data'].to_csv(filtered_output, index=False)\n","                    print(f\"Filtered dataset saved to {filtered_output}\")\n","\n","            # Apply metadata and filtering\n","            print(\"\\nEnhancing dataset with metadata and filtering...\")\n","            result_dict = add_metadata_and_filter(\n","                results,\n","                text_col1=text_col1,\n","                text_col2=text_col2,\n","                min_similarity_threshold=0.1\n","            )\n","\n","            # Export the results\n","            metadata_prefix = output_file.replace('.csv', '')\n","            export_with_metadata(result_dict, metadata_prefix)\n","\n","            # Use the filtered dataset for analysis\n","            results_for_analysis = result_dict['filtered_data'] if filter_dataset else result_dict['full_data']\n","\n","        except Exception as e:\n","            print(f\"Warning: Could not add metadata or filter dataset: {e}\")\n","            import traceback\n","            traceback.print_exc()\n","            # Continue with original results\n","            results_for_analysis = results\n","    else:\n","        results_for_analysis = results\n","\n","    # Analyze the results\n","    if results_for_analysis is not None:\n","        try:\n","            # Import the analysis function\n","            try:\n","                from analysis_utils import analyze_paraphrase_results\n","                analysis_module_found = True\n","            except ImportError:\n","                print(\"Analysis module not found. Using local implementation.\")\n","                analysis_module_found = False\n","\n","            print(\"\\nAnalyzing results...\")\n","            analysis_dir = os.path.join(os.path.dirname(output_file), \"analysis\")\n","            os.makedirs(analysis_dir, exist_ok=True)\n","\n","            if analysis_module_found:\n","                stats = analyze_paraphrase_results(results_for_analysis, analysis_dir)\n","            else:\n","                # Use the visualization functions we already have\n","                visualize_results(results_for_analysis, analysis_dir, dataset_name=dataset)  # Pass dataset name here\n","                stats = {}  # Empty stats as fallback\n","\n","            print(\"Analysis complete.\")\n","\n","            # Save statistics as JSON for later reference\n","            import json\n","            try:\n","                # Convert stats to JSON-serializable format (handle numpy types)\n","                def convert_for_json(obj):\n","                    if isinstance(obj, (np.int64, np.int32, np.int16, np.int8)):\n","                        return int(obj)\n","                    elif isinstance(obj, (np.float64, np.float32, np.float16)):\n","                        return float(obj)\n","                    raise TypeError(f\"Type {type(obj)} not serializable\")\n","\n","                stats_file = os.path.join(analysis_dir, \"statistics.json\")\n","                with open(stats_file, 'w') as f:\n","                    json.dump(stats, f, indent=2, default=convert_for_json)\n","                print(f\"Statistics saved to {stats_file}\")\n","            except Exception as e:\n","                print(f\"Warning: Could not save statistics as JSON: {e}\")\n","\n","            # Compare with previous results if available\n","            original_results_file = os.path.join(base_dir, \"original_paraphrase_results.csv\")\n","            if os.path.exists(original_results_file):\n","                try:\n","                    from analysis_utils import compare_pipeline_results\n","\n","                    print(\"\\nComparing with original implementation results...\")\n","                    original_df = pd.read_csv(original_results_file)\n","\n","                    comparison_dir = os.path.join(os.path.dirname(output_file), \"comparison\")\n","                    os.makedirs(comparison_dir, exist_ok=True)\n","\n","                    comparison = compare_pipeline_results(original_df, results_for_analysis, comparison_dir)\n","                    print(\"Comparison complete.\")\n","                except Exception as e:\n","                    print(f\"Warning: Could not compare with original results: {e}\")\n","                    import traceback\n","                    traceback.print_exc()\n","        except Exception as e:\n","            print(f\"Warning: Could not analyze results: {e}\")\n","            import traceback\n","            traceback.print_exc()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1742832990148,"user_tz":-60,"elapsed":383067,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"b33ff76d-404b-4ded-d190-f38cbc3d76c7","id":"03teJdzfrHWx"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Converting Excel file to CSV for better compatibility...\n","Successfully converted Excel to CSV: /content/drive/MyDrive/Colab Notebooks/preprocessed_datasets/paws_nepodvojene_filtrirane_parafraze_00.csv\n","Starting Spark-powered paraphrase analysis pipeline at 16:10:13\n","Processing dataset: paws_nepodvojene_filtrirane_parafraze_00\n","Initialized Spark with cuda device: Tesla T4\n","Loading data from /content/drive/MyDrive/Colab Notebooks/preprocessed_datasets/paws_nepodvojene_filtrirane_parafraze_00.csv\n","Reading as CSV file (extension: .csv)\n","Successfully read CSV with 29493 rows and columns: ['sentence_translation', 'paraphrase_translation']\n","Loaded 29493 sentence pairs\n","Preprocessing data with Spark...\n","Preprocessed 29493 rows using Spark\n","Saved preprocessed data to /content/drive/MyDrive/Colab Notebooks/preprocessed_datasets/paraphrase_analysis_results_paws_paws_nepodvojene_filtrirane_parafraze_00_preprocessed.csv\n","Calculating embedding metrics with Spark...\n","Calculating LaBSE similarities...\n","Calculating Sentence-Transformer similarities...\n","Calculated embedding metrics for 29493 rows using Spark\n","Saved embedding results to /content/drive/MyDrive/Colab Notebooks/preprocessed_datasets/paraphrase_analysis_results_paws_paws_nepodvojene_filtrirane_parafraze_00_embeddings.csv\n","Calculating linguistic metrics with Spark...\n","Calculating linguistic metrics with Spark...\n","Calculated linguistic metrics for 29493 rows using Spark\n","Saved linguistic analysis to /content/drive/MyDrive/Colab Notebooks/preprocessed_datasets/paraphrase_analysis_results_paws_paws_nepodvojene_filtrirane_parafraze_00_linguistic.csv\n","Ensemble scoring...\n","Ensemble scoring failed: cannot access local variable 'col' where it is not associated with a value\n","Using fallback ensemble scoring method...\n","Calculated fallback ensemble score using 5 metrics with weights: {'labse_similarity': 0.27272727272727276, 'laser_similarity': 0.27272727272727276, 'jaccard_similarity': 0.09090909090909093, 'length_ratio': 0.09090909090909093, 'meteor_score': 0.27272727272727276}\n","Saving final results to /content/drive/MyDrive/Colab Notebooks/preprocessed_datasets/paraphrase_analysis_results_paws_paws_nepodvojene_filtrirane_parafraze_00.csv\n","Generating visualizations...\n","Basic visualizations saved to /content/drive/MyDrive/Colab Notebooks/preprocessed_datasets/visualizations\n","Visualizations saved to /content/drive/MyDrive/Colab Notebooks/preprocessed_datasets/visualizations\n","Pipeline completed in 365.89 seconds\n","Spark session stopped\n","Pipeline execution complete.\n","Filtering module not found. Using local implementation.\n","\n","Enhancing dataset with metadata and filtering...\n","\n","Adding metadata and filtering dataset with 29493 pairs...\n","Input columns: ['sentence_translation', 'paraphrase_translation', 'norm_sentence_translation', 'norm_paraphrase_translation', 'labse_similarity', 'laser_similarity', 'jaccard_similarity', 'length_ratio', 'meteor_score', 'ensemble_score', 'is_paraphrase']\n","Found 386 identical pairs (1.31%)\n","Removed 386 identical sentence pairs\n","Columns after metadata: ['sentence_translation', 'paraphrase_translation', 'norm_sentence_translation', 'norm_paraphrase_translation', 'labse_similarity', 'laser_similarity', 'jaccard_similarity', 'length_ratio', 'meteor_score', 'ensemble_score', 'is_paraphrase', 'length_s1', 'length_s2', 'string_similarity', 'is_identical']\n","Full dataset with metadata saved to /content/drive/MyDrive/Colab Notebooks/preprocessed_datasets/paraphrase_analysis_results_paws_paws_nepodvojene_filtrirane_parafraze_00_with_metadata.csv\n","Filtered dataset saved to /content/drive/MyDrive/Colab Notebooks/preprocessed_datasets/paraphrase_analysis_results_paws_paws_nepodvojene_filtrirane_parafraze_00_filtered.csv\n","Analysis module not found. Using local implementation.\n","\n","Analyzing results...\n","Basic visualizations saved to /content/drive/MyDrive/Colab Notebooks/preprocessed_datasets/analysis\n","Analysis complete.\n","Statistics saved to /content/drive/MyDrive/Colab Notebooks/preprocessed_datasets/analysis/statistics.json\n"]}]},{"cell_type":"markdown","source":["## Basic Statistical Analysis of the Datasets"],"metadata":{"id":"y2rWRZKQ_-GX"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from scipy import stats\n","\n","# Load dataset\n","base_dir = \"/content/drive/MyDrive/Colab Notebooks/preprocessed_datasets\"\n","\n","#dataset = \"predprocesiranje_msr_paired_cleaned\"\n","#dataset = \"paranmt_small_translated_cleaned_00\"\n","#dataset = \"processed_quora_clean_00\"\n","#dataset = \"paws_nepodvojene_filtrirane_parafraze_00\"\n","\n","input_file = f\"{base_dir}/paraphrase_analysis_results_{dataset.split('_')[0]}_{dataset}.csv\"\n","output_file = f\"{base_dir}/paraphrase_analysis_results_{dataset.split('_')[0]}_{dataset}_analysis.csv\"\n","\n","# Read the Excel file\n","print(f\"Loading dataset from {input_file}...\")\n","df = pd.read_csv(input_file)\n","\n","# Display basic information about the dataset\n","print(\"\\nDataset Overview:\")\n","print(f\"Total number of rows: {len(df)}\")\n","print(f\"Columns: {', '.join(df.columns)}\")\n","\n","# Basic statistics for is_paraphrase column\n","print(\"\\nAnalyzing 'is_paraphrase' column...\")\n","if 'is_paraphrase' in df.columns:\n","    # Distribution of is_paraphrase values\n","    paraphrase_counts = df['is_paraphrase'].value_counts()\n","    paraphrase_percent = df['is_paraphrase'].value_counts(normalize=True) * 100\n","\n","    print(\"\\nDistribution of is_paraphrase values:\")\n","    for value in sorted(paraphrase_counts.index):\n","        print(f\"Value {value}: {paraphrase_counts[value]} occurrences ({paraphrase_percent[value]:.2f}%)\")\n","\n","    # Check data type and unique values\n","    print(f\"\\nData type of is_paraphrase: {df['is_paraphrase'].dtype}\")\n","    print(f\"Unique values in is_paraphrase: {sorted(df['is_paraphrase'].unique())}\")\n","\n","    # Create a results dataframe\n","    results = pd.DataFrame({\n","        'metric': ['total_pairs', 'is_paraphrase_true', 'is_paraphrase_false', 'percent_paraphrase'],\n","        'value': [\n","            len(df),\n","            paraphrase_counts.get(1, 0) if 1 in paraphrase_counts else paraphrase_counts.get(True, 0),\n","            paraphrase_counts.get(0, 0) if 0 in paraphrase_counts else paraphrase_counts.get(False, 0),\n","            paraphrase_percent.get(1, 0) if 1 in paraphrase_percent else paraphrase_percent.get(True, 0)\n","        ]\n","    })\n","\n","    # Save results to CSV\n","    results.to_csv(output_file, index=False)\n","    print(f\"\\nResults saved to {output_file}\")\n","\n","    # Create visualization of the distribution\n","    plt.figure(figsize=(10, 6))\n","    ax = sns.countplot(x='is_paraphrase', data=df)\n","    plt.title('Distribution of Paraphrase vs. Non-Paraphrase Pairs')\n","    plt.xlabel('Is Paraphrase')\n","    plt.ylabel('Count')\n","\n","    # Add count labels on bars\n","    for p in ax.patches:\n","        ax.annotate(f'{p.get_height()}',\n","                   (p.get_x() + p.get_width() / 2., p.get_height()),\n","                   ha = 'center', va = 'bottom')\n","\n","    plt.savefig(f\"{base_dir}/paraphrase_distribution_{dataset.split('_')[0]}.png\")\n","    print(f\"Visualization saved to {base_dir}/paraphrase_distribution_{dataset.split('_')[0]}.png\")\n","\n","    # Check for additional analysis possibilities\n","    if 'sentence1' in df.columns and 'sentence2' in df.columns:\n","        print(\"\\nAdditional sentence pair analysis:\")\n","        # Calculate sentence lengths\n","        df['sent1_length'] = df['sentence1'].apply(lambda x: len(str(x).split()))\n","        df['sent2_length'] = df['sentence2'].apply(lambda x: len(str(x).split()))\n","        df['length_diff'] = abs(df['sent1_length'] - df['sent2_length'])\n","\n","        # Group by is_paraphrase and calculate average length differences\n","        length_diff_by_type = df.groupby('is_paraphrase')['length_diff'].mean()\n","        print(\"Average absolute word count difference between sentence pairs:\")\n","        for value in sorted(length_diff_by_type.index):\n","            print(f\"is_paraphrase={value}: {length_diff_by_type[value]:.2f} words\")\n","\n","        # Add this information to results\n","        for value in sorted(length_diff_by_type.index):\n","            value_str = 'true' if value == 1 or value == True else 'false'\n","            results = results.append({\n","                'metric': f'avg_length_diff_paraphrase_{value_str}',\n","                'value': length_diff_by_type[value]\n","            }, ignore_index=True)\n","\n","        # Update the CSV\n","        results.to_csv(output_file, index=False)\n","        print(f\"Updated results saved to {output_file}\")\n","else:\n","    print(\"Error: 'is_paraphrase' column not found in the dataset.\")\n","    print(f\"Available columns: {', '.join(df.columns)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":879},"id":"o5T00cnP_80V","executionInfo":{"status":"ok","timestamp":1742839843059,"user_tz":-60,"elapsed":817,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"99b665df-8dfb-419e-d559-d49855c1b84c"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading dataset from /content/drive/MyDrive/Colab Notebooks/preprocessed_datasets/paraphrase_analysis_results_predprocesiranje_predprocesiranje_msr_paired_cleaned.csv...\n","\n","Dataset Overview:\n","Total number of rows: 4798\n","Columns: sentence_translation, paraphrase_translation, norm_sentence_translation, norm_paraphrase_translation, labse_similarity, laser_similarity, jaccard_similarity, length_ratio, meteor_score, ensemble_score, is_paraphrase\n","\n","Analyzing 'is_paraphrase' column...\n","\n","Distribution of is_paraphrase values:\n","Value False: 3713 occurrences (77.39%)\n","Value True: 1085 occurrences (22.61%)\n","\n","Data type of is_paraphrase: bool\n","Unique values in is_paraphrase: [np.False_, np.True_]\n","\n","Results saved to /content/drive/MyDrive/Colab Notebooks/preprocessed_datasets/paraphrase_analysis_results_predprocesiranje_predprocesiranje_msr_paired_cleaned_analysis.csv\n","Visualization saved to /content/drive/MyDrive/Colab Notebooks/preprocessed_datasets/paraphrase_distribution_predprocesiranje.png\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x600 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["## Cross-validation with Splitting Data into Train, Validation, and Test Sets"],"metadata":{"id":"nDzg-JLTWmWN"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split, KFold, ParameterGrid\n","from sklearn.metrics import (\n","    classification_report, accuracy_score,\n","    precision_recall_fscore_support, confusion_matrix,\n","    precision_recall_curve, average_precision_score, roc_curve, auc\n",")\n","from tqdm.notebook import tqdm\n","\n","# Function to split dataset (simplified from previous code)\n","def prepare_dataset(df, test_size=0.2, val_size=0.25, random_state=42):\n","    \"\"\"Split a dataset into train, validation, and test sets.\"\"\"\n","    X = df[['labse_similarity', 'laser_similarity', 'meteor_score', 'length_ratio', 'jaccard_similarity']]\n","    y = df['is_paraphrase']  # Binary label\n","\n","    X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n","    X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=val_size, random_state=random_state, stratify=y_temp)\n","\n","    print(f\"Training set: {X_train.shape[0]} samples\")\n","    print(f\"Validation set: {X_val.shape[0]} samples\")\n","    print(f\"Test set: {X_test.shape[0]} samples\")\n","\n","    return X_train, X_val, X_test, y_train, y_val, y_test\n","\n","# Calculate weighted score for a given set of weights\n","def calculate_weighted_score(X, weights):\n","    \"\"\"Calculate weighted scores given features and weights.\"\"\"\n","    return (\n","        weights[0] * X['labse_similarity'] +\n","        weights[1] * X['laser_similarity'] +\n","        weights[2] * X['meteor_score'] +\n","        weights[3] * X['length_ratio'] +\n","        weights[4] * X['jaccard_similarity']\n","    )\n","\n","# Calculate binary predictions based on threshold\n","def get_predictions(scores, threshold):\n","    \"\"\"Convert scores to binary predictions based on threshold.\"\"\"\n","    return (scores >= threshold).astype(int)\n","\n","# Evaluate performance for a given set of weights and threshold\n","def evaluate_performance(X, y_true, weights, threshold):\n","    \"\"\"Evaluate performance metrics for given weights and threshold.\"\"\"\n","    scores = calculate_weighted_score(X, weights)\n","    y_pred = get_predictions(scores, threshold)\n","\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n","\n","    return {\n","        'accuracy': accuracy,\n","        'precision': precision,\n","        'recall': recall,\n","        'f1': f1\n","    }\n","\n","# Comprehensive cross-validation with detailed analysis\n","def detailed_cross_validation(X, y, param_grid, n_splits=5, random_state=42):\n","    \"\"\"\n","    Perform detailed cross-validation to find optimal weights and threshold.\n","\n","    Args:\n","        X: Features DataFrame\n","        y: Target labels\n","        param_grid: Dictionary of parameter ranges to search\n","        n_splits: Number of CV folds\n","        random_state: For reproducibility\n","\n","    Returns:\n","        results_df: DataFrame with all results\n","        best_params: Dictionary with best parameters\n","    \"\"\"\n","    # Setup K-fold cross-validation\n","    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n","\n","    # Generate all parameter combinations\n","    param_combinations = list(ParameterGrid(param_grid))\n","    print(f\"Testing {len(param_combinations)} parameter combinations with {n_splits}-fold cross-validation\")\n","\n","    # Store all results\n","    all_results = []\n","\n","    # Iterate through all parameter combinations\n","    for params in tqdm(param_combinations):\n","        # Extract weights and threshold\n","        weights = [\n","            params['weight_labse'],\n","            params['weight_laser'],\n","            params['weight_meteor'],\n","            params['weight_length'],\n","            params['weight_jaccard']\n","        ]\n","        threshold = params['threshold']\n","\n","        # Cross-validation scores for this parameter set\n","        cv_scores = {\n","            'accuracy': [],\n","            'precision': [],\n","            'recall': [],\n","            'f1': []\n","        }\n","\n","        # Perform k-fold cross-validation\n","        for train_idx, val_idx in kf.split(X):\n","            X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n","            y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n","\n","            # Evaluate on validation fold\n","            fold_performance = evaluate_performance(X_val_fold, y_val_fold, weights, threshold)\n","\n","            # Collect metrics\n","            for metric, value in fold_performance.items():\n","                cv_scores[metric].append(value)\n","\n","        # Calculate average scores across folds\n","        avg_scores = {metric: np.mean(scores) for metric, scores in cv_scores.items()}\n","        std_scores = {metric: np.std(scores) for metric, scores in cv_scores.items()}\n","\n","        # Store results\n","        result = {\n","            'weight_labse': params['weight_labse'],\n","            'weight_laser': params['weight_laser'],\n","            'weight_meteor': params['weight_meteor'],\n","            'weight_length': params['weight_length'],\n","            'weight_jaccard': params['weight_jaccard'],\n","            'threshold': params['threshold'],\n","            'accuracy_mean': avg_scores['accuracy'],\n","            'precision_mean': avg_scores['precision'],\n","            'recall_mean': avg_scores['recall'],\n","            'f1_mean': avg_scores['f1'],\n","            'accuracy_std': std_scores['accuracy'],\n","            'precision_std': std_scores['precision'],\n","            'recall_std': std_scores['recall'],\n","            'f1_std': std_scores['f1']\n","        }\n","\n","        all_results.append(result)\n","\n","    # Convert to DataFrame\n","    results_df = pd.DataFrame(all_results)\n","\n","    # Find best parameters based on F1 score\n","    best_idx = results_df['f1_mean'].idxmax()\n","    best_params = results_df.iloc[best_idx].to_dict()\n","\n","    print(\"\\nBest parameters:\")\n","    print(f\"  LaBSE weight: {best_params['weight_labse']:.3f}\")\n","    print(f\"  LASER weight: {best_params['weight_laser']:.3f}\")\n","    print(f\"  METEOR weight: {best_params['weight_meteor']:.3f}\")\n","    print(f\"  Length ratio weight: {best_params['weight_length']:.3f}\")\n","    print(f\"  Jaccard weight: {best_params['weight_jaccard']:.3f}\")\n","    print(f\"  Threshold: {best_params['threshold']:.3f}\")\n","    print(\"\\nBest cross-validation scores:\")\n","    print(f\"  Accuracy: {best_params['accuracy_mean']:.4f} ± {best_params['accuracy_std']:.4f}\")\n","    print(f\"  Precision: {best_params['precision_mean']:.4f} ± {best_params['precision_std']:.4f}\")\n","    print(f\"  Recall: {best_params['recall_mean']:.4f} ± {best_params['recall_std']:.4f}\")\n","    print(f\"  F1 Score: {best_params['f1_mean']:.4f} ± {best_params['f1_std']:.4f}\")\n","\n","    return results_df, best_params\n","\n","# Visualize cross-validation results\n","def visualize_cross_validation_results(results_df, best_params, save_dir=None):\n","    \"\"\"Create visualizations to analyze cross-validation results.\"\"\"\n","    # Set up figure\n","    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n","    axes = axes.flatten()\n","\n","    # 1. Feature weight importance\n","    weight_cols = ['weight_labse', 'weight_laser', 'weight_meteor', 'weight_length', 'weight_jaccard']\n","    best_weights = [best_params[col] for col in weight_cols]\n","    feature_names = ['LaBSE', 'LASER', 'METEOR', 'Length Ratio', 'Jaccard']\n","\n","    sns.barplot(x=feature_names, y=best_weights, palette='viridis', ax=axes[0])\n","    axes[0].set_title('Optimal Feature Weights')\n","    axes[0].set_ylabel('Weight')\n","    axes[0].set_ylim(0, max(best_weights) * 1.2)\n","\n","    # 2. Distribution of F1 scores\n","    sns.histplot(results_df['f1_mean'], kde=True, ax=axes[1])\n","    axes[1].axvline(best_params['f1_mean'], color='red', linestyle='--')\n","    axes[1].set_title('Distribution of F1 Scores')\n","    axes[1].set_xlabel('F1 Score')\n","\n","    # 3. Threshold vs F1 score\n","    threshold_f1 = results_df.groupby('threshold')['f1_mean'].mean().reset_index()\n","    sns.lineplot(x='threshold', y='f1_mean', data=threshold_f1, marker='o', ax=axes[2])\n","    axes[2].axvline(best_params['threshold'], color='red', linestyle='--')\n","    axes[2].set_title('Threshold vs F1 Score')\n","    axes[2].set_xlabel('Threshold')\n","    axes[2].set_ylabel('F1 Score')\n","\n","    # 4. Precision vs Recall tradeoff\n","    results_pivot = results_df.pivot_table(\n","        index='threshold',\n","        values=['precision_mean', 'recall_mean']\n","    ).reset_index()\n","\n","    sns.lineplot(x='recall_mean', y='precision_mean', data=results_pivot,\n","                 sort=False, marker='o', ax=axes[3])\n","    axes[3].set_title('Precision-Recall Tradeoff')\n","    axes[3].set_xlabel('Recall')\n","    axes[3].set_ylabel('Precision')\n","\n","    # 5. Weight correlation with F1 score\n","    corr_data = results_df[weight_cols + ['f1_mean']]\n","    corr_matrix = corr_data.corr()['f1_mean'].drop('f1_mean').sort_values(ascending=False)\n","\n","    sns.barplot(x=corr_matrix.index, y=corr_matrix.values, ax=axes[4], palette='coolwarm')\n","    axes[4].set_title('Feature Weight Correlation with F1 Score')\n","    axes[4].set_ylabel('Correlation')\n","    axes[4].set_xticklabels([x.replace('weight_', '') for x in corr_matrix.index], rotation=45)\n","\n","    # 6. Threshold impact on metrics\n","    metrics_by_threshold = results_df.groupby('threshold')[\n","        ['accuracy_mean', 'precision_mean', 'recall_mean', 'f1_mean']\n","    ].mean().reset_index()\n","\n","    metrics_melted = pd.melt(\n","        metrics_by_threshold,\n","        id_vars=['threshold'],\n","        value_vars=['accuracy_mean', 'precision_mean', 'recall_mean', 'f1_mean'],\n","        var_name='Metric',\n","        value_name='Score'\n","    )\n","\n","    metrics_melted['Metric'] = metrics_melted['Metric'].str.replace('_mean', '')\n","\n","    sns.lineplot(x='threshold', y='Score', hue='Metric', data=metrics_melted,\n","                 marker='o', ax=axes[5])\n","    axes[5].axvline(best_params['threshold'], color='black', linestyle='--')\n","    axes[5].set_title('Impact of Threshold on Metrics')\n","    axes[5].set_xlabel('Threshold')\n","    axes[5].set_ylabel('Score')\n","\n","    plt.tight_layout()\n","\n","    # Save the figure if save_dir is provided\n","    if save_dir:\n","        os.makedirs(save_dir, exist_ok=True)\n","        fig.savefig(f\"{save_dir}/feature_weights_analysis.png\", dpi=300, bbox_inches='tight')\n","\n","    plt.show()\n","\n","    # For the heatmaps\n","    weight_cols = ['weight_labse', 'weight_laser', 'weight_meteor', 'weight_length', 'weight_jaccard']\n","    for w1 in weight_cols:\n","        for w2 in weight_cols:\n","            if w1 < w2:  # Avoid duplicates\n","                # Create a new figure for each heatmap\n","                plt.figure(figsize=(10, 8))\n","                pivot = results_df.pivot_table(\n","                    index=w1,\n","                    columns=w2,\n","                    values='f1_mean',\n","                    aggfunc='mean'\n","                )\n","\n","                sns.heatmap(pivot, cmap='viridis', annot=True, fmt='.3f')\n","                plt.title(f'F1 Score: {w1.replace(\"weight_\", \"\")} vs {w2.replace(\"weight_\", \"\")}')\n","                plt.tight_layout()\n","\n","                # Save the heatmap if save_dir is provided\n","                if save_dir:\n","                    plt.savefig(f\"{save_dir}/heatmap_{w1.replace('weight_', '')}_{w2.replace('weight_', '')}.png\",\n","                               dpi=300, bbox_inches='tight')\n","\n","                plt.show()\n","\n","    return fig\n","\n","# 2. Update the test_optimized_weights function\n","def test_optimized_weights(X_val, y_val, best_params, save_dir=None):\n","    \"\"\"Test the optimized weights on validation data to verify performance.\"\"\"\n","    # Extract best weights and threshold\n","    best_weights = [\n","        best_params['weight_labse'],\n","        best_params['weight_laser'],\n","        best_params['weight_meteor'],\n","        best_params['weight_length'],\n","        best_params['weight_jaccard']\n","    ]\n","    best_threshold = best_params['threshold']\n","\n","    # Calculate scores and predictions\n","    scores = calculate_weighted_score(X_val, best_weights)\n","    y_pred = get_predictions(scores, best_threshold)\n","\n","    # Calculate metrics\n","    print(\"\\nPerformance on validation set:\")\n","    print(classification_report(y_val, y_pred))\n","\n","    # Create directory if saving\n","    if save_dir:\n","        os.makedirs(save_dir, exist_ok=True)\n","\n","    # Plot confusion matrix\n","    plt.figure(figsize=(8, 6))\n","    cm = confusion_matrix(y_val, y_pred)\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n","    plt.title('Confusion Matrix')\n","    plt.xlabel('Predicted')\n","    plt.ylabel('True')\n","\n","    if save_dir:\n","        plt.savefig(f\"{save_dir}/confusion_matrix.png\", dpi=300, bbox_inches='tight')\n","\n","    plt.show()\n","\n","    # Plot ROC curve\n","    plt.figure(figsize=(8, 6))\n","    fpr, tpr, _ = roc_curve(y_val, scores)\n","    roc_auc = auc(fpr, tpr)\n","\n","    plt.plot(fpr, tpr, color='darkorange', lw=2,\n","             label=f'ROC curve (area = {roc_auc:.3f})')\n","    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('Receiver Operating Characteristic')\n","    plt.legend(loc=\"lower right\")\n","\n","    if save_dir:\n","        plt.savefig(f\"{save_dir}/roc_curve.png\", dpi=300, bbox_inches='tight')\n","\n","    plt.show()\n","\n","    # Plot Precision-Recall curve\n","    plt.figure(figsize=(8, 6))\n","    precision, recall, _ = precision_recall_curve(y_val, scores)\n","    avg_precision = average_precision_score(y_val, scores)\n","\n","    plt.plot(recall, precision, color='blue', lw=2,\n","             label=f'Precision-Recall curve (AP = {avg_precision:.3f})')\n","    plt.axhline(y=sum(y_val)/len(y_val), color='red', linestyle='--',\n","                label=f'Baseline (prevalence = {sum(y_val)/len(y_val):.3f})')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('Recall')\n","    plt.ylabel('Precision')\n","    plt.title('Precision-Recall Curve')\n","    plt.legend(loc=\"lower left\")\n","\n","    if save_dir:\n","        plt.savefig(f\"{save_dir}/precision_recall_curve.png\", dpi=300, bbox_inches='tight')\n","\n","    plt.show()\n","\n","    # Score distribution analysis\n","    plt.figure(figsize=(10, 6))\n","\n","    # Create DataFrame with scores and actual labels\n","    score_df = pd.DataFrame({\n","        'Weighted Score': scores,\n","        'Is Paraphrase': y_val\n","    })\n","\n","    # Plot score distributions\n","    sns.histplot(data=score_df, x='Weighted Score', hue='Is Paraphrase',\n","                 element='step', stat='density', common_norm=False, bins=50)\n","    plt.axvline(best_threshold, color='red', linestyle='--',\n","                label=f'Threshold = {best_threshold:.3f}')\n","    plt.title('Distribution of Weighted Scores by Class')\n","    plt.legend()\n","\n","    if save_dir:\n","        plt.savefig(f\"{save_dir}/score_distributions.png\", dpi=300, bbox_inches='tight')\n","\n","    plt.show()\n","\n","    return scores, y_pred\n","\n","# Main execution for cross-validation analysis\n","def run_cross_validation_analysis(df, n_splits=5):\n","    \"\"\"Run the complete cross-validation analysis pipeline.\"\"\"\n","    # 1. Split the dataset\n","    X_train, X_val, X_test, y_train, y_val, y_test = prepare_dataset(df)\n","\n","    # 2. Define parameter grid for cross-validation\n","    param_grid = {\n","        'weight_labse': np.linspace(0.1, 0.5, 5),\n","        'weight_laser': np.linspace(0.1, 0.5, 5),\n","        'weight_meteor': np.linspace(0.1, 0.5, 5),\n","        'weight_length': np.linspace(0.05, 0.25, 5),\n","        'weight_jaccard': np.linspace(0.05, 0.25, 5),\n","        'threshold': np.linspace(0.4, 0.8, 5)\n","    }\n","\n","    # 3. Perform detailed cross-validation\n","    print(f\"Running {n_splits}-fold cross-validation...\")\n","    results_df, best_params = detailed_cross_validation(X_train, y_train, param_grid, n_splits=n_splits)\n","\n","    # 4. Visualize cross-validation results\n","    print(\"\\nVisualizing cross-validation results...\")\n","    visualize_cross_validation_results(results_df, best_params)\n","\n","    # 5. Test optimized weights on validation set\n","    print(\"\\nTesting optimized weights on validation set...\")\n","    scores, predictions = test_optimized_weights(X_val, y_val, best_params)\n","\n","    # 6. Save optimized weights for later use\n","    optimized_weights = {\n","        'labse': best_params['weight_labse'],\n","        'laser': best_params['weight_laser'],\n","        'meteor': best_params['weight_meteor'],\n","        'length_ratio': best_params['weight_length'],\n","        'jaccard': best_params['weight_jaccard'],\n","        'threshold': best_params['threshold']\n","    }\n","\n","    return results_df, best_params, optimized_weights\n","\n","# Function to perform sensitivity analysis on the weights\n","def weight_sensitivity_analysis(X_val, y_val, best_params, n_points=20, save_dir=None):\n","    \"\"\"\n","    Analyze how small changes to each weight affect performance.\n","\n","    Args:\n","        X_val: Validation features\n","        y_val: Validation labels\n","        best_params: Best parameters from cross-validation\n","        n_points: Number of test points to use per weight\n","\n","    Returns:\n","        sensitivity_results: DataFrame with sensitivity analysis results\n","    \"\"\"\n","    print(\"\\nPerforming weight sensitivity analysis...\")\n","\n","    # Extract best weights and threshold\n","    best_weights = {\n","        'weight_labse': best_params['weight_labse'],\n","        'weight_laser': best_params['weight_laser'],\n","        'weight_meteor': best_params['weight_meteor'],\n","        'weight_length': best_params['weight_length'],\n","        'weight_jaccard': best_params['weight_jaccard']\n","    }\n","    best_threshold = best_params['threshold']\n","\n","    # Map weight names to indices\n","    weight_indices = {\n","        'weight_labse': 0,\n","        'weight_laser': 1,\n","        'weight_meteor': 2,\n","        'weight_length': 3,\n","        'weight_jaccard': 4\n","    }\n","\n","    # Store results\n","    sensitivity_results = []\n","\n","    # For each weight, vary it while keeping others constant\n","    for weight_name, base_value in best_weights.items():\n","        weight_idx = weight_indices[weight_name]\n","\n","        # Determine range to test (±50% of the original value)\n","        min_val = max(0.01, base_value * 0.5)\n","        max_val = base_value * 1.5\n","        test_values = np.linspace(min_val, max_val, n_points)\n","\n","        for test_value in test_values:\n","            # Create a copy of best weights\n","            current_weights = list(best_weights.values())\n","            # Modify the weight being tested\n","            current_weights[weight_idx] = test_value\n","\n","            # Calculate performance metrics\n","            scores = calculate_weighted_score(X_val, current_weights)\n","            y_pred = get_predictions(scores, best_threshold)\n","\n","            accuracy = accuracy_score(y_val, y_pred)\n","            precision, recall, f1, _ = precision_recall_fscore_support(y_val, y_pred, average='binary')\n","\n","            # Store results\n","            sensitivity_results.append({\n","                'weight_name': weight_name.replace('weight_', ''),\n","                'test_value': test_value,\n","                'percent_change': ((test_value - base_value) / base_value) * 100,\n","                'accuracy': accuracy,\n","                'precision': precision,\n","                'recall': recall,\n","                'f1': f1\n","            })\n","\n","    # Convert to DataFrame\n","    sensitivity_df = pd.DataFrame(sensitivity_results)\n","\n","# Create directory if saving\n","    if save_dir:\n","        os.makedirs(save_dir, exist_ok=True)\n","\n","    # Plot sensitivity results\n","    plt.figure(figsize=(15, 10))\n","    for weight_name in sensitivity_df['weight_name'].unique():\n","        subset = sensitivity_df[sensitivity_df['weight_name'] == weight_name]\n","        plt.plot(subset['percent_change'], subset['f1'],\n","                 marker='o', label=weight_name)\n","\n","    plt.axvline(x=0, color='gray', linestyle='--')\n","    plt.axhline(y=best_params['f1_mean'], color='red', linestyle='--',\n","                label='Best F1')\n","\n","    plt.title('Sensitivity Analysis: Impact of Weight Changes on F1 Score')\n","    plt.xlabel('Percent Change in Weight (%)')\n","    plt.ylabel('F1 Score')\n","    plt.legend()\n","    plt.grid(True)\n","\n","    if save_dir:\n","        plt.savefig(f\"{save_dir}/weight_sensitivity_f1.png\", dpi=300, bbox_inches='tight')\n","\n","    plt.show()\n","\n","    # Plot individual charts for each metric\n","    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n","    metrics = ['accuracy', 'precision', 'recall', 'f1']\n","\n","    for i, metric in enumerate(metrics):\n","        ax = axes[i//2, i%2]\n","        for weight_name in sensitivity_df['weight_name'].unique():\n","            subset = sensitivity_df[sensitivity_df['weight_name'] == weight_name]\n","            ax.plot(subset['percent_change'], subset[metric],\n","                    marker='o', label=weight_name)\n","\n","        ax.axvline(x=0, color='gray', linestyle='--')\n","        ax.set_title(f'Impact of Weight Changes on {metric.capitalize()}')\n","        ax.set_xlabel('Percent Change in Weight (%)')\n","        ax.set_ylabel(metric.capitalize())\n","        ax.grid(True)\n","        ax.legend()\n","\n","    plt.tight_layout()\n","\n","    if save_dir:\n","        plt.savefig(f\"{save_dir}/weight_sensitivity_all_metrics.png\", dpi=300, bbox_inches='tight')\n","\n","    plt.show()\n","\n","    return sensitivity_df\n","\n","# Usage example (assuming you have loaded your dataset):\n","# Example data prep (you would use your own dataset)\n","# import pandas as pd\n","# import numpy as np\n","# df = pd.DataFrame({\n","#     'labse_similarity': np.random.uniform(0.5, 1.0, 1000),\n","#     'laser_similarity': np.random.uniform(0.5, 1.0, 1000),\n","#     'meteor_score': np.random.uniform(0.3, 0.9, 1000),\n","#     'length_ratio': np.random.uniform(0.7, 1.3, 1000),\n","#     'jaccard_similarity': np.random.uniform(0.3, 0.8, 1000),\n","#     'is_paraphrase': np.random.randint(0, 2, 1000)\n","# })\n","#\n","# # Run the full analysis\n","# results_df, best_params, optimized_weights = run_cross_validation_analysis(df, n_splits=5)\n","#\n","# # Get validation data for sensitivity analysis\n","# X_train, X_val, X_test, y_train, y_val, y_test = prepare_dataset(df)\n","#\n","# # Run sensitivity analysis\n","# sensitivity_df = weight_sensitivity_analysis(X_val, y_val, best_params)\n","#\n","# # Print final optimized weights\n","# print(\"\\nFinal Optimized Weights:\")\n","# for metric, weight in optimized_weights.items():\n","#     print(f\"  {metric}: {weight:.4f}\")"],"metadata":{"id":"P6ANNQbVW1bk","executionInfo":{"status":"ok","timestamp":1742893594786,"user_tz":-60,"elapsed":38,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import os\n","from google.colab import drive\n","from tqdm.notebook import tqdm\n","import time\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","\n","# Function to load and prepare dataset\n","def load_dataset(input_file):\n","    \"\"\"Load dataset from CSV and prepare it for analysis.\"\"\"\n","    print(f\"Loading dataset from: {input_file}\")\n","\n","    try:\n","        # Load the dataset\n","        df = pd.read_csv(input_file)\n","\n","        # Print basic info\n","        print(f\"Dataset loaded successfully. Shape: {df.shape}\")\n","        print(\"\\nColumn information:\")\n","        for col in df.columns:\n","            print(f\"  - {col}: {df[col].dtype}\")\n","\n","        # Check for missing values\n","        missing_values = df.isnull().sum()\n","        if missing_values.sum() > 0:\n","            print(\"\\nMissing values found:\")\n","            print(missing_values[missing_values > 0])\n","\n","            # Drop rows with missing values in key columns\n","            key_columns = ['labse_similarity', 'laser_similarity', 'meteor_score',\n","                          'length_ratio', 'jaccard_similarity', 'is_paraphrase']\n","            df_cleaned = df.dropna(subset=key_columns)\n","            print(f\"Dropped {df.shape[0] - df_cleaned.shape[0]} rows with missing values in key columns\")\n","            df = df_cleaned\n","\n","        # Ensure binary labels for is_paraphrase\n","        if 'is_paraphrase' in df.columns:\n","            df['is_paraphrase'] = df['is_paraphrase'].astype(int)\n","            print(f\"\\nClass distribution:\")\n","            print(df['is_paraphrase'].value_counts())\n","        else:\n","            raise ValueError(\"The dataset doesn't contain 'is_paraphrase' column\")\n","\n","        # Check that all similarity metrics are present\n","        required_columns = ['labse_similarity', 'laser_similarity', 'meteor_score',\n","                           'length_ratio', 'jaccard_similarity']\n","\n","        missing_columns = [col for col in required_columns if col not in df.columns]\n","        if missing_columns:\n","            raise ValueError(f\"Missing required columns: {', '.join(missing_columns)}\")\n","\n","        # Print summary statistics for similarity metrics\n","        print(\"\\nSummary statistics for similarity metrics:\")\n","        print(df[required_columns].describe().round(3))\n","\n","        # Create a histogram for each similarity metric\n","        plt.figure(figsize=(15, 10))\n","        for i, col in enumerate(required_columns, 1):\n","            plt.subplot(2, 3, i)\n","            sns.histplot(data=df, x=col, hue='is_paraphrase', element='step',\n","                         common_norm=False, bins=30)\n","            plt.title(f'Distribution of {col}')\n","        plt.tight_layout()\n","        plt.show()\n","\n","        return df\n","\n","    except Exception as e:\n","        print(f\"Error loading dataset: {e}\")\n","        return None\n","\n","def analyze_dataset(dataset_name, base_dir, n_splits=5):\n","    \"\"\"Run the complete analysis pipeline on a specific dataset.\"\"\"\n","    start_time = time.time()\n","\n","    # Construct file paths\n","    input_file = f\"{base_dir}/paraphrase_analysis_results_{dataset_name.split('_')[0]}_{dataset_name}.csv\"\n","    output_file = f\"{base_dir}/paraphrase_analysis_results_{dataset_name.split('_')[0]}_{dataset_name}_crossvalidation.csv\"\n","\n","    # Create a directory for visualizations - MOVED THIS UP\n","    viz_dir = f\"{base_dir}/visualizations_{dataset_name}\"\n","    os.makedirs(viz_dir, exist_ok=True)\n","\n","    print(f\"=\" * 80)\n","    print(f\"ANALYZING DATASET: {dataset_name}\")\n","    print(f\"=\" * 80)\n","\n","    # Step 1: Load the dataset\n","    df = load_dataset(input_file)\n","    if df is None:\n","        print(f\"Skipping analysis for {dataset_name} due to loading errors.\")\n","        return None\n","\n","    # Step 2: Split the dataset into train, validation, and test sets\n","    X_train, X_val, X_test, y_train, y_val, y_test = prepare_dataset(df)\n","\n","    # Step 3: Define parameter grid for cross-validation\n","    param_grid = {\n","        'weight_labse': np.linspace(0.1, 0.5, 5),\n","        'weight_laser': np.linspace(0.1, 0.5, 5),\n","        'weight_meteor': np.linspace(0.1, 0.5, 5),\n","        'weight_length': np.linspace(0.05, 0.25, 5),\n","        'weight_jaccard': np.linspace(0.05, 0.25, 5),\n","        'threshold': np.linspace(0.4, 0.8, 5)\n","    }\n","\n","    # Step 4: Perform detailed cross-validation\n","    print(f\"\\nRunning {n_splits}-fold cross-validation...\")\n","    results_df, best_params = detailed_cross_validation(X_train, y_train, param_grid, n_splits=n_splits)\n","\n","    # Step 5: Visualize cross-validation results\n","    print(\"\\nVisualizing cross-validation results...\")\n","    visualize_cross_validation_results(results_df, best_params, save_dir=viz_dir)\n","\n","    # Step 6: Test optimized weights on validation set\n","    print(\"\\nTesting optimized weights on validation set...\")\n","    scores, predictions = test_optimized_weights(X_val, y_val, best_params, save_dir=viz_dir)\n","\n","    # Step 7: Perform sensitivity analysis\n","    print(\"\\nPerforming sensitivity analysis...\")\n","    sensitivity_df = weight_sensitivity_analysis(X_val, y_val, best_params, save_dir=viz_dir)\n","\n","    # Step 8: Evaluate on the test set\n","    print(\"\\nEvaluating final performance on test set...\")\n","    best_weights = [\n","        best_params['weight_labse'],\n","        best_params['weight_laser'],\n","        best_params['weight_meteor'],\n","        best_params['weight_length'],\n","        best_params['weight_jaccard']\n","    ]\n","    test_scores = calculate_weighted_score(X_test, best_weights)\n","    test_preds = get_predictions(test_scores, best_params['threshold'])\n","\n","    print(\"\\nFinal performance on test set:\")\n","    print(classification_report(y_test, test_preds))\n","\n","    # Step 9: Save results\n","    print(f\"\\nSaving analysis results to: {output_file}\")\n","\n","    # Prepare results summary\n","    results_summary = {\n","        'dataset': dataset_name,\n","        'samples': len(df),\n","        'paraphrase_ratio': df['is_paraphrase'].mean(),\n","        'weight_labse': best_params['weight_labse'],\n","        'weight_laser': best_params['weight_laser'],\n","        'weight_meteor': best_params['weight_meteor'],\n","        'weight_length': best_params['weight_length'],\n","        'weight_jaccard': best_params['weight_jaccard'],\n","        'threshold': best_params['threshold'],\n","        'train_f1': best_params['f1_mean'],\n","        'val_f1': f1_score(y_val, predictions),\n","        'test_f1': f1_score(y_test, test_preds),\n","        'test_accuracy': accuracy_score(y_test, test_preds),\n","        'test_precision': precision_score(y_test, test_preds),\n","        'test_recall': recall_score(y_test, test_preds)\n","    }\n","\n","    # Save detailed results\n","    results_df.to_csv(output_file, index=False)\n","\n","    # Create a summary file\n","    summary_file = f\"{base_dir}/weight_optimization_summary.csv\"\n","    summary_df = pd.DataFrame([results_summary])\n","\n","    if os.path.exists(summary_file):\n","        existing_summary = pd.read_csv(summary_file)\n","        # Check if this dataset is already in the summary\n","        if dataset_name in existing_summary['dataset'].values:\n","            # Update the existing row\n","            existing_summary.loc[existing_summary['dataset'] == dataset_name] = summary_df.values[0]\n","        else:\n","            # Append the new row\n","            existing_summary = pd.concat([existing_summary, summary_df], ignore_index=True)\n","        existing_summary.to_csv(summary_file, index=False)\n","    else:\n","        summary_df.to_csv(summary_file, index=False)\n","\n","    elapsed_time = time.time() - start_time\n","    print(f\"\\nAnalysis completed in {elapsed_time:.2f} seconds ({elapsed_time/60:.2f} minutes)\")\n","\n","    return results_summary\n","\n","# Function to analyze multiple datasets\n","def analyze_multiple_datasets(dataset_list, base_dir, n_splits=5):\n","    \"\"\"Run analysis on multiple datasets and compare results.\"\"\"\n","    all_results = []\n","\n","    for dataset_name in dataset_list:\n","        result = analyze_dataset(dataset_name, base_dir, n_splits)\n","        if result is not None:\n","            all_results.append(result)\n","\n","    if len(all_results) > 1:\n","        # Create a directory for cross-dataset comparison visualizations\n","        comparison_dir = f\"{base_dir}/dataset_comparisons\"\n","        os.makedirs(comparison_dir, exist_ok=True)\n","\n","        # Create comparison visualizations\n","        results_comparison = pd.DataFrame(all_results)\n","\n","        # Compare weights across datasets\n","        plt.figure(figsize=(14, 8))\n","        metrics = ['weight_labse', 'weight_laser', 'weight_meteor', 'weight_length', 'weight_jaccard']\n","        weight_data = results_comparison[metrics].copy()\n","        weight_data.index = results_comparison['dataset']\n","\n","        ax = weight_data.plot(kind='bar', figsize=(14, 8))\n","        plt.title('Optimal Weights Comparison Across Datasets')\n","        plt.ylabel('Weight Value')\n","        plt.xlabel('Dataset')\n","        plt.legend(title='Metric')\n","        plt.grid(axis='y', linestyle='--', alpha=0.7)\n","        plt.tight_layout()\n","\n","        # Save weight comparison plot\n","        plt.savefig(f\"{comparison_dir}/weight_comparison.png\", dpi=300, bbox_inches='tight')\n","        plt.show()\n","\n","        # Compare performance across datasets\n","        plt.figure(figsize=(14, 8))\n","        performance_metrics = ['test_accuracy', 'test_precision', 'test_recall', 'test_f1']\n","        performance_data = results_comparison[performance_metrics].copy()\n","        performance_data.index = results_comparison['dataset']\n","\n","        ax = performance_data.plot(kind='bar', figsize=(14, 8))\n","        plt.title('Performance Metrics Comparison Across Datasets')\n","        plt.ylabel('Score')\n","        plt.xlabel('Dataset')\n","        plt.legend(title='Metric')\n","        plt.grid(axis='y', linestyle='--', alpha=0.7)\n","        plt.tight_layout()\n","\n","        # Save performance comparison plot\n","        plt.savefig(f\"{comparison_dir}/performance_comparison.png\", dpi=300, bbox_inches='tight')\n","        plt.show()\n","\n","        # Print summary table\n","        print(\"\\nCross-Dataset Comparison:\")\n","        comparison_table = results_comparison[['dataset', 'samples', 'paraphrase_ratio',\n","                                              'threshold', 'test_f1', 'test_precision',\n","                                              'test_recall']]\n","        print(comparison_table.to_string(index=False))\n","\n","        # Save comparison table as CSV\n","        comparison_table.to_csv(f\"{comparison_dir}/dataset_comparison_summary.csv\", index=False)\n","\n","        # Optional: Create a heatmap of the weights\n","        plt.figure(figsize=(12, 8))\n","        weight_data_normalized = weight_data.div(weight_data.sum(axis=1), axis=0)  # Normalize for better visualization\n","        sns.heatmap(weight_data_normalized, annot=True, cmap='viridis', fmt='.2f')\n","        plt.title('Relative Importance of Similarity Metrics Across Datasets')\n","        plt.tight_layout()\n","\n","        # Save weight heatmap\n","        plt.savefig(f\"{comparison_dir}/weight_heatmap.png\", dpi=300, bbox_inches='tight')\n","        plt.show()\n","\n","    return all_results\n","\n","# Add required imports for evaluate_performance function\n","from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, classification_report\n","\n","# Main execution block\n","if __name__ == \"__main__\":\n","    # Base directory for datasets\n","    base_dir = \"/content/drive/MyDrive/Colab Notebooks/preprocessed_datasets\"\n","\n","    # Individual dataset analysis\n","    # Choose one of these approaches:\n","\n","    # Option 1: Analyze a single dataset\n","    #dataset = \"paranmt_small_translated_cleaned_00\"  # Change to your desired dataset\n","    #results = analyze_dataset(dataset, base_dir, n_splits=5)\n","\n","    # Option 2: Analyze multiple datasets\n","    dataset_list = [\n","        \"predprocesiranje_msr_paired_cleaned\",\n","        \"paranmt_small_translated_cleaned_00\",\n","        \"processed_quora_clean_00\",\n","        \"paws_nepodvojene_filtrirane_parafraze_00\"\n","    ]\n","    results = analyze_multiple_datasets(dataset_list, base_dir, n_splits=5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f7c604680eb0449585cdc0be1dc92bdf","deb162482986433ea34ff79463194b2b","0eda439bfbd94e5baf173d078fbfb002","5f101e0a6e034227828955b1605b4bc4","72ae29eb5f9d4b8381df7f614bce70da","376f6f13d1df492b879131562b525178","6382ee4e63b247d487677fe72f7b4141","f7a487a9e8554ad59bfbf58db4dd4c1e","dbe12e6a5a834759a8c2ca18a3d6a780","a7ef4f3248784490bc873d5b35c496e4","cac0d1acc1bf41378ca3640d2ee3adec","cbe755f789df4150b44eca81c7272a8e","629ecbb5d7d5405b805e307a64656da4","eb401c48e452472399e144567ccf517d","b5562fdbd1b5466dbfc5b630f76a4512","45f00cce07384502997e21f6f87a8665","8252dc5cb6e14ab3ac3b616ac0dbc30d","e04aefacdde64ef286bcc50f66677f6f","bb59746519ca4bec88d2af34a881bd86","b334019243b04b30b2e9ddc11e141b4c","69e03c6398ec436eb0b268fc0f995c17","1454a7c0837144669982c830cd2373d9","5184c5effb8c48ab86f4c822323bb4f4","3a2ed0a7420f4470bc104e5ecd811219","a88ba9a7d07b485c8536556ddb9ec4e1","6388f5abae4c435eb4323fca5e356c8a","16e5e789a59e4b04af86ac4d469831b2","62b15f533c714266bb8569759e555bf0","d3b8102ae7144c4796045f37ecfd5178","0b6be3fff88242f6b69d70916b1f68ae","1a3c13747995487ab8aa0dcd97a1d5cd","0738a1ca7bc84a0687656d4a0aa3a873","5c1126610b4a4ba6835aa77dffac7112","6cda1a10158b40b5addf593c00fb31e0","8b862bd8f33a4f7fa0f589f415f6cfa3","baecdefadca740beb01a21086d42e76d","f174fb46c0bc4e18b34299b118728981","8c33b28d87934a1a82264c7db9747a47","1fa91898583d4014b1e941ea714844f2","a6b2b061e475414fb0f4c7f0c3d77cd0","6e954e04348a4d1a9948f6cda49b87ec","1771c0dabac04710a3c00f222100a693","c4acfdbdb24842c7ab72b6a041bfa188","1fd3a0244da34920b1431423d43efbbb"],"output_embedded_package_id":"1ObkaGkbi9KMEo_wPElgAotUkl-07WXIz"},"id":"Eh3bu6rX5ktI","executionInfo":{"status":"ok","timestamp":1742895420268,"user_tz":-60,"elapsed":1818638,"user":{"displayName":"Alenka Zumer","userId":"03523294138110394084"}},"outputId":"5ad63725-9198-4ab1-d992-4cbcc1487b5a"},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["## Random Forest Model Training for Detecting Paraphrases"],"metadata":{"id":"gln9ELAsjCn6"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import (\n","    classification_report, accuracy_score,\n","    precision_recall_fscore_support, confusion_matrix,\n","    precision_recall_curve, average_precision_score, roc_curve, auc\n",")\n","from tqdm.notebook import tqdm\n","import time\n","import os\n","\n","# Function to split dataset (reused from existing code)\n","def prepare_dataset(df, test_size=0.2, val_size=0.25, random_state=42):\n","    \"\"\"Split a dataset into train, validation, and test sets.\"\"\"\n","    X = df[['labse_similarity', 'laser_similarity', 'meteor_score', 'length_ratio', 'jaccard_similarity']]\n","    y = df['is_paraphrase']  # Binary label\n","\n","    X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n","    X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=val_size, random_state=random_state, stratify=y_temp)\n","\n","    print(f\"Training set: {X_train.shape[0]} samples\")\n","    print(f\"Validation set: {X_val.shape[0]} samples\")\n","    print(f\"Test set: {X_test.shape[0]} samples\")\n","\n","    return X_train, X_val, X_test, y_train, y_val, y_test\n","\n","# Function to train and evaluate a Random Forest model\n","def train_random_forest(X_train, y_train, X_val, y_val, param_grid=None, cv=5, n_jobs=-1):\n","    \"\"\"\n","    Train a Random Forest model with optional hyperparameter tuning.\n","\n","    Args:\n","        X_train: Training features\n","        y_train: Training labels\n","        X_val: Validation features\n","        y_val: Validation labels\n","        param_grid: Dictionary of parameters for grid search (or None for default)\n","        cv: Number of cross-validation folds\n","        n_jobs: Number of parallel jobs for grid search\n","\n","    Returns:\n","        best_model: Trained Random Forest model\n","        cv_results: Cross-validation results\n","    \"\"\"\n","    print(\"Training Random Forest classifier...\")\n","\n","    # Default hyperparameters if none provided\n","    if param_grid is None:\n","        param_grid = {\n","            'n_estimators': [100, 200, 300],\n","            'max_depth': [None, 10, 20, 30],\n","            'min_samples_split': [2, 5, 10],\n","            'min_samples_leaf': [1, 2, 4],\n","            'max_features': ['sqrt', 'log2']\n","        }\n","\n","    # Initialize the model\n","    base_model = RandomForestClassifier(random_state=42)\n","\n","    # Grid search with cross-validation\n","    start_time = time.time()\n","    grid_search = GridSearchCV(\n","        estimator=base_model,\n","        param_grid=param_grid,\n","        cv=cv,\n","        scoring='f1',\n","        n_jobs=n_jobs,\n","        verbose=1\n","    )\n","\n","    # Fit the model\n","    grid_search.fit(X_train, y_train)\n","\n","    # Get best model\n","    best_model = grid_search.best_estimator_\n","\n","    elapsed_time = time.time() - start_time\n","    print(f\"Training completed in {elapsed_time:.2f} seconds\")\n","    print(f\"Best parameters: {grid_search.best_params_}\")\n","    print(f\"Best cross-validation score (F1): {grid_search.best_score_:.4f}\")\n","\n","    # Evaluate on validation set\n","    y_pred = best_model.predict(X_val)\n","    print(\"\\nValidation set performance:\")\n","    print(classification_report(y_val, y_pred))\n","\n","    return best_model, grid_search.cv_results_\n","\n","# Function to analyze feature importance\n","def analyze_feature_importance(model, feature_names, save_dir=None):\n","    \"\"\"\n","    Analyze and visualize feature importance from a trained Random Forest model.\n","\n","    Args:\n","        model: Trained Random Forest model\n","        feature_names: List of feature names\n","        save_dir: Directory to save visualizations (optional)\n","    \"\"\"\n","    # Get feature importances\n","    importances = model.feature_importances_\n","    indices = np.argsort(importances)[::-1]\n","\n","    # Print feature ranking\n","    print(\"\\nFeature ranking:\")\n","    for f in range(len(feature_names)):\n","        print(f\"{f+1}. {feature_names[indices[f]]} ({importances[indices[f]]:.4f})\")\n","\n","    # Plot feature importances\n","    plt.figure(figsize=(10, 6))\n","    plt.title(\"Feature importance\")\n","    plt.bar(range(len(feature_names)), importances[indices], align=\"center\")\n","    plt.xticks(range(len(feature_names)), [feature_names[i] for i in indices], rotation=45)\n","    plt.xlim([-1, len(feature_names)])\n","    plt.tight_layout()\n","\n","    if save_dir:\n","        os.makedirs(save_dir, exist_ok=True)\n","        plt.savefig(f\"{save_dir}/feature_importance.png\", dpi=300, bbox_inches='tight')\n","\n","    plt.show()\n","\n","    return importances, indices\n","\n","# Function to plot decision surface (for 2 most important features)\n","def plot_decision_boundaries(model, X, y, feature_indices, feature_names, save_dir=None):\n","    \"\"\"\n","    Plot the decision boundaries of a model using the two most important features.\n","\n","    Args:\n","        model: Trained model\n","        X: Feature matrix\n","        y: Target vector\n","        feature_indices: Indices of features to use (sorted by importance)\n","        feature_names: Names of features\n","        save_dir: Directory to save visualizations (optional)\n","    \"\"\"\n","    # Select the two most important features\n","    top_features = feature_indices[:2]\n","    X_reduced = X.iloc[:, top_features]\n","\n","    # Create a mesh grid\n","    h = 0.02  # step size\n","    x_min, x_max = X_reduced.iloc[:, 0].min() - 0.1, X_reduced.iloc[:, 0].max() + 0.1\n","    y_min, y_max = X_reduced.iloc[:, 1].min() - 0.1, X_reduced.iloc[:, 1].max() + 0.1\n","    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n","\n","    # Create a DataFrame with all combinations of the two features\n","    meshgrid_points = pd.DataFrame({\n","        feature_names[top_features[0]]: xx.ravel(),\n","        feature_names[top_features[1]]: yy.ravel()\n","    })\n","\n","    # For the model to work, we need all features, even those we're not plotting\n","    # Create a DataFrame with default values for the other features\n","    default_values = X.median()\n","    grid_data = pd.DataFrame()\n","    for col in X.columns:\n","        if col == feature_names[top_features[0]]:\n","            grid_data[col] = meshgrid_points[col]\n","        elif col == feature_names[top_features[1]]:\n","            grid_data[col] = meshgrid_points[col]\n","        else:\n","            grid_data[col] = default_values[col]\n","\n","    # Predict class labels\n","    Z = model.predict(grid_data)\n","    Z = Z.reshape(xx.shape)\n","\n","    # Plot decision boundaries\n","    plt.figure(figsize=(12, 10))\n","    plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.RdYlBu)\n","\n","    # Plot training points\n","    scatter = plt.scatter(\n","        X_reduced.iloc[:, 0], X_reduced.iloc[:, 1],\n","        c=y, edgecolors='k', cmap=plt.cm.RdYlBu\n","    )\n","    plt.legend(*scatter.legend_elements(), title=\"Classes\")\n","\n","    plt.xlabel(feature_names[top_features[0]])\n","    plt.ylabel(feature_names[top_features[1]])\n","    plt.title(f\"Decision Boundaries using {feature_names[top_features[0]]} and {feature_names[top_features[1]]}\")\n","    plt.xlim(xx.min(), xx.max())\n","    plt.ylim(yy.min(), yy.max())\n","\n","    if save_dir:\n","        os.makedirs(save_dir, exist_ok=True)\n","        plt.savefig(f\"{save_dir}/decision_boundaries.png\", dpi=300, bbox_inches='tight')\n","\n","    plt.show()\n","\n","# Function to evaluate model performance with detailed metrics and visualizations\n","def evaluate_model_performance(model, X, y, save_dir=None):\n","    \"\"\"\n","    Evaluate model performance with various metrics and visualizations.\n","\n","    Args:\n","        model: Trained model\n","        X: Feature matrix\n","        y: Target vector\n","        save_dir: Directory to save visualizations (optional)\n","    \"\"\"\n","    # Get predictions and probability scores\n","    y_pred = model.predict(X)\n","    y_prob = model.predict_proba(X)[:, 1]\n","\n","    # Calculate metrics\n","    accuracy = accuracy_score(y, y_pred)\n","    precision, recall, f1, _ = precision_recall_fscore_support(y, y_pred, average='binary')\n","\n","    # Print classification report\n","    print(\"\\nModel Performance:\")\n","    print(f\"Accuracy: {accuracy:.4f}\")\n","    print(f\"Precision: {precision:.4f}\")\n","    print(f\"Recall: {recall:.4f}\")\n","    print(f\"F1 Score: {f1:.4f}\")\n","    print(\"\\nDetailed Classification Report:\")\n","    print(classification_report(y, y_pred))\n","\n","    # Create directory if saving\n","    if save_dir:\n","        os.makedirs(save_dir, exist_ok=True)\n","\n","    # Plot confusion matrix\n","    plt.figure(figsize=(8, 6))\n","    cm = confusion_matrix(y, y_pred)\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n","    plt.title('Confusion Matrix')\n","    plt.xlabel('Predicted')\n","    plt.ylabel('True')\n","\n","    if save_dir:\n","        plt.savefig(f\"{save_dir}/confusion_matrix.png\", dpi=300, bbox_inches='tight')\n","\n","    plt.show()\n","\n","    # Plot ROC curve\n","    plt.figure(figsize=(8, 6))\n","    fpr, tpr, _ = roc_curve(y, y_prob)\n","    roc_auc = auc(fpr, tpr)\n","\n","    plt.plot(fpr, tpr, color='darkorange', lw=2,\n","             label=f'ROC curve (area = {roc_auc:.3f})')\n","    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('Receiver Operating Characteristic')\n","    plt.legend(loc=\"lower right\")\n","\n","    if save_dir:\n","        plt.savefig(f\"{save_dir}/roc_curve.png\", dpi=300, bbox_inches='tight')\n","\n","    plt.show()\n","\n","    # Plot Precision-Recall curve\n","    plt.figure(figsize=(8, 6))\n","    precision_curve, recall_curve, _ = precision_recall_curve(y, y_prob)\n","    avg_precision = average_precision_score(y, y_prob)\n","\n","    plt.plot(recall_curve, precision_curve, color='blue', lw=2,\n","             label=f'Precision-Recall curve (AP = {avg_precision:.3f})')\n","    plt.axhline(y=sum(y)/len(y), color='red', linestyle='--',\n","                label=f'Baseline (prevalence = {sum(y)/len(y):.3f})')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('Recall')\n","    plt.ylabel('Precision')\n","    plt.title('Precision-Recall Curve')\n","    plt.legend(loc=\"lower left\")\n","\n","    if save_dir:\n","        plt.savefig(f\"{save_dir}/precision_recall_curve.png\", dpi=300, bbox_inches='tight')\n","\n","    plt.show()\n","\n","    # Probability distribution by class\n","    plt.figure(figsize=(10, 6))\n","\n","    # Create DataFrame with scores and actual labels\n","    score_df = pd.DataFrame({\n","        'Probability': y_prob,\n","        'Is Paraphrase': y\n","    })\n","\n","    # Plot score distributions\n","    sns.histplot(data=score_df, x='Probability', hue='Is Paraphrase',\n","                 element='step', stat='density', common_norm=False, bins=50)\n","    plt.title('Distribution of Predicted Probabilities by Class')\n","    plt.legend(title='Actual Class')\n","\n","    if save_dir:\n","        plt.savefig(f\"{save_dir}/probability_distributions.png\", dpi=300, bbox_inches='tight')\n","\n","    plt.show()\n","\n","    return {\n","        'accuracy': accuracy,\n","        'precision': precision,\n","        'recall': recall,\n","        'f1': f1,\n","        'roc_auc': roc_auc,\n","        'avg_precision': avg_precision\n","    }\n","\n","# Complete the compare_with_weighted_approach function\n","def compare_with_weighted_approach(X, y, best_params_weighted, rf_model, save_dir=None):\n","    \"\"\"\n","    Compare Random Forest model performance with the weighted approach.\n","\n","    Args:\n","        X: Feature matrix\n","        y: Target vector\n","        best_params_weighted: Best parameters from weighted approach\n","        rf_model: Trained Random Forest model\n","        save_dir: Directory to save visualizations (optional)\n","\n","    Returns:\n","        comparison_results: Dictionary with performance metrics for both approaches\n","    \"\"\"\n","    # Extract weights and threshold from weighted approach\n","    weights = [\n","        best_params_weighted['weight_labse'],\n","        best_params_weighted['weight_laser'],\n","        best_params_weighted['weight_meteor'],\n","        best_params_weighted['weight_length'],\n","        best_params_weighted['weight_jaccard']\n","    ]\n","    threshold = best_params_weighted['threshold']\n","\n","    # Calculate scores for weighted approach\n","    weighted_scores = (\n","        weights[0] * X['labse_similarity'] +\n","        weights[1] * X['laser_similarity'] +\n","        weights[2] * X['meteor_score'] +\n","        weights[3] * X['length_ratio'] +\n","        weights[4] * X['jaccard_similarity']\n","    )\n","    weighted_preds = (weighted_scores >= threshold).astype(int)\n","\n","    # Get Random Forest predictions\n","    rf_preds = rf_model.predict(X)\n","    rf_prob = rf_model.predict_proba(X)[:, 1]\n","\n","    # Calculate metrics for both approaches\n","    weighted_accuracy = accuracy_score(y, weighted_preds)\n","    weighted_precision, weighted_recall, weighted_f1, _ = precision_recall_fscore_support(\n","        y, weighted_preds, average='binary'\n","    )\n","\n","    rf_accuracy = accuracy_score(y, rf_preds)\n","    rf_precision, rf_recall, rf_f1, _ = precision_recall_fscore_support(\n","        y, rf_preds, average='binary'\n","    )\n","\n","    # Print comparison\n","    print(\"\\nModel Comparison - Weighted Approach vs Random Forest:\")\n","    print(f\"{'Metric':<20} {'Weighted':<10} {'Random Forest':<15} {'Difference':<10}\")\n","    print(f\"{'-'*55}\")\n","    print(f\"{'Accuracy':<20} {weighted_accuracy:.4f}     {rf_accuracy:.4f}          {rf_accuracy-weighted_accuracy:+.4f}\")\n","    print(f\"{'Precision':<20} {weighted_precision:.4f}     {rf_precision:.4f}          {rf_precision-weighted_precision:+.4f}\")\n","    print(f\"{'Recall':<20} {weighted_recall:.4f}     {rf_recall:.4f}          {rf_recall-weighted_recall:+.4f}\")\n","    print(f\"{'F1 Score':<20} {weighted_f1:.4f}     {rf_f1:.4f}          {rf_f1-weighted_f1:+.4f}\")\n","\n","    # Create comparison visualizations\n","    if save_dir:\n","        os.makedirs(save_dir, exist_ok=True)\n","\n","        # 1. Bar chart comparing metrics\n","        metrics = ['Accuracy', 'Precision', 'Recall', 'F1']\n","        weighted_values = [weighted_accuracy, weighted_precision, weighted_recall, weighted_f1]\n","        rf_values = [rf_accuracy, rf_precision, rf_recall, rf_f1]\n","\n","        x = np.arange(len(metrics))\n","        width = 0.35\n","\n","        plt.figure(figsize=(12, 6))\n","        plt.bar(x - width/2, weighted_values, width, label='Weighted Approach')\n","        plt.bar(x + width/2, rf_values, width, label='Random Forest')\n","\n","        plt.xlabel('Metrics')\n","        plt.ylabel('Score')\n","        plt.title('Performance Comparison: Weighted Approach vs Random Forest')\n","        plt.xticks(x, metrics)\n","        plt.ylim(0, 1.0)\n","        plt.legend()\n","        plt.grid(axis='y', linestyle='--', alpha=0.7)\n","\n","        plt.savefig(f\"{save_dir}/model_comparison.png\", dpi=300, bbox_inches='tight')\n","        plt.show()\n","\n","        # 2. Combined ROC curves\n","        plt.figure(figsize=(8, 6))\n","\n","        # ROC for weighted approach\n","        fpr_weighted, tpr_weighted, _ = roc_curve(y, weighted_scores)\n","        roc_auc_weighted = auc(fpr_weighted, tpr_weighted)\n","        plt.plot(fpr_weighted, tpr_weighted, color='blue', lw=2,\n","                 label=f'Weighted (AUC = {roc_auc_weighted:.3f})')\n","\n","        # ROC for Random Forest\n","        fpr_rf, tpr_rf, _ = roc_curve(y, rf_prob)\n","        roc_auc_rf = auc(fpr_rf, tpr_rf)\n","        plt.plot(fpr_rf, tpr_rf, color='red', lw=2,\n","                 label=f'Random Forest (AUC = {roc_auc_rf:.3f})')\n","\n","        # Reference line\n","        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n","\n","        plt.xlim([0.0, 1.0])\n","        plt.ylim([0.0, 1.05])\n","        plt.xlabel('False Positive Rate')\n","        plt.ylabel('True Positive Rate')\n","        plt.title('ROC Curve Comparison')\n","        plt.legend(loc=\"lower right\")\n","\n","        plt.savefig(f\"{save_dir}/roc_comparison.png\", dpi=300, bbox_inches='tight')\n","        plt.show()\n","\n","    comparison_results = {\n","        'weighted': {\n","            'accuracy': weighted_accuracy,\n","            'precision': weighted_precision,\n","            'recall': weighted_recall,\n","            'f1': weighted_f1\n","        },\n","        'random_forest': {\n","            'accuracy': rf_accuracy,\n","            'precision': rf_precision,\n","            'recall': rf_recall,\n","            'f1': rf_f1\n","        }\n","    }\n","\n","    return comparison_results\n","\n","# Function to load and prepare dataset\n","def load_dataset(input_file):\n","    \"\"\"Load dataset from CSV and prepare it for analysis.\"\"\"\n","    print(f\"Loading dataset from: {input_file}\")\n","\n","    try:\n","        # Load the dataset\n","        df = pd.read_csv(input_file)\n","\n","        # Print basic info\n","        print(f\"Dataset loaded successfully. Shape: {df.shape}\")\n","        print(\"\\nColumn information:\")\n","        for col in df.columns:\n","            print(f\"  - {col}: {df[col].dtype}\")\n","\n","        # Check for missing values\n","        missing_values = df.isnull().sum()\n","        if missing_values.sum() > 0:\n","            print(\"\\nMissing values found:\")\n","            print(missing_values[missing_values > 0])\n","\n","            # Drop rows with missing values in key columns\n","            key_columns = ['labse_similarity', 'laser_similarity', 'meteor_score',\n","                          'length_ratio', 'jaccard_similarity', 'is_paraphrase']\n","            df_cleaned = df.dropna(subset=key_columns)\n","            print(f\"Dropped {df.shape[0] - df_cleaned.shape[0]} rows with missing values in key columns\")\n","            df = df_cleaned\n","\n","        # Ensure binary labels for is_paraphrase\n","        if 'is_paraphrase' in df.columns:\n","            df['is_paraphrase'] = df['is_paraphrase'].astype(int)\n","            print(f\"\\nClass distribution:\")\n","            print(df['is_paraphrase'].value_counts())\n","        else:\n","            raise ValueError(\"The dataset doesn't contain 'is_paraphrase' column\")\n","\n","        # Check that all similarity metrics are present\n","        required_columns = ['labse_similarity', 'laser_similarity', 'meteor_score',\n","                           'length_ratio', 'jaccard_similarity']\n","\n","        missing_columns = [col for col in required_columns if col not in df.columns]\n","        if missing_columns:\n","            raise ValueError(f\"Missing required columns: {', '.join(missing_columns)}\")\n","\n","        # Print summary statistics for similarity metrics\n","        print(\"\\nSummary statistics for similarity metrics:\")\n","        print(df[required_columns].describe().round(3))\n","\n","        return df\n","\n","    except Exception as e:\n","        print(f\"Error loading dataset: {e}\")\n","        return None\n","\n","# Function to run the entire random forest analysis pipeline on a dataset\n","def analyze_dataset_with_random_forest(dataset_name, base_dir, weighted_params=None, param_grid=None):\n","    \"\"\"\n","    Run Random Forest analysis on a specific dataset.\n","\n","    Args:\n","        dataset_name: Name of the dataset\n","        base_dir: Base directory for files\n","        weighted_params: Optional parameters from weighted approach for comparison\n","        param_grid: Optional custom parameter grid for Random Forest\n","    \"\"\"\n","    start_time = time.time()\n","\n","    # Construct file paths\n","    input_file = f\"{base_dir}/paraphrase_analysis_results_{dataset_name.split('_')[0]}_{dataset_name}.csv\"\n","\n","    # Create a directory for visualizations\n","    output_dir = f\"{base_dir}/rf_visualizations_{dataset_name}\"\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    print(f\"=\" * 80)\n","    print(f\"RANDOM FOREST ANALYSIS FOR DATASET: {dataset_name}\")\n","    print(f\"=\" * 80)\n","\n","    # Step 1: Load the dataset\n","    df = load_dataset(input_file)\n","    if df is None:\n","        print(f\"Skipping analysis for {dataset_name} due to loading errors.\")\n","        return None\n","\n","    # Save distribution plots with dataset name\n","    feature_cols = ['labse_similarity', 'laser_similarity', 'meteor_score',\n","                    'length_ratio', 'jaccard_similarity']\n","\n","    plt.figure(figsize=(15, 10))\n","    for i, col in enumerate(feature_cols, 1):\n","        plt.subplot(2, 3, i)\n","        sns.histplot(data=df, x=col, hue='is_paraphrase', element='step',\n","                     common_norm=False, bins=30)\n","        plt.title(f'Distribution of {col}')\n","\n","    plt.suptitle(f'Feature Distributions for {dataset_name}', fontsize=16)\n","    plt.tight_layout()\n","    plt.savefig(f\"{output_dir}/{dataset_name}_feature_distributions.png\", dpi=300, bbox_inches='tight')\n","    plt.show()\n","\n","    # Step 2: Split the dataset into train, validation, and test sets\n","    X_train, X_val, X_test, y_train, y_val, y_test = prepare_dataset(df)\n","\n","    # Step 3: Train Random Forest model\n","    print(\"\\nTraining Random Forest classifier...\")\n","    rf_model, cv_results = train_random_forest(X_train, y_train, X_val, y_val, param_grid=param_grid)\n","\n","    # Step 4: Analyze feature importance\n","    print(\"\\nAnalyzing feature importance...\")\n","    importances, importance_indices = analyze_feature_importance(\n","        rf_model,\n","        X_train.columns.tolist(),\n","        save_dir=output_dir\n","    )\n","\n","    # Step 5: Plot decision boundaries\n","    print(\"\\nPlotting decision boundaries...\")\n","    plot_decision_boundaries(\n","        rf_model,\n","        X_val,\n","        y_val,\n","        importance_indices,\n","        X_val.columns.tolist(),\n","        save_dir=output_dir\n","    )\n","\n","    # Step 6: Evaluate model performance on test set\n","    print(\"\\nEvaluating model performance on test set...\")\n","    test_performance = evaluate_model_performance(\n","        rf_model,\n","        X_test,\n","        y_test,\n","        save_dir=output_dir\n","    )\n","\n","    # Step 7: Compare with weighted approach (if provided)\n","    if weighted_params is not None:\n","        print(\"\\nComparing with weighted approach...\")\n","        comparison_results = compare_with_weighted_approach(\n","            X_test,\n","            y_test,\n","            weighted_params,\n","            rf_model,\n","            save_dir=output_dir\n","        )\n","\n","    # Step 8: Save model and results\n","    model_file = f\"{output_dir}/{dataset_name}_random_forest_model.pkl\"\n","    import pickle\n","    with open(model_file, 'wb') as f:\n","        pickle.dump(rf_model, f)\n","    print(f\"\\nModel saved to: {model_file}\")\n","\n","    # Save results summary\n","    results_summary = {\n","        'dataset': dataset_name,\n","        'samples': len(df),\n","        'paraphrase_ratio': df['is_paraphrase'].mean(),\n","        'best_parameters': rf_model.get_params(),\n","        'feature_importance': dict(zip(X_train.columns, rf_model.feature_importances_)),\n","        'test_performance': test_performance\n","    }\n","\n","    summary_file = f\"{output_dir}/{dataset_name}_rf_results_summary.json\"\n","    import json\n","    with open(summary_file, 'w') as f:\n","        json.dump(results_summary, f, indent=4)\n","    print(f\"Results summary saved to: {summary_file}\")\n","\n","    elapsed_time = time.time() - start_time\n","    print(f\"\\nAnalysis completed in {elapsed_time:.2f} seconds ({elapsed_time/60:.2f} minutes)\")\n","\n","    return results_summary\n","\n","# Function to analyze multiple datasets\n","def analyze_multiple_datasets_with_rf(dataset_list, base_dir, weighted_params_dict=None):\n","    \"\"\"\n","    Run Random Forest analysis on multiple datasets and compare results.\n","\n","    Args:\n","        dataset_list: List of dataset names\n","        base_dir: Base directory for files\n","        weighted_params_dict: Dictionary mapping dataset names to their weighted parameters\n","    \"\"\"\n","    all_results = []\n","\n","    for dataset_name in dataset_list:\n","        weighted_params = weighted_params_dict.get(dataset_name) if weighted_params_dict else None\n","        result = analyze_dataset_with_random_forest(dataset_name, base_dir, weighted_params)\n","        if result is not None:\n","            all_results.append(result)\n","\n","    if len(all_results) > 1:\n","        # Create a directory for cross-dataset comparison visualizations\n","        comparison_dir = f\"{base_dir}/rf_dataset_comparisons\"\n","        os.makedirs(comparison_dir, exist_ok=True)\n","\n","        # Create comparison visualizations\n","        results_comparison = pd.DataFrame(all_results)\n","\n","        # Extract test performance metrics\n","        test_metrics = []\n","        for result in all_results:\n","            metrics = result['test_performance']\n","            metrics['dataset'] = result['dataset']\n","            test_metrics.append(metrics)\n","\n","        perf_df = pd.DataFrame(test_metrics)\n","\n","        # Compare performance across datasets\n","        plt.figure(figsize=(14, 8))\n","        performance_metrics = ['accuracy', 'precision', 'recall', 'f1']\n","        perf_data = perf_df[performance_metrics + ['dataset']].copy()\n","        perf_data.set_index('dataset', inplace=True)\n","\n","        ax = perf_data.plot(kind='bar', figsize=(14, 8))\n","        plt.title('Random Forest Performance Metrics Across Datasets')\n","        plt.ylabel('Score')\n","        plt.xlabel('Dataset')\n","\n","        plt.legend(title='Metric')\n","        plt.grid(axis='y', linestyle='--', alpha=0.7)\n","\n","        plt.savefig(f\"{comparison_dir}/performance_comparison.png\", dpi=300, bbox_inches='tight')\n","        plt.show()\n","\n","        # Feature importance comparison across datasets\n","        # Extract feature importance from each dataset\n","        importance_df = pd.DataFrame()\n","\n","        for result in all_results:\n","            dataset = result['dataset']\n","            importance = result['feature_importance']\n","            importance['dataset'] = dataset\n","            importance_df = pd.concat([importance_df, pd.DataFrame([importance])], ignore_index=True)\n","\n","        # Create a heatmap of feature importance\n","        importance_pivot = importance_df.drop('dataset', axis=1)\n","        importance_pivot.index = importance_df['dataset']\n","\n","        plt.figure(figsize=(12, 8))\n","        sns.heatmap(importance_pivot, annot=True, cmap='viridis', fmt='.3f')\n","        plt.title('Feature Importance Comparison Across Datasets')\n","        plt.tight_layout()\n","\n","        plt.savefig(f\"{comparison_dir}/feature_importance_comparison.png\", dpi=300, bbox_inches='tight')\n","        plt.show()\n","\n","        # Save comparison results\n","        comparison_file = f\"{comparison_dir}/rf_dataset_comparison.csv\"\n","        perf_df.to_csv(comparison_file, index=False)\n","        print(f\"\\nComparison results saved to: {comparison_file}\")\n","\n","    return all_results\n","\n","# Function to load existing weighted parameters from previous analysis\n","def load_weighted_params(base_dir, dataset_name):\n","    \"\"\"\n","    Load previously optimized weighted parameters for a dataset.\n","\n","    Args:\n","        base_dir: Base directory\n","        dataset_name: Dataset name\n","\n","    Returns:\n","        weighted_params: Dictionary with weighted parameters, or None if not found\n","    \"\"\"\n","    summary_file = f\"{base_dir}/weight_optimization_summary.csv\"\n","\n","    try:\n","        if os.path.exists(summary_file):\n","            summary_df = pd.read_csv(summary_file)\n","            dataset_row = summary_df[summary_df['dataset'] == dataset_name]\n","\n","            if len(dataset_row) > 0:\n","                weighted_params = {\n","                    'weight_labse': float(dataset_row['weight_labse'].values[0]),\n","                    'weight_laser': float(dataset_row['weight_laser'].values[0]),\n","                    'weight_meteor': float(dataset_row['weight_meteor'].values[0]),\n","                    'weight_length': float(dataset_row['weight_length'].values[0]),\n","                    'weight_jaccard': float(dataset_row['weight_jaccard'].values[0]),\n","                    'threshold': float(dataset_row['threshold'].values[0])\n","                }\n","                print(f\"Loaded weighted parameters for {dataset_name}\")\n","                return weighted_params\n","            else:\n","                print(f\"No weighted parameters found for {dataset_name}\")\n","                return None\n","        else:\n","            print(f\"Summary file not found: {summary_file}\")\n","            return None\n","    except Exception as e:\n","        print(f\"Error loading weighted parameters: {e}\")\n","        return None\n","\n"],"metadata":{"id":"ES9PF8RwjCJP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Main execution when script is run directly\n","if __name__ == \"__main__\":\n","    # Base directory for datasets - adjust as needed\n","    base_dir = \"/content/drive/MyDrive/Colab Notebooks/preprocessed_datasets\"\n","\n","    # Option 1: Analyze a single dataset with random forest\n","    # Example usage for a single dataset:\n","    \"\"\"\n","    dataset_name = \"paranmt_small_translated_cleaned_00\"\n","\n","    # Optional: Load weighted parameters for comparison\n","    weighted_params = load_weighted_params(base_dir, dataset_name)\n","\n","    # Optional: Customize Random Forest parameter grid for faster testing\n","    custom_param_grid = {\n","        'n_estimators': [100, 300],  # Reduced options\n","        'max_depth': [None, 20],\n","        'min_samples_split': [2, 5],\n","        'min_samples_leaf': [1, 2],\n","        'max_features': ['sqrt']\n","    }\n","\n","    # Run analysis on a single dataset\n","    result = analyze_dataset_with_random_forest(\n","        dataset_name=dataset_name,\n","        base_dir=base_dir,\n","        weighted_params=weighted_params,\n","        param_grid=custom_param_grid\n","    )\n","    \"\"\"\n","\n","    # Option 2: Analyze multiple datasets and compare results\n","    # List of datasets to analyze\n","    dataset_list = [\n","        \"predprocesiranje_msr_paired_cleaned\",\n","        \"paranmt_small_translated_cleaned_00\",\n","        \"processed_quora_clean_00\",\n","        \"paws_nepodvojene_filtrirane_parafraze_00\"\n","    ]\n","\n","    # Optional: Load weighted parameters for all datasets\n","    weighted_params_dict = {}\n","    for dataset in dataset_list:\n","        weighted_params = load_weighted_params(base_dir, dataset)\n","        if weighted_params:\n","            weighted_params_dict[dataset] = weighted_params\n","\n","    # Optional: Use a smaller parameter grid for faster execution\n","    reduced_param_grid = {\n","        'n_estimators': [100, 200],\n","        'max_depth': [None, 15],\n","        'min_samples_split': [2, 5],\n","        'max_features': ['sqrt']\n","    }\n","\n","    # Run analysis on multiple datasets\n","    results = analyze_multiple_datasets_with_rf(\n","        dataset_list=dataset_list,\n","        base_dir=base_dir,\n","        weighted_params_dict=weighted_params_dict\n","    )\n","\n","    print(\"\\nAnalysis completed for all datasets!\")\n","\n","    # Example of how to use the trained model to make predictions on new data\n","    \"\"\"\n","    # Load a saved model\n","    model_file = f\"{base_dir}/rf_visualizations_paranmt_small_translated_cleaned_00/paranmt_small_translated_cleaned_00_random_forest_model.pkl\"\n","\n","    with open(model_file, 'rb') as f:\n","        loaded_model = pickle.load(f)\n","\n","    # Example new data (features need to match the training data columns)\n","    new_data = pd.DataFrame({\n","        'labse_similarity': [0.85, 0.65],\n","        'laser_similarity': [0.82, 0.60],\n","        'meteor_score': [0.75, 0.45],\n","        'length_ratio': [0.95, 0.70],\n","        'jaccard_similarity': [0.65, 0.30]\n","    })\n","\n","    # Make predictions\n","    predictions = loaded_model.predict(new_data)\n","    probabilities = loaded_model.predict_proba(new_data)[:, 1]\n","\n","    # Display results\n","    print(\"\\nPredictions for new data:\")\n","    for i, (pred, prob) in enumerate(zip(predictions, probabilities)):\n","        print(f\"Sample {i+1}: Is Paraphrase = {bool(pred)} (Confidence: {prob:.4f})\")\n","    \"\"\""],"metadata":{"id":"Xf6vNHLj19Wj"},"execution_count":null,"outputs":[]}]}